---
title: "MixedRegression"
author: "Tim Schneegans"
date: "4 Januar 2021"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

getPackages(c(
    'boot',
    'broom',
    'compiler',
    'data.table',
    "dplyr",
    'GGally',
    'ggplot2',
    'Hmisc',
    'influence.ME', 
    "ICC",
    "knitr",
    'lme4',
    'lattice',
    'lme4',
    "lmerTest", # Erhalte p-Werte
    'nlme', 
    'parallel',
    'readr',
    'reshape',
    'reshape2',
    "rsq",
    "tinytex"))

knitr::opts_chunk$set(echo = TRUE)
options(scipen=999) # Show R markdown output as Integers
```

# Prep data
```{r data}
data_et <- read_csv('data_jupyter/data_et_fix.csv')
data_trial <- read_csv('data_jupyter/data_trial_fix.csv')
data_subject <- read_csv('data_jupyter/data_subject.csv')
```

## Add glasses to data_et
```{r}
merge_by_subject = function(data, data_source, varName) {
    if (varName %in% names(data)) {
        data = data %>% dplyr::select(!varName)
    }

    data = merge(
        data, 
        data_source %>% dplyr::select(run_id, varName), 
        by='run_id')
    return(data)
}

data_trial = data_trial %>%
    merge_by_subject(data_subject, 'glasses_binary')

```

# Screening
```{r}
summary(data_et %>%
    dplyr::select(x, y, t_task)
)

summary(data_trial %>% 
    dplyr::select(run_id, offset, precision, fps)
)
```

## FPS for fixation task
```{r}
trialFPS = data_et %>%
    group_by(run_id, trial_index) %>%
    summarise(n = n())

trialFPS = merge(
    trialFPS, 
    data_trial %>% 
        dplyr::select(run_id, trial_index, trial_duration_exact),
    by=c('run_id', 'trial_index'))
trialFPS$fps = 1000 * trialFPS$n / trialFPS$trial_duration_exact

if ('fps_fix' %in% names(data_subject))
    {data_subject = data_subject %>% select(!fps_fix)}
data_subject = merge(
    data_subject, 
    trialFPS %>% group_by(run_id) %>% summarise(fps_fix = mean(fps)),
    by='run_id'
)
summary(data_subject$fps_fix)
```

## Low FPS or not following instructions
```{r}
data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(
        triedChin==0 | 
        keptHead==0 |
        fps_fix<3)

subjects_lowFPS = data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(fps_fix<3) %>%
    dplyr::pull(run_id)
print(paste(
    'N Subjects with low FPS: ', 
    length(subjects_lowFPS)))
print(subjects_lowFPS)

subjects_noInstruction = data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(triedChin==0 | keptHead==0) %>%
    dplyr::pull(run_id)
print(paste(
    'N Subjects who did not follow the instructions: ', 
    length(subjects_noInstruction)))
print(subjects_noInstruction)
```

## Trials with insanely high t_task
```{r}
high_t_task = data_et %>%
    filter(t_task>5500) %>%
    group_by(run_id, trial_index) %>%
    summarise(t_task_max = max(t_task))

merge_by_index = function(data, data_source, varName) {
    if ('trial_duration_exact' %in% names(high_t_task)) {
        data = data %>% dplyr::select(!varName)
    }
    data = merge(
        data, 
        data_source %>%
            dplyr::select(run_id, trial_index, varName),
        by=c('run_id', 'trial_index'))
    return(data)
}

high_t_task = high_t_task %>%
    merge_by_index(data_trial, 'trial_duration_exact')
unique(high_t_task$run_id)
high_t_task      
```

## Anyone without the full number of trials?
```{r}
# Number of trials per subject
ans = as.data.table(
    data_trial %>% 
        dplyr::select(run_id, trial_index, chin, withinTaskIndex)
    )[, count := uniqueN(trial_index), by = run_id]
ans %>% 
    filter(count!=18)
```

## Glasses 
```{r}
data_subject %>%
    dplyr::select(run_id, glasses_binary) %>%
    filter(is.na(glasses_binary))

subjects_NA_glasses = data_subject %>%
    dplyr::select(run_id, glasses_binary) %>%
    filter(is.na(glasses_binary)) %>%
    dplyr::pull(run_id)
```

# Cleaning
## Subjects to exclude from screening
```{r}
excludedSubjects = c(
    1, 70, 80, 97, 131, 2012, 
    subjects_lowFPS,
    subjects_noInstruction,
    subjects_NA_glasses) %>% 
    sort() %>%
    unique()

print(paste(
    'N Excluded subjects: ', 
    length(excludedSubjects)))
print(excludedSubjects)
```

## data_trial
```{r}
generalCleaning = function(data) {
    print(deparse(substitute(data)))
    print(paste('Raw: ', nrow(data)))
    data = data %>%
        filter(!(run_id %in% excludeSubjects))
    print(paste('Cleaned: ', nrow(data)))
    return(data)
}

data_trial = generalCleaning(data_trial)
data_subject = generalCleaning(data_subject)
```


```{r}
print(paste('Raw: ', nrow(data_trial)))

data_trial = data_trial %>%
    filter(
        !is.na(precision) & 
        (trial_duration_exact<5100)
        )

print(paste('Cleaned: ', nrow(data_trial)))
```

## data_et
On purpose, we don't exclude specific x and y values, neither positive nor negative outliers
```{r}
data_et = data_et %>%
    filter(
        !(run_id %in% excludedSubjects) &
        (t_task<5100)
        )
print(paste('Raw: ', nrow(data_et)))
print(paste('Cleaned: ', nrow(data_et)))
```
# Assumptions - Long Format
```{r}
predictors = c('withinTaskIndex', 'x_pos', 'y_pos', 'fps', 'glasses_binary', 'chin')
```
## Multicollinearity of the predictors
```{r}
correlation = cor(
    data_trial %>% 
        select(predictors),
    use = 'pairwise.complete.obs'
)

symnum(correlation)
correlation
```

## Standardized residuals
```{r}
random = rchisq(nrow(data_trial), 7)
fake = lm(
    random ~ ., 
    data=data_trial %>% select(predictors)
    )

fitted = scale(fake$fitted.values)
# Studentized residuals
standardized = rstudent(fake)
qqnorm(standardized)
abline(0, 1)
```

```{r}
hist(standardized)
```

## Heteroscedasticity
```{r}
plot(fitted, standardized)
abline(0, 0)
abline(v=0)
```


# Visualize Predictors
```{r}
ggpairs(data_trial[, append(predictors, c('precision', 'offset'))]) # Correlations
```



# Models
## IO: intercept only
```{r}
m_io_0 = gls(
    offset ~ 1, 
    data=data_trial,
    method='ML', 
    na.action='na.omit'
    )
summary(m_io_0)
```
## RI: Random intercept
Control for the fact that the subjects start at different places regarding the accuracy of the eyetracking data. Standard error has increased. Subjects vary by about 0.12 (Jan 24) around the intercept. The RI model is way better than the IO model. Therefore, we should do an MLM.

```{r}
m_ri_0 = lme(
    offset ~ 1, 
    data=data_trial,
    method='ML', 
    na.action='na.omit', 
    random = ~1 | run_id
    )
summary(m_ri_0)
anova(m_io_0, m_ri_0)
```
## ICC
ICC = x%. x% of the variance relate to the variance between the subjects 
```{r ICC}
library(ICC)
data_trial$run_id_factor <- as.factor(data_trial$run_id)
ICCest(data_trial$run_id_factor, data_trial$offset, 
       alpha=.05, CI.type="THD")
fixef(m_ri_0)
ranef(m_ri_0)
coef(m_ri_0)
```

# m_ri_1: adding chin rest
Look at the predictor correlation
```{r}
m_ri_1 = lme(
    offset ~ chin, # x_pos + y_pos + withinTaskIndex + fps, 
    data=data_trial,
    method='ML', 
    na.action='na.omit', 
    random = ~1 | run_id
    )
summary(m_ri_1)
anova(m_ri_0, m_ri_1)
```
# m_ri_2: adding experimental variables
glasses, chin
```{r}
m_ri_2 = lme(
    offset ~ x_pos + y_pos + withinTaskIndex + fps + glasses_binary + chin, 
    data=data_trial,
    method='ML', 
    na.action='na.omit', 
    random = ~1 | run_id
    )
summary(m_ri_2)
anova(m_ri_0, m_ri_1, m_ri_2)
```

# m_rs_0: Random slopes for chin
Standard deviation across glasses is large. Participants vary a lot around the average score. Probably another variable. Also interpret the Correlation between the fixed effects. With lower offset, chin-rest could have a greater effect. However, there are no significant findings. (Unfortunately), the RS-model is better, so the effect of chin-rest largely varies.

```{r}
m_rs_1 = lme(
    offset ~ chin, 
    data=data_trial,
    method='ML', 
    na.action='na.omit', 
    random = ~ chin | run_id,
    control = lmeControl(msMaxIter = 200) # Get sure it converges
    )
summary(m_rs_1)
anova(m_ri_1, m_rs_1)
# anova(...)
```

# Random Slope with the best predictors
# TODO: Also try only using the top positions (see Semmelmann & Weigelt) 
```{r}
m_rs_2 = lme(
    offset ~ chin + y_pos, 
    data=data_trial,
    method='ML', 
    na.action='na.omit', 
    random = ~ chin | run_id,
    control = lmeControl(msMaxIter = 200) # Get sure it converges
    )
summary(m_rs_2)

anova(m_rs_1, m_rs_2)
```

# Assumptions
For this model, 
```{r}
screen = lme(offset ~ chin, 
             data = data_trial, 
             method = 'ML',
             na.action = "na.omit",
             random = ~ chin | run_id,
             control = lmeControl(msMaxIter = 200))
standardized = as.data.frame(scale(screen$residuals))
standardized = standardized$fixed
fitted = scale(fitted.values(screen))
qqnorm(standardized)
abline(0, 1)
```

Normality got worse
```{r}
hist(standardized)
```
Heteroscedasticity got worse
Concentration of dots is heavily on the left side
```{r}
plot(fitted, standardized)
abline(0, 0)
abline(v=0)
```


## Effects
Varianzaufkl?rung: Pseudo-R? (VL11 F18f.)

# More models? 
Kontexteffekte (GRO-Zentrierung, VL10)?

# Assumptions
Sources: 
 - https://www.youtube.com/watch?v=UvyxSqEXBwc
 - https://www.pythonfordatascience.org/mixed-effects-regression-python/

## Accuracy
```{r}
```

## Outliers
```{r}
```

## Multicollinearity
```{r}
```

## Linearity
```{r}
```

## Normality
Voraussetzungen (Eid2015, p. 747)
 - Residuen unabh?ngig und identisch normalverteilt, u.a.
```{r}
```

## Homogeneity
```{r}
```

## Homoscedasticity
```{r}
```