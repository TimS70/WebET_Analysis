---
title: "Fixation Task Regression Models"
author: "Tim Schneegans"
date: "4 Januar 2021"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

getPackages(c(
    'boot',
    'broom',
    'car',
    'compiler',
    'data.table',
    'DHARMa',
    "dplyr",
    'GGally',
    'ggplot2',
    'HLMdiag',
    'Hmisc',
    'influence.ME', 
    "ICC",
    "knitr",
    'lme4',
    'lattice',
    'lme4',
    "lmerTest", # Erhalte p-Werte
    'nlme', 
    'parallel',
    'readr',
    'reshape',
    'reshape2',
    "rsq",
    'tidyverse',
    "tinytex"))

knitr::opts_chunk$set(echo = TRUE)
options(scipen=999) # Show R markdown output as Integers
```

# Prep data
```{r data}
data_et <- read_csv('data_jupyter/data_et_fix.csv')
data_trial <- read_csv('data_jupyter/data_trial_fix.csv')
data_subject <- read_csv('data_jupyter/data_subject.csv')
```

## Add glasses to data_et
```{r}
merge_by_subject = function(data, data_source, varName) {
    if (varName %in% names(data)) {
        data = data %>% dplyr::select(!varName)
    }

    data = merge(
        data, 
        data_source %>% dplyr::select(run_id, varName), 
        by='run_id')
    return(data)
}

data_trial = data_trial %>%
    merge_by_subject(data_subject, 'glasses_binary')

```

# Screening
Visually impaired without aids? 
```{r}
subjects_cannotSee = data_subject %>%
    filter(sight == 'notCorrected' & 
           glasses == 'longSight') %>%
    dplyr::pull(run_id)
print(paste(
    'Subjects who are long-sighted but do not wear corrections: ',
    subjects_cannotSee
))

```


```{r}
summary(data_et %>%
    dplyr::select(x, y, t_task)
)

summary(data_trial %>% 
    dplyr::select(run_id, offset, precision, fps)
)
```

## FPS for fixation task
```{r}
trialFPS = data_et %>%
    group_by(run_id, trial_index) %>%
    summarise(n = n())

trialFPS = merge(
    trialFPS, 
    data_trial %>% 
        dplyr::select(run_id, trial_index, trial_duration_exact),
    by=c('run_id', 'trial_index'))
trialFPS$fps = 1000 * trialFPS$n / trialFPS$trial_duration_exact

if ('fps_fix' %in% names(data_subject))
    {data_subject = data_subject %>% select(!fps_fix)}
data_subject = merge(
    data_subject, 
    trialFPS %>% group_by(run_id) %>% summarise(fps_fix = mean(fps)),
    by='run_id'
)
summary(data_subject$fps_fix)
```

## Low FPS or not following instructions
```{r}
data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(
        triedChin==0 | 
        keptHead==0 |
        fps_fix<3)

subjects_lowFPS = data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(fps_fix<3) %>%
    dplyr::pull(run_id)
print(paste(
    'N Subjects with low FPS: ', 
    length(subjects_lowFPS)))
print(subjects_lowFPS)

subjects_noInstruction = data_subject %>%
    dplyr::select(run_id, triedChin, keptHead, fps_fix) %>%
    filter(triedChin==0 | keptHead==0) %>%
    dplyr::pull(run_id)
print(paste(
    'N Subjects who did not follow the instructions: ', 
    length(subjects_noInstruction)))
print(subjects_noInstruction)
```

## Trials with insanely high t_task
```{r}
high_t_task = data_et %>%
    filter(t_task>5500) %>%
    group_by(run_id, trial_index) %>%
    summarise(t_task_max = max(t_task))

merge_by_index = function(data, data_source, varName) {
    if ('trial_duration_exact' %in% names(high_t_task)) {
        data = data %>% dplyr::select(!varName)
    }
    data = merge(
        data, 
        data_source %>%
            dplyr::select(run_id, trial_index, varName),
        by=c('run_id', 'trial_index'))
    return(data)
}

high_t_task = high_t_task %>%
    merge_by_index(data_trial, 'trial_duration_exact')
unique(high_t_task$run_id)
high_t_task      
```

## Anyone without the full number of trials?
```{r}
# Number of trials per subject
ans = as.data.table(
    data_trial %>% 
        dplyr::select(run_id, trial_index, chin, withinTaskIndex)
    )[, count := uniqueN(trial_index), by = run_id]
ans %>% 
    filter(count!=18)
```

## Glasses 
```{r}
data_subject %>%
    dplyr::select(run_id, glasses_binary) %>%
    filter(is.na(glasses_binary))

subjects_NA_glasses = data_subject %>%
    dplyr::select(run_id, glasses_binary) %>%
    filter(is.na(glasses_binary)) %>%
    dplyr::pull(run_id)
```

# Cleaning
## Subjects to exclude from screening
```{r}
excludedSubjects = c(
    1, 70, 80, 97, 131, 2012, 
    subjects_lowFPS,
    subjects_noInstruction,
    subjects_NA_glasses,
    subjects_cannotSee) %>% 
    sort() %>%
    unique()

print(paste(
    'N Excluded subjects: ', 
    length(excludedSubjects)))
print(excludedSubjects)
```

## data_trial
```{r}
generalCleaning = function(data) {
    data_name = deparse(substitute(data))
    print(data_name)
    print(paste('Raw: ', nrow(data)))
    data = data %>%
        filter(!(run_id %in% excludedSubjects))
    print(paste('Cleaned: ', nrow(data)))
    return(data)
}

data_trial = generalCleaning(data_trial)
data_subject = generalCleaning(data_subject)
```


```{r}
print(paste('Raw: ', nrow(data_trial)))

data_trial = data_trial %>%
    filter(
        !is.na(precision) & 
        (trial_duration_exact<5100)
        )

print(paste('Cleaned: ', nrow(data_trial)))
```

## data_et
On purpose, we don't exclude specific x and y values, neither positive nor negative outliers
```{r}
print(paste('Raw: ', nrow(data_et)))
data_et = data_et %>% filter((t_task<5100))
print(paste('Cleaned: ', nrow(data_et)))
```


# Visualize Predictors
Significant correlations of the predictors witih fps, glasses_binary, and chin
```{r}
predictors = c('withinTaskIndex', 
               'x_pos', 'y_pos', 'fps', 
               'glasses_binary', 'chin')

ggpairs(data_trial[, append(predictors, c('precision', 'offset'))],
        progress=F) # Correlations
```



# Models

# Linear model (Fixed Effects, no MLA)
Average offset=0.17 = 17%
```{r}
lm_null = lm(offset ~ 1, data = data_trial %>% filter(!is.na(offset)))
summary(lm_null)
```

## IO: intercept only
ICC = 0.6182. 62% of the variance can be explained by the variance between the subjects. Interdependence assumption of the simple linear regression is violated. We should to an MLA
```{r}
lmer0_io = lmer(
    offset ~ 1 + (1 | run_id), 
    data=data_trial,
    REML=FALSE) # FML for comparing different fixed effects

summary(lmer0_io)

ICCest(factor(data_trial$run_id), data_trial$offset, alpha=.05, CI.type="THD")
```

## RI: Random intercept
Control for the fact that the subjects start at different places regarding the accuracy of the eyetracking data. Standard error has increased. Subjects vary by about 0.12 (Jan 24) around the intercept. The RI model is way better than the IO model. Therefore, we should do an MLM.
```{r}
data_trial = data_trial %>%
    mutate(
        y_pos_c = scale(y_pos),
        x_pos_c = scale(x_pos),
        fps_c = scale(fps))

lmer1_control = lmer(
    offset ~  withinTaskIndex + x_pos_c + y_pos_c + fps_c + (1 | run_id), 
    data=data_trial,
    REML=FALSE)

summary(lmer1_control)
anova(lmer0_io, lmer1_control)
```

### Only relevant control variables
```{r}
lmer2_control = lmer(
    offset ~ y_pos_c + (1 | run_id), 
    data=data_trial,
    REML=FALSE)

summary(lmer2_control)
anova(lmer0_io, lmer2_control)
```

### adding chin rest
Look at the predictor correlation
```{r}
lmer3_experimental = lmer(
    offset ~ y_pos_c + glasses_binary + chin + (1 | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer3_experimental)
anova(lmer2_control, lmer3_experimental)
```

### Only relevant variables
```{r}
lmer4_experimental = lmer(
    offset ~ y_pos_c + chin + (1 | run_id), 
    data=data_trial,
    REML=FALSE)

summary(lmer4_experimental)
```

### Interaction
The effect depends on the y position
```{r}
lmer5_interaction = lmer(
    offset ~ y_pos_c * chin + (1 | run_id), 
    data=data_trial,
    REML=FALSE)

summary(lmer5_interaction)
anova(lmer4_experimental, lmer5_interaction)
```

## Random slopes for chin
Standard deviation across glasses is large. Participants vary a lot around the average score. Probably another variable. Also interpret the Correlation between the fixed effects. With lower offset, chin-rest could have a greater effect. However, there are no significant findings. (Unfortunately), the RS-model is better, so the effect of chin-rest largely varies.

### Basic
```{r}
lmer6_rs = lmer(
    offset ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer6_rs)
# ranef(lmer6_rs)
anova(lmer4_experimental, lmer6_rs)
```

### Intercepts as outcomes
Offset differences are predicted by fps. L2 predictor fps is centered by an unweighted mean. No evidence for an effect of subject's computation power on the offset.
```{r}
# Get average 
grouped = data_trial %>%
    group_by(run_id) %>%
    summarise(fps_subject = mean(fps))
data_trial = data_trial %>%
    merge_by_subject(grouped, 'fps_subject') %>%
    mutate(fps_subject_c = fps - mean(grouped$fps_subject))
    
lmer7_iao = lmer(
    offset ~ y_pos_c + chin + fps_subject_c + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer7_iao)
# ranef(lmer7_iao)
anova(lmer6_rs, lmer7_iao)
```

## Cross-level interaction
Can the effect of the chin-rest be explained by differences in fps? 
````{r}
lmer8_cli = lmer(
    offset ~ y_pos_c + chin * fps_subject_c + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer8_cli)
anova(lmer7_iao, lmer8_cli)
```

# Effects
Use formulas without random slopes (Snijders & Bosker, 2012)
```{r}
m0 <- lmer(offset ~ y_pos_c + (1 | run_id),
           data=data_trial,
           REML=FALSE)
m1 <- lmer(offset ~ y_pos_c + chin + (1 | run_id),
           data=data_trial,
           REML=FALSE)

L1_m0 <- sigma(m0)^2 # L1-Residualvarianz RIO Modell
L1_m1 <- sigma(m1)^2 # L1-Residualvarianz RI Modell
print('Pseudo R^2')
print(paste(
    'Reduction of L1 variance due to chin: ',
    (L1_m0 - L1_m1)/L1_m0
))

L2_m0 <- unlist(summary(m0)$var) # Interceptvarianz RI Modell
L2_m1 <- unlist(summary(m1)$var) # Interceptvarianz IAO Modell
print(paste(
    'Reduction of L2 variance due to chin: ',
    (L2_m0 - L2_m1)/L2_m0
))

```

# Assumptions
Sources: 
 - https://www.youtube.com/watch?v=UvyxSqEXBwc
 - https://www.pythonfordatascience.org/mixed-effects-regression-python/
 - https://ademos.people.uic.edu/Chapter18.html
 
## Linearity: Plot residuals vs. observed
```{r}
plot(resid(lmer6_rs), data_trial$offset)
```

## Homosedasticity: Homogeneity of residuals across groups
ANOVA as a variation of Levene's test. Extract residuals from the model and square the absolute value. Should be not significant. Significant differences across residuals. We have Heteroscedasticity.
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(lmer6_rs),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(lmer6_rs)
```

## Normal distribution of residuals
Normal distribution not given. 
```{r}
qqmath(lmer6_rs, id=0.05)
```

Lets try with log transformed offset
Does not make it any better
```{r}
data_trial = data_trial %>%
    mutate(
        offset_log = log(offset+1),
        offset_log10 = log10(offset+1),
        offset_sqrt = sqrt(offset),
        )

lmer_log = lmer(
    offset_log ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_log)
ranef(lmer_log)
qqmath(lmer_log, id=0.05, main='log transformed offset')

lmer_log10 = lmer(
    offset_log10 ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_log10)
ranef(lmer_log10)
qqmath(lmer_log10, id=0.05, main='log10 transformed offset')

lmer_sqrt = lmer(
    offset_sqrt ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_sqrt)
ranef(lmer_sqrt)
qqmath(lmer_sqrt, id=0.05, main='sqrt transformed offset')

````

### Residuals for sqrt transformation
Does not look better
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(lmer_sqrt),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(lmer_sqrt)
```

## Multicollinearity of the predictors
No multicollinearity
```{r}
correlation = cor(
    data_trial %>% 
        select(predictors),
    use = 'pairwise.complete.obs'
)

symnum(correlation)
correlation

car::vif(lmer6_rs)
```

## HLMdiag
https://cran.rstudio.com/web/packages/HLMdiag/index.html
```{r}
#case_delete() #iteratively delete groups corresponding to the levels of a hierarchical linear model, using lmer to fit the models for each deleted case

#covratio() #calculate measures of the change in the covariance matrices for the fixed effects based on the deletion of an observation, or group of observations,

#diagnostics() #is used to compute deletion diagnostics for a hierarchical linear model based on the building blocks returned by case_delete.

#HLMresid() #extracts residuals from a hierarchical linear model fit using lmer. Can provide a variety of different types of residuals based upon the specifications when you call the function

#leverage() #calculates the leverage of a hierarchical linear model fit

#mdffits() #calculate measures of the change in the fixed effects estimates based on the deletetion of an observation, or group of observations
```


