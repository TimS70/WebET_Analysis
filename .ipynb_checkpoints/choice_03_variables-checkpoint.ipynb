{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working directory  C:\\Users\\User\\GitHub\\WebET_Analysis\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm \n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "from tqdm import tqdm \n",
    "    \n",
    "from IPython.display import HTML\n",
    "def View(df):\n",
    "    css = \"\"\"<style>\n",
    "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
    "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
    "    table thead th { background-color: #eee; color: #000; }\n",
    "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
    "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
    "    \"\"\"\n",
    "    s  = '<script type=\"text/Javascript\">'\n",
    "    s += 'var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));'\n",
    "    s += 'win.document.body.innerHTML = \\'' + (df.to_html() + css).replace(\"\\n\",'\\\\') + '\\';'\n",
    "    s += '</script>'\n",
    "    return(HTML(s+css))    \n",
    "\n",
    "os.chdir(r'C:\\Users\\User\\GitHub\\WebET_Analysis')\n",
    "print(\"Current Working directory \" , os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-corrected or the standard datset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_adjusted_et_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['trial_index'], dtype='object'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7d3f6eebec26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         r'C:/Users/User/GitHub/WebET_Analysis/data_jupyter/choice_task/data_subject.csv')    \n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0met_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_et\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'run_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trial_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    773\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m             \u001b[1;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1055\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_seq_items\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"display.width\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 raise KeyError(\n\u001b[0m\u001b[0;32m   1322\u001b[0m                     \u001b[1;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                     \u001b[1;34m\"is no longer supported. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['trial_index'], dtype='object'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "if use_adjusted_et_data: \n",
    "    print('Using adjusted et data \\n')\n",
    "    data_et = pd.read_csv(\n",
    "        r'C:/Users/User/GitHub/WebET_Analysis/data_jupyter/choice_task/adjusted/data_et.csv')\n",
    "else: \n",
    "    data_et = pd.read_csv(\n",
    "        r'C:/Users/User/GitHub/WebET_Analysis/data_jupyter/choice_task/cleaned/data_et.csv')\n",
    "    \n",
    "data_trial = pd.read_csv(\n",
    "    r'C:/Users/User/GitHub/WebET_Analysis/data_jupyter/choice_task/cleaned/data_trial.csv')\n",
    "data_subject = pd.read_csv(\n",
    "    r'C:/Users/User/GitHub/WebET_Analysis/data_jupyter/choice_task/cleaned/data_subject.csv')    \n",
    "\n",
    "et_trials = data_et.loc[:, ['run_id', 'trial_index']] \\\n",
    "    .drop_duplicates()\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "   {'dataset': \n",
    "        [ \n",
    "           'data_et',\n",
    "           'data_trial',\n",
    "           'data_subject'\n",
    "        ],\n",
    "    'runs': \n",
    "        [\n",
    "            len(data_et['run_id'].unique()),\n",
    "            len(data_trial['run_id'].unique()),\n",
    "            len(data_subject['run_id'].unique()),\n",
    "        ],\n",
    "    'n_trials': \n",
    "        [\n",
    "            len(et_trials),\n",
    "            len(data_trial['trial_index']),\n",
    "            '-',\n",
    "        ]\n",
    "   }\n",
    ") \n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_amount_left(data):\n",
    "    data['amountLeft'] = 0 \n",
    "    data.loc[\n",
    "        (data['option_topLeft'].str.contains(\"\\$\", regex=True)) |\n",
    "        (data['option_topLeft'].str.contains(\"cent\", regex=True)), \n",
    "        'amountLeft'] = 1\n",
    "    data['amountLeft'].unique()\n",
    "    return data\n",
    "\n",
    "data_trial = identify_amount_left(data_trial)\n",
    "data_trial.loc[:, ['amountLeft', 'option_topLeft']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_var_to_data_et(data_et, source_data, varName):\n",
    "    \n",
    "    if varName in data_et.columns: \n",
    "        data_et=data_et.drop(columns=varName)\n",
    "        \n",
    "    data_et = data_et.merge(\n",
    "        source_data.loc[:, ['run_id', 'trial_index', varName]], \n",
    "        on=['run_id', 'trial_index'], how='left')\n",
    "    \n",
    "    return data_et\n",
    "\n",
    "data_et = add_var_to_data_et(data_et, data_trial, 'amountLeft')\n",
    "print(data_et['amountLeft'].unique())\n",
    "data_et['amountLeft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_options_to_numeric(data, varName): \n",
    "    data[varName + '_num'] = data[varName]\n",
    "    data[varName + '_num'] = data[varName + '_num'] \\\n",
    "        .replace(['Today', 'Tomorrow', '7 days', \n",
    "                  '15 days', '30 days', '90 days', \n",
    "                  '180 days'], \n",
    "                 [0, 1, 7, 15, 30, 90, 180]) \\\n",
    "        .replace({'\\$':''}, regex = True) \\\n",
    "        .replace('50 cent', 0.5) \\\n",
    "        .astype(float)\n",
    "    return data\n",
    "\n",
    "data_trial = data_trial \\\n",
    "    .rename(columns={\n",
    "    'option_topLeft': 'option_TL', \n",
    "    'option_bottomLeft': 'option_BL', \n",
    "    'option_topRight': 'option_TR', \n",
    "    'option_bottomRight': 'option_BR'\n",
    "    })\n",
    "\n",
    "variables = [\n",
    "    'option_TL',\n",
    "    'option_BL', \n",
    "    'option_TR', \n",
    "    'option_BR'\n",
    "]\n",
    "for var in variables:\n",
    "    data_trial = choice_options_to_numeric(data_trial, var) \n",
    "    \n",
    "data_trial.loc[\n",
    "    :, \n",
    "    [\n",
    "    'option_TL',\n",
    "    'option_BL', \n",
    "    'option_TR', \n",
    "    'option_BR',\n",
    "    'option_TL_num',\n",
    "    'option_BL_num', \n",
    "    'option_TR_num', \n",
    "    'option_BR_num'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformatAttributes(data):    \n",
    "    data['aSS'] = 0 \n",
    "    data.loc[data['amountLeft']==1, 'aSS']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==1, \n",
    "            [\"option_TL_num\", \"option_BL_num\"]\n",
    "        ].values.min(1)\n",
    "    data.loc[data['amountLeft']==0, 'aSS']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==0, \n",
    "            [\"option_TR_num\", \"option_BR_num\"]\n",
    "        ].values.min(1)\n",
    "\n",
    "    data['aLL'] = 0 \n",
    "    data.loc[data['amountLeft']==1, 'aLL']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==1, \n",
    "            [\"option_TL_num\", \"option_BL_num\"]\n",
    "        ].values.max(1)\n",
    "    data.loc[data['amountLeft']==0, 'aLL']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==0, \n",
    "            [\"option_TR_num\", \"option_BR_num\"]\n",
    "        ].values.max(1)\n",
    "    \n",
    "    data.loc[:, \"tSS\"] = 0 \n",
    "    \n",
    "    data['tLL'] = 0 \n",
    "    data.loc[data['amountLeft']==1, 'tLL']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==1, \n",
    "            [\"option_TR_num\", \"option_BR_num\"]\n",
    "        ].values.max(1)\n",
    "    data.loc[data['amountLeft']==0, 'tLL']= \\\n",
    "        data.loc[\n",
    "            data['amountLeft']==0, \n",
    "            [\"option_TL_num\", \"option_BL_num\"]\n",
    "        ].values.max(1)\n",
    "    \n",
    "    data['LL_top'] = \\\n",
    "        (data[\"option_TL_num\"] > data[\"option_BL_num\"]) \\\n",
    "        .astype(int)\n",
    "\n",
    "    print('aLL values: ' + str(np.sort(data['aLL'].unique())))\n",
    "    print('aSS values: ' + str(np.sort(data['aSS'].unique())))\n",
    "    print('tLL values: ' + str(np.sort(data['tLL'].unique())))\n",
    "    print('tSS values: ' + str(np.sort(data['tSS'].unique())))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data_trial = reformatAttributes(data_trial)\n",
    "data_trial.loc[\n",
    "    : , \n",
    "    [\n",
    "        'amountLeft', \n",
    "        'option_TL',\n",
    "        'option_BL', \n",
    "        'option_TR', \n",
    "        'option_BR', \n",
    "        'aLL', \n",
    "        'aSS', \n",
    "        'tLL', \n",
    "        'tSS',\n",
    "        'LL_top'\n",
    "    ] \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_bottom_attributes(data):\n",
    "    data['aT'] = data['LL_top'] * data['aLL'] + \\\n",
    "        (1-data['LL_top']) * data['aSS']\n",
    "    data['aB'] = (1-data['LL_top']) * data['aLL'] + \\\n",
    "        data['LL_top'] * data['aSS']\n",
    "    data['tT'] = data['LL_top'] * data['tLL'] + \\\n",
    "        (1-data['LL_top']) * data['tSS']\n",
    "    data['tB'] = (1-data['LL_top']) * data['tLL'] + \\\n",
    "        data['LL_top'] * data['tSS']\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "data_trial = top_bottom_attributes(data_trial)\n",
    "data_trial.loc[\n",
    "    :, \n",
    "    ['aT', 'tT', 'aB', 'tB', 'LL_top']\n",
    "].sort_values(by='LL_top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_et = add_var_to_data_et(\n",
    "    data_et, \n",
    "    data_trial, \n",
    "    'LL_top'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choice_response_variables(data):\n",
    "    \n",
    "    # Up-Arrow is 38, Down-Arrow is 40\n",
    "    data[\"choseTop\"] = 0\n",
    "    data.loc[(data[\"key_press\"]==38), \"choseTop\"] = 1\n",
    "\n",
    "    data[\"choseLL\"] = 0\n",
    "    data.loc[(data[\"choseTop\"]==1) & (data[\"LL_top\"] == 1), \"choseLL\"] = 1\n",
    "    data.loc[(data[\"choseTop\"]==0) & (data[\"LL_top\"] == 0), \"choseLL\"] = 1\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "data_trial = choice_response_variables(data_trial)\n",
    "\n",
    "# Check these subjects:  19   32   66   96  126  130 1000 2012\n",
    "data_trial.loc[\n",
    "    :, # data_trial['run_id']==32, \n",
    "    [\n",
    "        'amountLeft', \n",
    "        'option_TL',\n",
    "        'option_TR', \n",
    "        'option_BL', \n",
    "        'option_BR', \n",
    "        'key_press',\n",
    "        'choseTop',\n",
    "        'choseLL', \n",
    "        ]\n",
    "].sort_values(by='amountLeft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial.loc[\n",
    "    (data_trial['choseTop']==1) &\n",
    "    (data_trial['LL_top']==1)\n",
    "    ,\n",
    "    [\n",
    "        'amountLeft', \n",
    "        'option_TL',\n",
    "        'option_TR', \n",
    "        'option_BL', \n",
    "        'option_BR',\n",
    "        'key_press',\n",
    "        'choseLL'\n",
    "    ]\n",
    "].sort_values(by='amountLeft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate on subject level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merge_by_subject(data, large_data, varName):\n",
    "    if varName in data.columns: data = data.drop(columns=[varName])\n",
    "    grouped = large_data.groupby(['run_id'])[varName].mean() \\\n",
    "        .reset_index()        \n",
    "    data = data.merge(grouped, on=['run_id'], how='left')\n",
    "    return data\n",
    "for var in ['choseLL', 'choseTop', 'LL_top']:\n",
    "    data_subject = merge_by_subject(data_subject, data_trial, var)\n",
    "data_subject.loc[\n",
    "    :,\n",
    "    ['run_id', 'choseLL', 'choseTop', 'LL_top']\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def k(aLL, aSS, tLL):\n",
    "    k = ((aLL / aSS) - 1) / tLL\n",
    "    return k\n",
    "\n",
    "data_trial['k'] = k(data_trial['aLL'], data_trial['aSS'], data_trial['tLL']) \n",
    "data_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lookDirections(data):\n",
    "    data[\"look_left\"] = (data[\"x\"] < 0.5).astype(int)\n",
    "    data[\"look_top\"] = (data[\"y\"] < 0.5).astype(int)\n",
    "    return data\n",
    "\n",
    "data_et = lookDirections(data_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addAOI(data, aoi_width, aoi_height): \n",
    "    aoiCenters = pd.DataFrame(\n",
    "        [\n",
    "            [(0.05+0.9*0.2), 0.75],\n",
    "            [(0.05+0.9*0.8), 0.75],\n",
    "            [(0.05+0.9*0.2), 0.25],\n",
    "            [(0.05+0.9*0.8), 0.25]\n",
    "        ], \n",
    "        columns = ['x', 'y'],\n",
    "        index = ['TL', 'TR', 'BL', 'BR']\n",
    "    )\n",
    "    \n",
    "    data['aoi'] = 0 \n",
    "    for aoi in aoiCenters.index:\n",
    "        data.loc[\n",
    "            (\n",
    "                (data['x'] > (aoiCenters.loc[aoi, 'x'] - aoi_width/2)) & \\\n",
    "                (data['x'] < (aoiCenters.loc[aoi, 'x'] + aoi_width/2)) & \\\n",
    "                (data['y'] > (aoiCenters.loc[aoi, 'y'] - aoi_height/2)) & \\\n",
    "                (data['y'] < (aoiCenters.loc[aoi, 'y'] + aoi_height/2))\n",
    "             ), 'aoi'] = aoi\n",
    "    return data \n",
    "\n",
    "# If not already done in Matlab\n",
    "if np.invert(use_adjusted_et_data):\n",
    "    print('AOI will be calculated. No cluster correction. ')\n",
    "    data_et = addAOI(data_et, 0.3, 0.3)\n",
    "    print(data_et['aoi'].unique())\n",
    "    \n",
    "data_et['aoi'] = data_et['aoi'].replace(\n",
    "    [1, 2, 3, 4], \n",
    "    ['TL', 'TR', 'BL', 'BR']\n",
    ")\n",
    "\n",
    "print(data_et['aoi'].unique())\n",
    "\n",
    "data_plot = data_et.loc[data_et['aoi']!=0, ['x', 'y']]\n",
    "x = data_plot['x']\n",
    "y = data_plot['y']\n",
    "plt.scatter(x, y)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAOIColumns(data):\n",
    "    data['aoi_aLL'] = 0\n",
    "    data['aoi_tLL'] = 0 \n",
    "    data['aoi_aSS'] = 0 \n",
    "    data['aoi_tSS'] = 0\n",
    "    \n",
    "    # If amounts are on the left side\n",
    "    ## If the gaze point is in the top option\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='TL')), \n",
    "             'aoi_aLL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='TR')), \n",
    "             'aoi_tLL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='BL')), \n",
    "             'aoi_aSS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='BR')), \n",
    "             'aoi_tSS'] = 1\n",
    "    \n",
    "    ## If the gaze point is in the bottom option\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='TL')), \n",
    "             'aoi_aSS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='TR')), \n",
    "             'aoi_tSS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='BL')), \n",
    "             'aoi_aLL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='BR')), \n",
    "             'aoi_tLL'] = 1\n",
    "    \n",
    "    # If amounts are on the right side\n",
    "    ## If the gaze point is in the top option\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='TL')), \n",
    "             'aoi_tLL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='TR')), \n",
    "             'aoi_aLL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='BL')), \n",
    "             'aoi_tSS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='BR')),\n",
    "             'aoi_aSS'] = 1\n",
    "\n",
    "    ## If the gaze point is in the bottom option\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='TL')), \n",
    "             'aoi_tSS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='TR')), \n",
    "             'aoi_aSS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='BL')), \n",
    "             'aoi_tLL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='BR')), \n",
    "             'aoi_aLL'] = 1\n",
    "    return data\n",
    "\n",
    "data_et = createAOIColumns(data_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_counter(aoi_vector):\n",
    "    aoi_numbers = aoi_vector \\\n",
    "        .replace(['TL', 'TR', 'BL', 'BR'], np.arange(1, 5)) \\\n",
    "        .astype(int) \\\n",
    "        .reset_index(drop=True)\n",
    "    counter = 0\n",
    "\n",
    "    fix_counter = np.zeros(len(aoi_numbers))\n",
    "    fix_counter[0] = int(aoi_numbers[0] != 0)\n",
    "\n",
    "    for i in np.delete(aoi_numbers.index, 0):\n",
    "        if (\n",
    "            (aoi_numbers[i] > 0) &  \n",
    "            (aoi_numbers[i] != aoi_numbers[i-1])\n",
    "           ):\n",
    "            counter += 1\n",
    "\n",
    "        if aoi_numbers[i] > 0:\n",
    "            fix_counter[i] = counter \n",
    "\n",
    "    return fix_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fixation_counter(data):\n",
    "    data = data.copy()\n",
    "    data.loc[:, 'fix_counter'] = 0\n",
    "    \n",
    "    for subject in tqdm(data['run_id'].unique()):\n",
    "        for trial in data.loc[data['run_id']==subject, 'withinTaskIndex'].unique():\n",
    "            \n",
    "            temp_aoi = data.loc[\n",
    "                (data['run_id']==subject) &\n",
    "                (data['withinTaskIndex']==trial), \n",
    "                'aoi']\n",
    "            \n",
    "            data.loc[\n",
    "                (data['run_id']==subject) &\n",
    "                (data['withinTaskIndex']==trial), \n",
    "                'fix_counter'] = fix_counter(temp_aoi)\n",
    "\n",
    "    return data\n",
    "\n",
    "data_et = add_fixation_counter(data_et)\n",
    "data_et.groupby(['run_id', 'aoi'])['fix_counter'].count().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixations on trial level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial = data_trial \\\n",
    "    .merge(\n",
    "        data_et.groupby(['run_id', 'withinTaskIndex'])['fix_counter'].nunique(),\n",
    "        on=['run_id', 'withinTaskIndex'],\n",
    "        how='left'\n",
    "    ) \\\n",
    "    .rename(columns={'n_fixations': 'fix_counter'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye-Tracking indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AOI counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_et.groupby(['run_id', 'trial_index']) \\\n",
    "        ['aoi_aSS', 'aoi_aLL', 'aoi_tSS', 'aoi_tLL'].sum() \\\n",
    "        .reset_index() \n",
    "print(grouped)\n",
    "\n",
    "data_plot = pd.DataFrame(pd.concat(\n",
    "    [\n",
    "        grouped['aoi_aSS'],\n",
    "        grouped['aoi_tSS'],\n",
    "        grouped['aoi_aLL'],\n",
    "        grouped['aoi_tLL']\n",
    "    ]), columns=['n']) \n",
    "\n",
    "plt.hist(data_plot, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in ['aoi_aSS', 'aoi_aLL', 'aoi_tSS', 'aoi_tLL']:\n",
    "    if var in data_trial.columns: \n",
    "        data_trial = data_trial.drop(columns=[var])\n",
    "        \n",
    "data_trial = data_trial.merge(\n",
    "    grouped, \n",
    "    on=['run_id', 'trial_index'], \n",
    "    how='left')\n",
    "    \n",
    "data_trial.loc[\n",
    "    :, \n",
    "    ['run_id', 'trial_index', 'aoi_aSS', 'aoi_aLL', 'aoi_tSS', 'aoi_tLL']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Option Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def require_min(data, min_required_count):\n",
    "    return data.replace(\n",
    "        np.arange(min_required_count), \n",
    "        np.repeat(0, min_required_count)) \n",
    "\n",
    "def addOptionIndex(data):\n",
    "    \n",
    "    gazePoints_immediate = \\\n",
    "        require_min(data['aoi_aSS'], 3) + \\\n",
    "        require_min(data['aoi_tSS'], 3)\n",
    "    gazePoints_delay = \\\n",
    "        require_min(data['aoi_aLL'], 3) + \\\n",
    "        require_min(data['aoi_tLL'], 3)\n",
    "    optionIndex = \\\n",
    "        (gazePoints_immediate - gazePoints_delay) / \\\n",
    "        (gazePoints_immediate + gazePoints_delay)\n",
    "    \n",
    "    return optionIndex\n",
    "\n",
    "data_trial['optionIndex'] = addOptionIndex(data_trial)\n",
    "print(data_trial['optionIndex'].describe())\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [sum(pd.isna(data_trial['optionIndex']))],\n",
    "            [sum(data_trial['optionIndex']==1)],\n",
    "            [sum(data_trial['optionIndex']==0)],\n",
    "            [sum((data_trial['optionIndex']>0) &\n",
    "                 (data_trial['optionIndex']<1))],\n",
    "            [len(data_trial)]\n",
    "        ], index = ['NAN', '1', '0', '0>optionIndex>1', 'total']    \n",
    "    )\n",
    ")\n",
    "\n",
    "print(data_trial.loc[\n",
    "    :, \n",
    "    [\n",
    "        'run_id', 'trial_index', \n",
    "        'aoi_aSS', 'aoi_aLL', 'aoi_tSS', 'aoi_tLL', \n",
    "        'optionIndex'\n",
    "    ]\n",
    "].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addAttributeIndex(data):\n",
    "\n",
    "    gazePoints_amount = \\\n",
    "        require_min(data['aoi_aLL'], 3) + \\\n",
    "        require_min(data['aoi_aSS'], 3)\n",
    "    gazePoints_time = \\\n",
    "        require_min(data['aoi_tLL'], 3) + \\\n",
    "        require_min(data['aoi_tSS'], 3)\n",
    "\n",
    "    attributeIndex = \\\n",
    "        (gazePoints_amount - gazePoints_time) / \\\n",
    "        (gazePoints_amount + gazePoints_time)\n",
    "    \n",
    "    return attributeIndex\n",
    "\n",
    "\n",
    "data_trial['attributeIndex'] = addAttributeIndex(data_trial)\n",
    "\n",
    "print(data_trial['attributeIndex'].describe())\n",
    "print(pd.DataFrame(\n",
    "        [\n",
    "            [sum(pd.isna(data_trial['attributeIndex']))],\n",
    "            [sum(data_trial['attributeIndex']==1)],\n",
    "            [sum(data_trial['attributeIndex']==0)],\n",
    "            [sum((data_trial['attributeIndex']>0) &\n",
    "                 (data_trial['attributeIndex']<1))],\n",
    "            [len(data_trial)]\n",
    "        ], index = ['NAN', '1', '0', '0>attributeIndex>1', 'total']    \n",
    "    )\n",
    ")\n",
    "\n",
    "print(data_trial.loc[\n",
    "    :, \n",
    "    [\n",
    "        'run_id', 'trial_index', \n",
    "        'aoi_aSS', 'aoi_aLL', 'aoi_tSS', 'aoi_tLL', \n",
    "        'attributeIndex'\n",
    "    ]\n",
    "].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payne Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitions between AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_data_transition_type(data):\n",
    "    data = data.loc[\n",
    "        pd.notna(data['aoi']) &\n",
    "        (data['aoi']!=0), :]\n",
    "    data['newAOIIndex'] = 0\n",
    "    data.loc[(data['aoi_aLL']==1), 'newAOIIndex'] = 1\n",
    "    data.loc[(data['aoi_tLL']==1), 'newAOIIndex'] = 2\n",
    "    data.loc[(data['aoi_aSS']==1), 'newAOIIndex'] = 4\n",
    "    data.loc[(data['aoi_tSS']==1), 'newAOIIndex'] = 8\n",
    "    data.sort_values(by=['run_id', 'withinTaskIndex'])\n",
    "    # Add a 0 due to the way np.diff works\n",
    "    data['transition_type'] = np.append([0], np.diff(data['newAOIIndex']))\n",
    "    data['transition_type'] = abs(data['transition_type']) \n",
    "\n",
    "    data.loc[data['t_task']==0, 'transition_type'] = 0\n",
    "\n",
    "    return data.loc[:, ['run_id', 'trial_index', 't_task', 'transition_type']]\n",
    "\n",
    "def addTransition_type(data, data_et):\n",
    "    data_et = et_data_transition_type(data_et)\n",
    "    data_et.loc[:, 'transition_type'] = data_et.loc[:, 'transition_type']\n",
    "    \n",
    "    transition_count = pd.pivot_table(\n",
    "        data_et.loc[:, ['run_id', 'trial_index', 'transition_type']], \n",
    "        index = ['run_id', 'trial_index'],\n",
    "        columns = ['transition_type'], \n",
    "        aggfunc = len,\n",
    "        fill_value = 0) \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns={\n",
    "        0: \"trans_type_0\",\n",
    "        1: \"trans_type_aLLtLL\",\n",
    "        2: \"trans_type_tLLaSS\",\n",
    "        3: \"trans_type_aLLaSS\",\n",
    "        4: \"trans_type_aSStSS\",\n",
    "        6: \"trans_type_tLLtSS\",\n",
    "        7: \"trans_type_aLLtSS\", \n",
    "        8: \"trans_type_0_tSS\",\n",
    "    })\n",
    "    \n",
    "    transition_columns = [\"trans_type_0\", \"trans_type_aLLtLL\", \n",
    "            \"trans_type_tLLaSS\", \"trans_type_aLLaSS\",\n",
    "            \"trans_type_aSStSS\", \"trans_type_tLLtSS\", \n",
    "            \"trans_type_aLLtSS\"]\n",
    "    \n",
    "    for var in transition_columns:\n",
    "        if var in data: \n",
    "            data = data.drop(columns=[var])\n",
    "        \n",
    "    data = data.merge(transition_count, on=['run_id', 'trial_index'], how='left') \n",
    "    data.loc[:, transition_columns] = data.loc[:, transition_columns] \\\n",
    "        .fillna(0)\n",
    "    return(data)\n",
    "\n",
    "data_trial = addTransition_type(data_trial, data_et)\n",
    "data_trial.loc[\n",
    "    :, \n",
    "    [\n",
    "        'run_id', 'trial_index',\n",
    "        'aoi_aLL', 'aoi_aSS', 'aoi_tLL', 'aoi_tSS',\n",
    "        'trans_type_0', 'trans_type_aLLtLL', 'trans_type_tLLaSS',\n",
    "        'trans_type_aLLaSS', 'trans_type_aSStSS', 'trans_type_tLLtSS',\n",
    "        'trans_type_aLLtSS'\n",
    "    ]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addPayneIndex(data):\n",
    "    \n",
    "    optionWise_transition = \\\n",
    "        data['trans_type_aLLtLL'] + \\\n",
    "        data['trans_type_aSStSS']\n",
    "    attributeWise_transition = \\\n",
    "        data['trans_type_aLLaSS'] + \\\n",
    "        data['trans_type_tLLtSS']  \n",
    "        \n",
    "    payneIndex = \\\n",
    "        (optionWise_transition - attributeWise_transition) / \\\n",
    "        (optionWise_transition + attributeWise_transition) \n",
    "    \n",
    "\n",
    "    return payneIndex\n",
    "\n",
    "data_trial['payneIndex'] = addPayneIndex(data_trial)\n",
    "\n",
    "print(data_trial['payneIndex'].describe())\n",
    "print(pd.DataFrame(\n",
    "        [\n",
    "            [sum(pd.isna(data_trial['payneIndex']))],\n",
    "            [sum(data_trial['payneIndex']==1)],\n",
    "            [sum(data_trial['payneIndex']==0)],\n",
    "            [sum((data_trial['payneIndex']>0) &\n",
    "                 (data_trial['payneIndex']<1))],\n",
    "            [len(data_trial)]\n",
    "        ], index = ['NAN', '1', '0', '0>payneIndex>1', 'total']    \n",
    "    )\n",
    ")\n",
    "\n",
    "data_trial.loc[\n",
    "    data_trial['fps']>15, \n",
    "    ['run_id', 'trial_duration_exact',\n",
    "     'trans_type_aLLtLL', 'trans_type_aSStSS', 'trans_type_aLLaSS', 'trans_type_tLLtSS',\n",
    "     'payneIndex'\n",
    "    ]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate on subject-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subject = merge_by_subject(data_subject, data_trial, 'attributeIndex')\n",
    "data_subject = merge_by_subject(data_subject, data_trial, 'optionIndex')\n",
    "data_subject = merge_by_subject(data_subject, data_trial, 'payneIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-value\n",
    "http://alexanderfengler.github.io/neuroeconomics/K-Estimation/\n",
    "\n",
    "According to Chabris and Laibson (2008), 'An agent chooses aLL, if Y / (1 + k*t) - X >= 0  holds true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Index: Order: A column that stores the order of questions asked\n",
    " - aSS: SIR: Column storing the small immediate rewards by choice set\n",
    " - aLL: LDR: Column storing the large delayed rewards by choice set\n",
    " - tLL: Delay: Column storing the respecitve delays for LDR’s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k = data_trial.loc[\n",
    "    data_trial['run_id']==11, \n",
    "    ['run_id', 'withinTaskIndex', 'aSS', 'aLL', 'tLL']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction time on subject-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_trial.groupby(['run_id'])['trial_duration_exact'].mean() \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'trial_duration_exact': 'choice_rt'})\n",
    "\n",
    "if 'choice_rt' in data_subject.columns: data_subject = data_subject.drop(columns=['choice_rt'])\n",
    "data_subject = data_subject.merge(grouped, on='run_id', how='left')\n",
    "data_subject['choice_rt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster = data_trial.dropna(\n",
    "    subset=['trans_type_0',\n",
    "       'trans_type_aLLtLL', 'trans_type_tLLaSS', 'trans_type_aLLaSS',\n",
    "       'trans_type_aSStSS', 'trans_type_tLLtSS'] , how='all')\n",
    "\n",
    "data_cluster.loc[:, [\n",
    "       'trans_type_0',\n",
    "       'trans_type_aLLtLL', 'trans_type_tLLaSS', 'trans_type_aLLaSS',\n",
    "       'trans_type_aSStSS', 'trans_type_tLLtSS']\n",
    "                     ].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data_cluster.loc[\n",
    "    :, \n",
    "    ['trans_type_0',\n",
    "     'trans_type_aLLtLL', 'trans_type_tLLaSS', 'trans_type_aLLaSS',\n",
    "     'trans_type_aSStSS', 'trans_type_tLLtSS']\n",
    "]\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters(n_clusters):\n",
    "    kmeans = KMeans(\n",
    "        init=\"random\",\n",
    "        n_clusters=n_clusters,\n",
    "        n_init=10,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    "    kmeans.fit(scaled_features)\n",
    "            \n",
    "#     https://realpython.com/k-means-clustering-python/\n",
    "#     print(kmeans.inertia_)\n",
    "#     print(kmeans.cluster_centers_)\n",
    "#     print(kmeans.n_iter_)\n",
    "\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "X = data_cluster[[\"run_id\"]] #, \"withinTaskIndex\"]]\n",
    "X_ = sm.add_constant(X)\n",
    "y = 1-data_cluster[[\"choseLL\"]]  \n",
    "log_reg = sm.Logit(y, X_).fit() \n",
    "output.append([0, log_reg.bic, log_reg.aic])\n",
    "                  \n",
    "for n_cluster in range(2, 5):\n",
    "    data_cluster['cluster' + str(n_cluster)] = clusters(n_cluster)\n",
    "    X = data_cluster[[\"run_id\", 'cluster' + str(n_cluster)]]\n",
    "    X_ = sm.add_constant(X)\n",
    "    y = 1-data_cluster[[\"choseLL\"]]  \n",
    "    log_reg = sm.Logit(y, X_).fit() \n",
    "    output.append([n_cluster, log_reg.bic, log_reg.aic]) \n",
    "\n",
    "output = pd.DataFrame(output, columns = ['n_clusters', 'BIC', 'AIC']) \\\n",
    "    .set_index('n_clusters')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_adjusted_et_data: \n",
    "    data_et.to_csv(\n",
    "        \"data_jupyter/choice_task/adjusted/data_et.csv\", \n",
    "        index=False, header=True)\n",
    "    data_trial.to_csv(\n",
    "        \"data_jupyter/choice_task/adjusted/data_trial.csv\", \n",
    "        index=False, header=True)\n",
    "    data_subject.to_csv(\n",
    "        \"data_jupyter/choice_task/adjusted/data_subject.csv\", \n",
    "        index=False, header=True)\n",
    "else:\n",
    "    if not os.path.exists('./data_jupyter/choice_task/uncorrected'):\n",
    "        os.mkdir('./data_jupyter/choice_task/uncorrected')\n",
    "    \n",
    "    data_et.to_csv(\n",
    "        \"data_jupyter/choice_task/uncorrected/data_et.csv\", \n",
    "        index=False, header=True)\n",
    "    data_trial.to_csv(\n",
    "        \"data_jupyter/choice_task/uncorrected/data_trial.csv\", \n",
    "        index=False, header=True)\n",
    "    data_subject.to_csv(\n",
    "        \"data_jupyter/choice_task/uncorrected/data_subject.csv\", \n",
    "        index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Success! Script ran through')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
