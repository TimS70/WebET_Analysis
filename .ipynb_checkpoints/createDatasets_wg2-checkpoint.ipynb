{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working directory  C:\\Users\\User\\GitHub\\WebET_Analysis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import re\n",
    "import seaborn as sns\n",
    "import json\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.graphics.api as smg\n",
    "import sys\n",
    "\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "    \n",
    "from IPython.display import HTML\n",
    "def View(df):\n",
    "    css = \"\"\"<style>\n",
    "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
    "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
    "    table thead th { background-color: #eee; color: #000; }\n",
    "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
    "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
    "    \"\"\"\n",
    "    s  = '<script type=\"text/Javascript\">'\n",
    "    s += 'var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));'\n",
    "    s += 'win.document.body.innerHTML = \\'' + (df.to_html() + css).replace(\"\\n\",'\\\\') + '\\';'\n",
    "    s += '</script>'\n",
    "    return(HTML(s+css))    \n",
    "\n",
    "os.chdir(r'C:\\Users\\User\\GitHub\\WebET_Analysis')\n",
    "print(\"Current Working directory \" , os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV from String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1000, 11000, 13000, 14000, 15000, 16000, 17000, 19000, 2000,\n",
       "       20000, 21000, 3000, 7000, 8000, 9000, 22000, 24000, 2],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    # https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleanText = re.sub(cleanr, '', raw_html)\n",
    "    return cleanText\n",
    "\n",
    "def cleanETText(text):\n",
    "    textWithinBrackets = re.findall(re.compile('\\[.*?\\]'), text)\n",
    "    output = text\n",
    "    for i in range(0,len(textWithinBrackets)):\n",
    "        old = textWithinBrackets[i]\n",
    "        new = re.sub(\",\", \"$\", old)\n",
    "        output = output.replace(old, new)\n",
    "    return output\n",
    "\n",
    "def cleanSurveyText(text):\n",
    "    output = text\n",
    "    textWithinBrackets = re.findall(re.compile('\\{.*?\\}'), text)\n",
    "    for i in range(0,len(textWithinBrackets)):\n",
    "        old = textWithinBrackets[i]\n",
    "        new = old.replace(',', 'ยง')\n",
    "        output = output.replace(old, new)\n",
    "    return output\n",
    "\n",
    "def compileData(path):\n",
    "    subject_files = os.listdir(path)\n",
    "    all_subjects = []\n",
    "    for i in range(0, len(subject_files)):\n",
    "        csv_thisSubject = open(path + \"/\" + subject_files[i]).read()\n",
    "        csv_thisSubject = cleanhtml(csv_thisSubject)\n",
    "        csv_thisSubject = cleanETText(csv_thisSubject)\n",
    "        csv_thisSubject = cleanSurveyText(csv_thisSubject)\n",
    "        all_subjects.append(pd.read_csv(StringIO(csv_thisSubject)))\n",
    "    output = pd.concat(all_subjects).reset_index(drop=True)\n",
    "    return output\n",
    "\n",
    "data_yang = compileData(\"data_Yang2020WG\")\n",
    "# Custom modifications\n",
    "data_yang.loc[0:515, 'run_id'] = 0\n",
    "data_yang = data_yang.loc[~data_yang['run_id'].isin([4, 18]), :]\n",
    "data_yang['run_id'] = data_yang['run_id'] * 1000\n",
    "data_yang = data_yang.rename(columns={'eyeData': 'et_data'})\n",
    "data_cognition = compileData(\"data_cognition\")\n",
    "\n",
    "data_raw = data_yang.append(data_cognition)\n",
    "data_raw['run_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude empty studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_raw.loc[data_raw['trial_index']>0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1000 11000 14000 15000 16000 17000 19000 2000 20000 21000 3000 7000\n",
      " 8000 9000 22000 24000 2]\n",
      "Index(['run_id', 'condition', 'rt', 'stimulus', 'button_pressed',\n",
      "       'window_width', 'window_height', 'trial_type', 'trial_index',\n",
      "       'time_elapsed', 'internal_node_id', 'subject', 'chinFirst',\n",
      "       'choiceTask_amountLeftFirst', 'webcam_label', 'webcam_Id', 'webcam_fps',\n",
      "       'webcam_aspectRatio', 'webcam_height', 'webcam_width', 'key_press',\n",
      "       'success', 'x_pos', 'y_pos', 'chin', 'task_nr', 'et_data',\n",
      "       'trial_duration', 'option_topLeft', 'option_bottomLeft',\n",
      "       'option_topRight', 'option_bottomRight', 'recorded_at', 'ip',\n",
      "       'user_agent', 'device', 'browser', 'browser_version', 'platform',\n",
      "       'platform_version', 'Unnamed: 2', 'fbclid', 'bonusAmount', 'bonusDelay',\n",
      "       'chosenAmount', 'chosenDelay', 'prolificID', 'age', 'gender', 'ethnic',\n",
      "       'sight', 'glasses', 'degree', 'eyeshadow', 'masquara', 'eyeliner',\n",
      "       'browliner', 'vertPosition', 'triedChin', 'keptHead', 'optionalNote'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def cleanOptionalNote(text):\n",
    "    optionalNoteText = re.findall(re.compile('optionalNote\":.*?\\}'), text)\n",
    "    if len(optionalNoteText) < 1:\n",
    "        output = text\n",
    "    else:\n",
    "        old = optionalNoteText[0]\n",
    "        new = old.replace('ยง', ' ')\n",
    "        output = text.replace(old, new)\n",
    "    return output\n",
    "\n",
    "\n",
    "def surveyStringToFrame(subject, string):\n",
    "    string = cleanOptionalNote(string)\n",
    "    string = re.sub(\"\"\"{\"\"\", '', string)\n",
    "    string = re.sub(\"\"\"}\"\"\", '', string)\n",
    "    string = re.sub('\"', '', string)\n",
    "    string = re.sub('ยง', '$', string)\n",
    "    output = pd.read_csv(StringIO(string),\n",
    "                         sep=\":\",\n",
    "                         lineterminator=\"$\",\n",
    "                         header=None,\n",
    "                         index_col=0\n",
    "                         ).transpose()\n",
    "    return output\n",
    "\n",
    "\n",
    "def surveyData_thisSubject(data):\n",
    "    df_thisSubject = data.loc[\n",
    "        (pd.notna(data[\"responses\"])) &\n",
    "        (data[\"responses\"] != '\"'), :].reset_index()\n",
    "    subject = df_thisSubject['run_id'].unique()[0]\n",
    "    output = []\n",
    "    for i in range(0, len(df_thisSubject)):\n",
    "        output.append(\n",
    "            surveyStringToFrame(subject,\n",
    "                                df_thisSubject.loc[i, 'responses'])\n",
    "        )\n",
    "\n",
    "    output = pd.concat(output, axis=1)\n",
    "    output['run_id'] = subject\n",
    "    return output\n",
    "\n",
    "def addSurveyData(data):\n",
    "    surveyData_allSubjects = pd.DataFrame(columns=[\n",
    "            'prolificID', 'age', 'gender', 'ethnic', 'sight', \n",
    "            'glasses', 'degree', 'eyeshadow', 'masquara', 'eyeliner', \n",
    "            'browliner', 'vertPosition', 'triedChin', 'keptHead', \n",
    "            'optionalNote', 'run_id'])\n",
    "\n",
    "    for subject in data['run_id'].unique():\n",
    "        surveyData_allSubjects = \\\n",
    "            surveyData_allSubjects.append(\n",
    "                surveyData_thisSubject(\n",
    "                    data.loc[data['run_id']==subject, ['run_id', 'responses']]\n",
    "                )\n",
    "            )\n",
    "    # print(surveyData_allSubjects)\n",
    "    \n",
    "    data = data.merge(surveyData_allSubjects, on='run_id', how='left')\n",
    "    data = data.drop(columns='responses')\n",
    "    return(data)\n",
    "    \n",
    "data_raw = addSurveyData(data_raw)\n",
    "print(data_raw['run_id'].unique())\n",
    "print(data_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1000, 11000, 14000, 15000, 16000, 17000, 19000, 2000, 20000,\n",
       "       21000, 3000, 7000, 8000, 9000, 22000, 24000, 2], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToNumeric(data, columns):\n",
    "    data[columns] = data[columns].apply(pd.to_numeric, errors='coerce')\n",
    "    return data\n",
    "\n",
    "\n",
    "data_raw = convertToNumeric(data_raw, ['age'])\n",
    "data_raw['degree'] = data_raw['degree'].replace(\n",
    "        [\n",
    "            'College / Undergraduate / Bachelor',\n",
    "            'High School',\n",
    "            'Graduate / PhD / Master',\n",
    "            'Middle School'\n",
    "        ],\n",
    "    [\n",
    "            'college',\n",
    "            'highSchool',\n",
    "            'grad',\n",
    "            'middle'\n",
    "        ]\n",
    ")\n",
    "data_raw['run_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed Webgazer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>prolificID</th>\n",
       "      <th>chinFirst</th>\n",
       "      <th>choiceTask_amountLeftFirst</th>\n",
       "      <th>webcam_label</th>\n",
       "      <th>webcam_fps</th>\n",
       "      <th>webcam_aspectRatio</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>device</th>\n",
       "      <th>browser</th>\n",
       "      <th>browser_version</th>\n",
       "      <th>platform</th>\n",
       "      <th>platform_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Logitech HD Webcam C310 (046d:081b)</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>WebKit</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>Windows</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>14000</td>\n",
       "      <td>LP2202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Integrierte iSight-Kamera</td>\n",
       "      <td>30.000030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Safari</td>\n",
       "      <td>11.1.2</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>15000</td>\n",
       "      <td>LP22022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Integrierte iSight-Kamera</td>\n",
       "      <td>30.000030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Safari</td>\n",
       "      <td>11.1.2</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>16000</td>\n",
       "      <td>L345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Integrierte iSight-Kamera</td>\n",
       "      <td>30.000030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Safari</td>\n",
       "      <td>11.1.2</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>17000</td>\n",
       "      <td>L345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Integrierte iSight-Kamera (05ac:8507)</td>\n",
       "      <td>30.000031</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>19000</td>\n",
       "      <td>Liv2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Integrierte iSight-Kamera (05ac:8507)</td>\n",
       "      <td>30.000031</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Logitech HD Webcam C310 (046d:081b)</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>WebKit</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>Windows</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>20000</td>\n",
       "      <td>2020Liv</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Integrierte iSight-Kamera (05ac:8507)</td>\n",
       "      <td>30.000031</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_13_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>7000</td>\n",
       "      <td>Ka61Kl61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HD User Facing (04f2:b64f)</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>WebKit</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>Windows</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>9000</td>\n",
       "      <td>ka1501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HD User Facing (04f2:b64f)</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>WebKit</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>87.0.4280.141</td>\n",
       "      <td>Windows</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>22000</td>\n",
       "      <td>Studie1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FaceTime HD-Kamera (integriert)</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Safari</td>\n",
       "      <td>14.0.2</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_15_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>24000</td>\n",
       "      <td>Studie1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FaceTime HD-Kamera (integriert)</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6...</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>Safari</td>\n",
       "      <td>14.0.2</td>\n",
       "      <td>OS X</td>\n",
       "      <td>10_15_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run_id  prolificID  chinFirst  choiceTask_amountLeftFirst  \\\n",
       "514    1000           0        0.0                         1.0   \n",
       "1040  14000      LP2202        0.0                         0.0   \n",
       "1051  15000     LP22022        1.0                         1.0   \n",
       "1057  16000        L345        0.0                         0.0   \n",
       "1063  17000        L345        1.0                         1.0   \n",
       "1065  19000     Liv2020        0.0                         1.0   \n",
       "1075   2000           0        1.0                         1.0   \n",
       "1085  20000     2020Liv        1.0                         0.0   \n",
       "2126   7000    Ka61Kl61        0.0                         0.0   \n",
       "2653   9000      ka1501        1.0                         1.0   \n",
       "2665  22000  Studie1970        1.0                         1.0   \n",
       "2671  24000  Studie1970        1.0                         0.0   \n",
       "\n",
       "                               webcam_label  webcam_fps  webcam_aspectRatio  \\\n",
       "514     Logitech HD Webcam C310 (046d:081b)   30.000000            0.001042   \n",
       "1040              Integrierte iSight-Kamera   30.000030            1.000000   \n",
       "1051              Integrierte iSight-Kamera   30.000030            1.000000   \n",
       "1057              Integrierte iSight-Kamera   30.000030            1.000000   \n",
       "1063  Integrierte iSight-Kamera (05ac:8507)   30.000031            0.002083   \n",
       "1065  Integrierte iSight-Kamera (05ac:8507)   30.000031            0.002083   \n",
       "1075    Logitech HD Webcam C310 (046d:081b)   30.000000            0.001042   \n",
       "1085  Integrierte iSight-Kamera (05ac:8507)   30.000031            0.002083   \n",
       "2126             HD User Facing (04f2:b64f)   30.000000            0.001389   \n",
       "2653             HD User Facing (04f2:b64f)   30.000000            0.001389   \n",
       "2665        FaceTime HD-Kamera (integriert)   29.970000            0.001389   \n",
       "2671        FaceTime HD-Kamera (integriert)   29.970000            0.001389   \n",
       "\n",
       "                                             user_agent     device browser  \\\n",
       "514   Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     WebKit  Chrome   \n",
       "1040  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Safari   \n",
       "1051  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Safari   \n",
       "1057  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Safari   \n",
       "1063  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Chrome   \n",
       "1065  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Chrome   \n",
       "1075  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     WebKit  Chrome   \n",
       "1085  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6...  Macintosh  Chrome   \n",
       "2126  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     WebKit  Chrome   \n",
       "2653  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     WebKit  Chrome   \n",
       "2665  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6...  Macintosh  Safari   \n",
       "2671  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6...  Macintosh  Safari   \n",
       "\n",
       "     browser_version platform platform_version  \n",
       "514    87.0.4280.141  Windows               10  \n",
       "1040          11.1.2     OS X          10_13_6  \n",
       "1051          11.1.2     OS X          10_13_6  \n",
       "1057          11.1.2     OS X          10_13_6  \n",
       "1063   87.0.4280.141     OS X          10_13_6  \n",
       "1065   87.0.4280.141     OS X          10_13_6  \n",
       "1075   87.0.4280.141  Windows               10  \n",
       "1085   87.0.4280.141     OS X          10_13_6  \n",
       "2126   87.0.4280.141  Windows               10  \n",
       "2653   87.0.4280.141  Windows               10  \n",
       "2665          14.0.2     OS X          10_15_6  \n",
       "2671          14.0.2     OS X          10_15_6  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_failedSetups = []\n",
    "for subject in data_raw['run_id'].unique():\n",
    "    maxTrialIndex = data_raw.loc[data_raw['run_id']==subject, ['trial_index']].max()\n",
    "    if int(maxTrialIndex) < 15:\n",
    "        subjects_failedSetups.append(subject)\n",
    "\n",
    "failedSetups = data_raw.loc[\n",
    "    data_raw['run_id'].isin(subjects_failedSetups), \n",
    "    [\n",
    "        'run_id', 'prolificID', 'chinFirst', 'choiceTask_amountLeftFirst',\n",
    "        'webcam_label', 'webcam_fps', 'webcam_aspectRatio',    \n",
    "        'user_agent', 'device', 'browser', 'browser_version', \n",
    "        'platform', 'platform_version', \n",
    "        # 'stimulus', 'trial_type', 'trial_index', 'trial_duration', \n",
    "        # 'et_data'\n",
    "    ]\n",
    "].drop_duplicates()\n",
    "    \n",
    "data_raw = data_raw.loc[~data_raw['run_id'].isin(subjects_failedSetups), :]\n",
    "\n",
    "print(data_raw['run_id'].unique())\n",
    "failedSetups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No EyeTracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>prolificID</th>\n",
       "      <th>chinFirst</th>\n",
       "      <th>choiceTask_amountLeftFirst</th>\n",
       "      <th>webcam_label</th>\n",
       "      <th>webcam_fps</th>\n",
       "      <th>webcam_aspectRatio</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>device</th>\n",
       "      <th>browser</th>\n",
       "      <th>browser_version</th>\n",
       "      <th>platform</th>\n",
       "      <th>platform_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [run_id, prolificID, chinFirst, choiceTask_amountLeftFirst, webcam_label, webcam_fps, webcam_aspectRatio, user_agent, device, browser, browser_version, platform, platform_version]\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_noet_data = []\n",
    "for subject in data_raw['run_id'].unique():\n",
    "    if len(data_raw.loc[data_raw['run_id']==subject, 'et_data'].unique()) < 4:\n",
    "        subjects_noet_data.append(subject)\n",
    "\n",
    "noet_data = data_raw.loc[\n",
    "    data_raw['run_id'].isin(subjects_failedSetups), \n",
    "    [\n",
    "        'run_id', 'prolificID', 'chinFirst', 'choiceTask_amountLeftFirst',\n",
    "        'webcam_label', 'webcam_fps', 'webcam_aspectRatio',    \n",
    "        'user_agent', 'device', 'browser', 'browser_version', \n",
    "        'platform', 'platform_version', \n",
    "        # 'stimulus', 'trial_type', 'trial_index', 'trial_duration', \n",
    "        # 'et_data'\n",
    "    ]\n",
    "].drop_duplicates()\n",
    "    \n",
    "data_raw = data_raw.loc[~data_raw['run_id'].isin(subjects_noet_data), :]\n",
    "\n",
    "noet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 11000, 21000, 3000, 8000, 2], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.run_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty ET trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values that probably represent empty values\n",
      "\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "run_id  chinFirst  task_nr  chin  trial_type            \n",
       "3       0.0        2        1     eyetracking-fix-object     1\n",
       "                   3        1     eyetracking-fix-object    14\n",
       "21      0.0        2        1     eyetracking-fix-object     1\n",
       "                   3        1     eyetracking-choice         2\n",
       "                                  eyetracking-fix-object     1\n",
       "Name: eyeData, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Values that probably represent empty values')\n",
    "for cell in data_raw[\"et_data\"].unique():\n",
    "    if len(cell) < 50:\n",
    "        print(cell)\n",
    "\n",
    "data_raw[\"et_data\"] = data_raw[\"et_data\"].apply(str)\n",
    "\n",
    "if np.invert('emptyETData' in globals()):\n",
    "    emptyETData = data_raw.loc[data_raw['et_data'].str.contains(\"\"\"\\[]}\"\"\"), :] \\\n",
    "        .groupby(['run_id', 'chinFirst', 'task_nr', 'chin', 'trial_type']) \\\n",
    "            ['et_data'].count()\n",
    "\n",
    "data_raw = data_raw.loc[~data_raw['et_data'].str.contains(\"\"\"\\[]}\"\"\"), :]\n",
    "\n",
    "emptyETData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Prolific ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: No duplicate subjects found\n"
     ]
    }
   ],
   "source": [
    "duplicates = data_raw.loc[:, ['prolificID', 'trial_index']].duplicated()\n",
    "duplicateSubjects = data_raw.loc[duplicates, 'run_id'].unique()\n",
    "\n",
    "if len(duplicateSubjects) > 0:\n",
    "    print('! Attention: Duplicate subjects: Check out the following: \\n')\n",
    "    print(duplicateSubjects)\n",
    "else:\n",
    "    print('Success: No duplicate subjects found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "data_raw = convertToNumeric(data_raw, [\n",
    "            'run_id', 'subject', 'chinFirst', 'chin', 'task_nr', 'trial_index', # Int\n",
    "            'key_press', \n",
    "            'x_pos', 'y_pos', 'time_elapsed', 'trial_duration',\n",
    "            'rt',\n",
    "            'window_width', 'window_height', \n",
    "        ]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def addWindowSize(data):\n",
    "    output = data\n",
    "    if \"window_width_max\" in data.columns:\n",
    "        print('window width_max already added')\n",
    "    else:\n",
    "        grouped = data.groupby([\"run_id\", \"subject\"])[\"window_width\", \"window_height\"].max().reset_index()\n",
    "        grouped.columns = [\"run_id\", \"subject\", \"window_width_max\", \"window_height_max\"]\n",
    "        grouped['window_diagonal_max'] = np.sqrt(grouped['window_width_max']**2 + grouped['window_height_max']**2)\n",
    "        output = data.merge(grouped, \n",
    "                            on=['run_id', \"subject\"],\n",
    "                            how='left')\n",
    "    return output\n",
    "\n",
    "data_raw = addWindowSize(data_raw)\n",
    "data_raw['window_diagonal'] = np.sqrt(data_raw['window_width']**2 + \n",
    "                                      data_raw['window_height']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tim', 'ka1501', 'Livaila22', 0, 'Ka61Kl61'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw['prolificID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToDataframe(text):\n",
    "    text = text.replace('$', ',')\n",
    "    dataframe = pd.read_json(text[11:len(text)-1], orient='records')\n",
    "    return(dataframe)\n",
    "\n",
    "def extractEyetrackingData(data):\n",
    "    data_eyetracking = pd.DataFrame(columns=['x', 'y', 't']) \n",
    "    data[\"et_data\"] = data['et_data'].apply(str)\n",
    "    \n",
    "    for i in data.loc[data['et_data'] != '\"', :].index:\n",
    "\n",
    "        df = textToDataframe(data.loc[i, 'et_data']) \\\n",
    "            .rename(columns = {\"relative-x\": \"x\", \n",
    "                               \"relative-y\": 'y', \n",
    "                               'elapse-time': 't'}\n",
    "                   ) \\\n",
    "            .reset_index(drop=True)\n",
    "\n",
    "        df[\"t_task\"] = (df.loc[:, \"t\"] - df.loc[0, \"t\"]) \n",
    "        columnsToAdd = data.columns.drop('et_data')\n",
    "        for col in columnsToAdd:\n",
    "            df[col] = data.loc[i, col]\n",
    "\n",
    "        data_eyetracking = data_eyetracking.append(\n",
    "            pd.DataFrame(data = df), ignore_index=True)  \n",
    "\n",
    "    return(data_eyetracking)\n",
    "\n",
    "data_et = extractEyetrackingData(data_raw)\n",
    "\n",
    "data_et.groupby(['run_id', 'chinFirst', 'task_nr', 'chin', 'trial_type']) \\\n",
    "    ['x'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_et = convertToNumeric(data_et,\n",
    "                        ['x', 'y', 't', 't_task', # Float \n",
    "                         'x_pos', 'y_pos', \n",
    "                         'chinFirst', 'chin', 'key_press'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToFactor(data, columns):\n",
    "    stacked = data[columns].stack()\n",
    "    data[columns] = pd.Series(stacked.factorize()[0], index=stacked.index).unstack()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addXCount(data):\n",
    "    if 'count' in data.columns:\n",
    "        print('Count already added!')\n",
    "    else: \n",
    "        grouped = pd.DataFrame(\n",
    "                data.groupby([\"run_id\", \"trial_index\"])[\"x\"].count()\n",
    "            ) \\\n",
    "            .reset_index() \\\n",
    "            .rename(columns={'x': 'count'})\n",
    "        data = data.merge(grouped, \n",
    "                          on=[\"run_id\", \"trial_index\"], \n",
    "                          how='left')\n",
    "    return(data)\n",
    "\n",
    "data_et = addXCount(data_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMeans(data):\n",
    "    if ('x_mean' in data.columns):\n",
    "        print('X_mean already added!')\n",
    "        data_output = data\n",
    "    elif ('y_mean' in data.columns):\n",
    "        print('Y_mean already added!')\n",
    "        data_output = data\n",
    "    else: \n",
    "        grouped = data.loc[:, ['run_id', 'subject', 'trial_index', 'x', 'y']] \\\n",
    "                             .groupby(['run_id', 'subject', 'trial_index']).mean() \\\n",
    "                             .rename(columns={'x': 'x_mean', \n",
    "                                              'y': 'y_mean'})\n",
    "        data_output = data.merge(grouped,\n",
    "                                 on=['run_id', 'subject', 'trial_index'],\n",
    "                                 how='left')\n",
    "    return data_output\n",
    "\n",
    "data_et = addMeans(data_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(x, x_target, y, y_target):\n",
    "    x_diff = x - x_target\n",
    "    y_diff = y - y_target\n",
    "    euclideanDistance = np.sqrt(x_diff**2 + y_diff**2)\n",
    "    return(euclideanDistance)\n",
    "\n",
    "x_location_pixel = data_et['window_width_max'] * data_et['x_pos']\n",
    "y_location_pixel = data_et['window_height_max'] * data_et['y_pos']\n",
    "data_et[\"offset\"] = euclideanDistance(data_et[\"x\"], x_location_pixel, \n",
    "                                      data_et[\"y\"], y_location_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addPrecision(data):\n",
    "    if 'precision' in data.columns: \n",
    "        print('precision already added!')\n",
    "    else:\n",
    "        data['deviationFromAVG'] = euclideanDistance(\n",
    "                data['x'], data['x_mean'], data['y'], data['y_mean']\n",
    "            )\n",
    "        data['deviationFromAVG_square'] = np.power(data['deviationFromAVG'], 2)\n",
    "        grouped = data.groupby(['run_id', 'trial_index']).mean() \\\n",
    "            .reset_index()\n",
    "        grouped['precision'] = np.sqrt(grouped['deviationFromAVG_square'])\n",
    "        data = data.merge(\n",
    "                grouped.loc[:, ['run_id', 'trial_index', 'precision']], \n",
    "                on=['run_id', 'trial_index'],\n",
    "                how='left'\n",
    "            )\n",
    "                                \n",
    "    return data\n",
    "\n",
    "data_et = addPrecision(data_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def withinTaskIndex(data): \n",
    "    allTrialIndices = []\n",
    "    for subject in data[\"run_id\"].unique():\n",
    "        df_subj = data.loc[data['run_id']==subject, :]\n",
    "        \n",
    "        for trial_type in df_subj['trial_type'].unique():\n",
    "            df_trial = df_subj.loc[df_subj['trial_type']==trial_type, :]\n",
    "                \n",
    "            for task_nr in df_trial[\"task_nr\"].unique():\n",
    "                df_thisTask = df_trial.loc[df_trial['task_nr']==task_nr, \n",
    "                         [\n",
    "                             'run_id',\n",
    "                             'trial_index'\n",
    "                         ]\n",
    "                    ] \\\n",
    "                    .drop_duplicates() \\\n",
    "                    .reset_index(drop=True)\n",
    "        \n",
    "                df_thisTask['withinTaskIndex'] = df_thisTask.index + 1\n",
    "                allTrialIndices.append(df_thisTask)\n",
    "    allTrialIndices = pd.concat(allTrialIndices).reset_index(drop=True)\n",
    "    return allTrialIndices\n",
    "\n",
    "def addWithinTaskIndex(data):\n",
    "    if 'withinTaskIndex' in data.columns: \n",
    "        print('withinTaskIndex already added')\n",
    "    else:\n",
    "        newIndices = withinTaskIndex(data_et) \\\n",
    "            .reset_index(drop=True)\n",
    "        data = data.merge(newIndices, \n",
    "                          on = ['run_id', 'trial_index'], \n",
    "                          how = 'left')\n",
    "    return data\n",
    "\n",
    "data_et = addWithinTaskIndex(data_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(x):\n",
    "    return x*10\n",
    "\n",
    "def positionIndex(data):\n",
    "    allPositionIndices = []\n",
    "    for subject in data[\"run_id\"].unique():\n",
    "        df_subj = data.loc[\n",
    "            (\n",
    "                (data['run_id']==subject) &\n",
    "                (data['trial_type'].isin(\n",
    "                        [\n",
    "                            'eyetracking-calibration', \n",
    "                            'eyetracking-fix-object'\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            ), :]\n",
    "        \n",
    "        for trial_type in df_subj['trial_type'].unique():\n",
    "            df_trial = df_subj.loc[df_subj['trial_type']==trial_type, :]\n",
    "                \n",
    "            for task_nr in df_trial[\"task_nr\"].unique():\n",
    "                df_thisTask = df_trial.loc[\n",
    "                        df_trial['task_nr']==task_nr, \n",
    "                        ['run_id', 'trial_index', 'x_pos', 'y_pos']\n",
    "                    ] \\\n",
    "                    .drop_duplicates() \\\n",
    "                    .reset_index(drop=True)\n",
    "\n",
    "                df_thisTask['positionIndex'] = df_thisTask.loc[:, ['x_pos', 'y_pos']] \\\n",
    "                    .apply(multiply) \\\n",
    "                    .astype(int) \\\n",
    "                    .astype(str) \\\n",
    "                    .apply(''.join, 1)\n",
    "                df_thisTask['positionIndex'] = df_thisTask['positionIndex'].astype(int)\n",
    "                df_thisTask['positionIndex'] = df_thisTask.loc[:, 'positionIndex'] \\\n",
    "                    .replace(\n",
    "                            np.sort(df_thisTask['positionIndex'].unique()), \n",
    "                            range(0, len(df_thisTask['positionIndex'].unique()))\n",
    "                        )        \n",
    "                allPositionIndices.append(df_thisTask)\n",
    "                \n",
    "    allPositionIndices = pd.concat(allPositionIndices).reset_index(drop=True)\n",
    "    return allPositionIndices\n",
    "\n",
    "def addPositionIndex(data):\n",
    "    if 'positionIndex' in data.columns: \n",
    "        print('positionIndex already added')\n",
    "    else:\n",
    "        newIndices = positionIndex(data_et) \\\n",
    "            .reset_index(drop=True)\n",
    "        data = data.merge(newIndices, \n",
    "                          on = ['run_id', 'trial_index', 'x_pos', 'y_pos'], \n",
    "                          how = 'left')\n",
    "    return data\n",
    "\n",
    "data_et = addPositionIndex(data_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_et_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_et_calibration = data_et.loc[data_et[\"trial_type\"]==\"eyetracking-calibration\", :]\n",
    "data_et_calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_et_fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_et_fixation = data_et.loc[(\n",
    "           (data_et[\"trial_type\"]==\"eyetracking-fix-object\") &\n",
    "           (pd.notna(data_et['withinTaskIndex'])) \n",
    "        ), :\n",
    "    ]\n",
    "data_et_fixation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_et_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_et_choice = data_et.loc[(data_et[\"trial_type\"]==\"eyetracking-choice\"), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lookDirections(data):\n",
    "    data[\"look_left\"] = (data[\"x\"] < 0.5).astype(int)\n",
    "    data[\"look_top\"] = (data[\"y\"] < 0.5).astype(int)\n",
    "    return data\n",
    "\n",
    "data_et_choice = lookDirections(data_et_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "data_et_choice.loc[\n",
    "    : , \n",
    "        [\n",
    "          'option_topLeft',\n",
    "          'option_bottomLeft', \n",
    "          'option_topRight', \n",
    "          'option_bottomRight'\n",
    "        ] \n",
    "    ] = data_et_choice.loc[\n",
    "            : , \n",
    "            [\n",
    "              'option_topLeft',\n",
    "              'option_bottomLeft', \n",
    "              'option_topRight', \n",
    "              'option_bottomRight'\n",
    "            ] \n",
    "        ] \\\n",
    "    .replace(['Today', 'Tomorrow', '7 days', '15 days', '30 days', '90 days', '180 days'], \n",
    "             [0, 1, 7, 15, 30, 90, 180]) \\\n",
    "    .replace({'\\$':''}, regex = True) \\\n",
    "    .replace('50 cent', 0.5) \\\n",
    "    .astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addChoiceVariables(data):\n",
    "    data.loc[\n",
    "                (\n",
    "                    (data['choiceTask_amountLeftFirst']==1) &\n",
    "                    (data['withinTaskIndex'] <41)\n",
    "                ), 'amountLeft'] = 1\n",
    "    data.loc[\n",
    "                (\n",
    "                    (data['choiceTask_amountLeftFirst']==0) &\n",
    "                    (data['withinTaskIndex'] >40)\n",
    "                ), 'amountLeft'] = 0\n",
    "\n",
    "    data.loc[data['amountLeft'] == 1, 'aSS'] = \\\n",
    "        data.loc[data['amountLeft'] == 1,[\"option_topLeft\", \"option_bottomLeft\"]].values.min(1)\n",
    "    data.loc[data['amountLeft'] == 0, 'aSS'] = \\\n",
    "        data.loc[data['amountLeft'] == 0,[\"option_topRight\", \"option_bottomRight\"]].values.min(1)\n",
    "\n",
    "    data.loc[data['amountLeft'] == 1, 'aLL'] = \\\n",
    "        data.loc[data['amountLeft'] == 1,[\"option_topLeft\", \"option_bottomLeft\"]].values.max(1)\n",
    "    data.loc[data['amountLeft'] == 0, 'aLL'] = \\\n",
    "        data.loc[data['amountLeft'] == 0,[\"option_topRight\", \"option_bottomRight\"]].values.max(1)\n",
    "\n",
    "    data.loc[:, \"tSS\"] = 0 \n",
    "\n",
    "    data.loc[data['amountLeft'] == 1, 'tLL'] = \\\n",
    "        data.loc[data['amountLeft'] == 1,[\"option_topRight\", \"option_bottomRight\"]].values.max(1)\n",
    "    data.loc[data['amountLeft'] == 0, 'tLL'] = \\\n",
    "        data.loc[data['amountLeft'] == 0,[\"option_topLeft\", \"option_bottomLeft\"]].values.max(1)\n",
    "\n",
    "    data.loc[(data[\"key_press\"]==38), \"choseTop\"] = 1\n",
    "    data.loc[(data[\"key_press\"]==40), \"choseTop\"] = 0\n",
    "\n",
    "    data.loc[data['amountLeft'] == 1, 'tLL'] = \\\n",
    "        data.loc[data['amountLeft'] == 1,[\"option_topRight\", \"option_bottomRight\"]].values.max(1)\n",
    "\n",
    "    data['LL_top'] = (data[\"option_topLeft\"] > data[\"option_bottomLeft\"]).astype(int)\n",
    "\n",
    "    data.loc[\n",
    "        (\n",
    "             (data[\"choseTop\"]==1) & \n",
    "             (data[\"LL_top\"] == 1)\n",
    "        ), \"choseLL\"] = 1\n",
    "    data.loc[\n",
    "        (\n",
    "             (data[\"choseTop\"]==1) & \n",
    "             (data[\"LL_top\"] == 0)\n",
    "        ), \"choseLL\"] = 0\n",
    "\n",
    "    return(data)\n",
    "\n",
    "data_et_choice = addChoiceVariables(data_et_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanETChoice(data):\n",
    "    output = data.loc[(data_et[\"x\"]>-1) & \n",
    "                      (data_et[\"y\"]>-1) & \n",
    "                      (data_et[\"x\"]<data_et['window_width_max']) & \n",
    "                      (data_et[\"y\"]<data_et['window_height_max']), :]\n",
    "    return output\n",
    "# data_et_choice = cleanETChoice(data_et_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_aoi(data, subject, aoi):\n",
    "    aoiCenters = pd.DataFrame([\n",
    "                [(0.05+0.9*0.2), 0.25],\n",
    "                [(0.05+0.9*0.8), 0.25],\n",
    "                [(0.05+0.9*0.2), 0.75],\n",
    "                [(0.05+0.9*0.8), 0.75]\n",
    "            ], \n",
    "            columns = ['x', 'y'], \n",
    "            index=['TL', 'TR', 'BL', 'BR']\n",
    "        )\n",
    "\n",
    "    data.loc[(\n",
    "            (data['run_id'] == subject) & \n",
    "            (data.loc[:, 'x'] > (aoiCenters.loc[aoi, 'x'] - 0.175)) & \\\n",
    "            (data.loc[:, 'x'] < (aoiCenters.loc[aoi, 'x'] + 0.175)) & \\\n",
    "            (data.loc[:, 'y'] > (aoiCenters.loc[aoi, 'y'] - 0.175)) & \\\n",
    "            (data.loc[:, 'y'] < (aoiCenters.loc[aoi, 'y'] + 0.175))\n",
    "        ), 'aoi'] = aoi   \n",
    "    \n",
    "    return data\n",
    "\n",
    "def addAOIs(data):\n",
    "    for subject in data['run_id'].unique(): \n",
    "        for aoi in ['TL', 'TR', 'BL', 'BR']:\n",
    "            data = assign_aoi(data, subject, aoi)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def createAOIColumns(data):\n",
    "    # If amounts are on the left side\n",
    "    # If the gaze point is in the top option\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='TL')), \n",
    "             'aoi_amount_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='TR')), \n",
    "             'aoi_delay_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='BL')), \n",
    "             'aoi_amount_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==1) & (data['aoi']=='BR')), \n",
    "             'aoi_delay_SS'] = 1\n",
    "    \n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='TL')), \n",
    "             'aoi_amount_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='TR')), \n",
    "             'aoi_delay_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='BL')), \n",
    "             'aoi_amount_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==1) & (data['LL_top']==0) & (data['aoi']=='BR')), \n",
    "             'aoi_delay_LL'] = 1\n",
    "    \n",
    "    # If amounts are on the right side\n",
    "    # If the gaze point is in the top option\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='TL')), \n",
    "             'aoi_delay_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='TR')), \n",
    "             'aoi_amount_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='BL')), \n",
    "             'aoi_delay_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==1) & (data['aoi']=='BR')),\n",
    "             'aoi_amount_SS'] = 1\n",
    "\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='TL')), \n",
    "             'aoi_delay_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='TR')), \n",
    "             'aoi_amount_SS'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='BL')), \n",
    "             'aoi_delay_LL'] = 1\n",
    "    data.loc[((data['amountLeft']==0) & (data['LL_top']==0) & (data['aoi']=='BR')), \n",
    "             'aoi_amount_LL'] = 1\n",
    "    return data\n",
    "\n",
    "data_et_choice = addAOIs(data_et_choice)\n",
    "data_et_choice = createAOIColumns(data_et_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition_type(data):\n",
    "    data = data.loc[(pd.notna(data['aoi'])), :]\n",
    "    data['newAOIIndex'] = 0\n",
    "    data.loc[(data['aoi_amount_LL']==1), 'newAOIIndex'] = 1\n",
    "    data.loc[(data['aoi_delay_LL']==1), 'newAOIIndex'] = 2\n",
    "    data.loc[(data['aoi_amount_SS']==1), 'newAOIIndex'] = 4\n",
    "    data.loc[(data['aoi_delay_SS']==1), 'newAOIIndex'] = 8\n",
    "    data.sort_values(by=['run_id', 'withinTaskIndex'])\n",
    "    # Add a 0 due to the way np.diff works\n",
    "    data['transition_type'] = np.append(np.diff(data['newAOIIndex']), [0])\n",
    "    data['transition_type'] = abs(data['transition_type']) \n",
    "    return(data)\n",
    "\n",
    "def cleanTransitions(data):\n",
    "    indices = []\n",
    "    for subject in data['run_id'].unique():\n",
    "        df_subj = data.loc[data['run_id']==subject, :]\n",
    "        for trial in df_subj['withinTaskIndex'].unique():\n",
    "            df_thisTrial = data.loc[(\n",
    "                                    (data['run_id'] == subject) &\n",
    "                                    (data['withinTaskIndex'] == trial)\n",
    "                                ), 'transition_type']\n",
    "            indices.append(df_thisTrial.index.max())\n",
    "    # last gaze point of each trial\n",
    "    data.loc[indices, 'transition_type'] = 0 \n",
    "    return(data)\n",
    "\n",
    "data_et_choice = add_transition_type(data_et_choice)\n",
    "\n",
    "data_et_choice = cleanTransitions(data_et_choice)\n",
    "# View(data_et_choice.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_trial\n",
    "[Back to Navigation](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial = data_raw.loc[\n",
    "    :, \n",
    "    [\n",
    "        'run_id', 'subject', 'chinFirst', 'choiceTask_amountLeftFirst', \n",
    "        'rt', 'stimulus',\n",
    "        'window_width', 'window_height', 'trial_type', 'trial_index',\n",
    "        'time_elapsed', \n",
    "        'webcam_label', 'webcam_Id', 'webcam_fps',\n",
    "        'webcam_aspectRatio', 'webcam_height', 'webcam_width', 'key_press',\n",
    "        'success', 'x_pos', 'y_pos', 'chin', 'task_nr',\n",
    "        'trial_duration', 'option_topLeft', 'option_bottomLeft',\n",
    "        'option_topRight', 'option_bottomRight', 'recorded_at',\n",
    "        'user_agent', 'device', 'browser', 'browser_version', 'platform',\n",
    "        'platform_version', 'bonusAmount', 'bonusDelay',\n",
    "        'prolificID', 'age', 'gender', 'ethnic', 'sight', 'glasses', 'degree',\n",
    "        'eyeshadow', 'masquara', 'eyeliner', 'browliner', 'vertPosition',\n",
    "        'triedChin', 'keptHead', 'optionalNote', 'window_width_max',\n",
    "        'window_height_max', 'window_diagonal_max', 'window_diagonal',\n",
    "        't_startTrial', 'trial_duration_exact'        \n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTimeDeviation(data, column1, column2, maxTimeDiffAllowed):\n",
    "    diff = data[column1] - data['trial_duration_exact']\n",
    "    longtrials_runID = data.loc[diff[diff > maxTimeDiffAllowed].index, 'run_id']\n",
    "    longtrials_previousrunID = pd.DataFrame(data.loc[diff[diff > maxTimeDiffAllowed].index-1, 'run_id']) \\\n",
    "        .rename(columns={'run_id':'previous_run_id'})\n",
    "    longtrials_previousrunID.index = longtrials_runID.index\n",
    "    compare_runIDs = pd.concat([longtrials_runID, longtrials_previousrunID], axis=1)\n",
    "\n",
    "    if sum(compare_runIDs['run_id'] == compare_runIDs['previous_run_id']) > 0: \n",
    "        print(column1 + ' and ' + column2 + ' show a deviation of ' +\n",
    "              '>' + str(maxTimeDiffAllowed) + \n",
    "              ' ms. Please check on the following indices: \\n')\n",
    "        print(compare_runIDs.loc[(compare_runIDs['run_id'] == compare_runIDs['previous_run_id']), :].index)\n",
    "\n",
    "    else:\n",
    "        print('Success! ' + column1 + ' and ' + column2 + ' do not deviate by ' +\n",
    "              '>' + str(maxTimeDiffAllowed) + 'ms.')\n",
    "        \n",
    "def exactTrialDuration(data):\n",
    "    output = data\n",
    "    output[\"t_startTrial\"] = pd.concat([pd.Series([0]), output[\"time_elapsed\"]], ignore_index=True)\n",
    "    output[\"trial_duration_exact\"] = output.loc[:, (\"time_elapsed\")] - output.loc[:, (\"t_startTrial\")]\n",
    "    output.drop(len(output)-1)\n",
    "    \n",
    "    checkTimeDeviation(data, 'rt', 'trial_duration_exact', 50)\n",
    "    checkTimeDeviation(data, 'trial_duration', 'trial_duration_exact', 50)\n",
    "    \n",
    "    return output\n",
    "\n",
    "data_trial = exactTrialDuration(data_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeByTrialIndex(data, largeData, varName):\n",
    "    if (varName in data_trial.columns):\n",
    "        print(varName + ' already added!')\n",
    "    else:\n",
    "        grouped = largeData.loc[:, \n",
    "                               [\n",
    "                                   'run_id', 'trial_index', varName\n",
    "                               ]\n",
    "                           ] \\\n",
    "                    .drop_duplicates()\n",
    "        data = data.merge(grouped, on=['run_id', 'trial_index'], how='left') \n",
    "    return data\n",
    "\n",
    "for column in ['x_mean', 'y_mean', 'count', 'offset', 'precision', 'withinTaskIndex']:\n",
    "    data_trial = mergeByTrialIndex(data_trial, data_et, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial[\"fps\"] = 1000 * data_trial[\"count\"] / data_trial[\"trial_duration_exact\"]\n",
    "data_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_trial_fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial_fixation = data_trial.loc[\n",
    "         (data_trial['trial_type'] == 'eyetracking-fix-object') & \n",
    "         (pd.notna(data_trial['x_pos'])) &\n",
    "         (pd.notna(data_trial['y_pos'])) &\n",
    "         np.invert(data_trial['task_nr'] == 3), \n",
    "    ] \\\n",
    "    .reset_index(drop=True) \n",
    "# View(data_trial_fixation.drop(columns=['et_data']).tail(20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_trial_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial_choice = data_trial.loc[\n",
    "    data_trial[\"trial_type\"] == \"eyetracking-choice\", \n",
    "    [\n",
    "        'run_id', 'chinFirst',\n",
    "        'trial_duration_exact',\n",
    "        'window_width', 'window_height', \n",
    "        'window_width_max', 'window_height_max',\n",
    "        'window_diagonal_max', 'window_diagonal', \n",
    "        \n",
    "        'trial_index',  'withinTaskIndex',\n",
    "        'task_nr',\n",
    "        'time_elapsed',\n",
    "\n",
    "        'choiceTask_amountLeftFirst', \n",
    "        'key_press', \n",
    "        'option_topLeft', 'option_bottomLeft',\n",
    "        'option_topRight', 'option_bottomRight', \n",
    "        'x_mean', 'y_mean', \n",
    "        'count', 'fps'        \n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in [\n",
    "                  'choseTop',\n",
    "                  'LL_top',\n",
    "                  'choseLL',\n",
    "                  'aLL',\n",
    "                  'aSS',\n",
    "                  'tLL',\n",
    "                  'tSS',\n",
    "                  'amountLeft'\n",
    "              ]:\n",
    "    data_trial_choice = mergeByTrialIndex(data_trial_choice, data_et_choice, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addOptionIndex(data):\n",
    "    if \"optionIndex\" in data.columns:\n",
    "        print(\"Option Index already added!\")\n",
    "        data_output = data\n",
    "    else:\n",
    "        grouped = data_et_choice.groupby(['run_id', 'trial_index']) \\\n",
    "            ['aoi', 'aoi_amount_SS', 'aoi_amount_LL', 'aoi_delay_SS', 'aoi_delay_LL'].count() \\\n",
    "            .reset_index() \\\n",
    "            .rename(columns={\"aoi\": \"count\"})\n",
    "        grouped['gazePoints_immediate'] = (grouped['aoi_amount_SS'] + grouped['aoi_delay_SS'])\n",
    "        grouped['gazePoints_delay'] = (grouped['aoi_amount_LL'] + grouped['aoi_delay_LL'])\n",
    "        grouped['optionIndex'] = (grouped['gazePoints_immediate'] - grouped['gazePoints_delay']) / \\\n",
    "                                 (grouped['gazePoints_immediate'] + grouped['gazePoints_delay'])\n",
    "        data_output = data.merge(grouped[['run_id', 'trial_index', 'optionIndex']], \n",
    "                                          on=['run_id', 'trial_index'])\n",
    "    return(data_output)\n",
    "\n",
    "data_trial_choice = addOptionIndex(data_trial_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAttributeIndex(data):\n",
    "    if \"attributeIndex\" in data.columns:\n",
    "        print('Attribute Index already added!')\n",
    "        data_output = data\n",
    "    else:\n",
    "        grouped = data_et_choice.groupby(['run_id', 'trial_index']) \\\n",
    "            ['aoi', 'aoi_amount_SS', 'aoi_amount_LL', 'aoi_delay_SS', 'aoi_delay_LL'].count() \\\n",
    "            .reset_index() \\\n",
    "            .rename(columns={\"aoi\": \"count\"})\n",
    "        grouped['gazePoints_amount'] = (grouped['aoi_amount_LL'] + grouped['aoi_amount_SS'])\n",
    "        grouped['gazePoints_time'] = (grouped['aoi_delay_LL'] + grouped['aoi_delay_SS'])\n",
    "        grouped['attributeIndex'] = (grouped['gazePoints_amount'] - grouped['gazePoints_time']) / \\\n",
    "                                 (grouped['gazePoints_amount'] + grouped['gazePoints_time'])\n",
    "\n",
    "        data_output = data.merge(grouped[['run_id', 'trial_index', 'attributeIndex']], \n",
    "                                          on=['run_id', 'trial_index'])\n",
    "    return(data_output)\n",
    "\n",
    "data_trial_choice = addAttributeIndex(data_trial_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTransition_type(data_trial, data_et):\n",
    "    transition_count = pd.pivot_table(data_et.loc[:, ['run_id', 'trial_index', 'transition_type']], \n",
    "                        index = ['run_id', 'trial_index'],\n",
    "                        columns = ['transition_type'], \n",
    "                        aggfunc = len,\n",
    "                        fill_value = 0\n",
    "                        ).reset_index()\n",
    "    transition_count.columns = ['run_id', 'trial_index', \n",
    "                    \"trans_type_0\",\n",
    "                    \"trans_type_1\",\n",
    "                    \"trans_type_2\",\n",
    "                    \"trans_type_3\",\n",
    "                    \"trans_type_4\",\n",
    "                    \"trans_type_6\",\n",
    "                    \"trans_type_7\"]\n",
    "\n",
    "    if \"trans_type_0\" in data_trial:\n",
    "        print(\"Transitions already added!\")\n",
    "        data_trial = data_trial\n",
    "    else:\n",
    "        data_trial = data_trial.merge(transition_count, on=['run_id', 'trial_index']) \n",
    "    return(data_trial)\n",
    "\n",
    "data_trial_choice = addTransition_type(data_trial_choice, data_et_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPayneIndex(data):\n",
    "    if \"payneIndex\" in data.columns:\n",
    "        print(\"PayneIndex already added!\")\n",
    "    else: \n",
    "        # Option-wise: amount_LL-delay_LL = 1; amount_SS - delay_SS = 4\n",
    "        # Attribute-wise: amount_LL-amount_SS = 3; delay_LL - delay_SS = 6\n",
    "        # Cross: amount_LL-delay_SS = 7; delay_LL - amount_SS = 2\n",
    "        optionWise_transition = data.loc[:, 'trans_type_1'] + data.loc[:, 'trans_type_4']\n",
    "        attributeWise_transition = data.loc[:, 'trans_type_3'] + data.loc[:, 'trans_type_6']  \n",
    "        data['payneIndex'] = (optionWise_transition - attributeWise_transition) / \\\n",
    "            (optionWise_transition + attributeWise_transition)      \n",
    "    return(data)\n",
    "\n",
    "data_trial_choice = addPayneIndex(data_trial_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(aLL, aSS, tLL):\n",
    "    k = ((aLL / aSS) - 1) / tLL\n",
    "    return k\n",
    "\n",
    "data_trial_choice['k'] = k(data_trial_choice['aLL'], data_trial_choice['aSS'], data_trial_choice['tLL']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanChoiceData(data):\n",
    "    output = data.loc[data['trial_duration_exact'] < 10000, :]\n",
    "    return output\n",
    "\n",
    "data_trial_choice = cleanChoiceData(data_trial_choice)\n",
    "# View(data_trial_choice.tail(20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_subject = data_raw.loc[: , \n",
    "          [\n",
    "               'run_id', 'subject', 'chinFirst',\n",
    "               'choiceTask_amountLeftFirst', 'webcam_label', 'webcam_Id', 'webcam_fps',\n",
    "               'webcam_aspectRatio', 'webcam_height', 'webcam_width', \n",
    "               'user_agent', 'device', 'browser',\n",
    "               'browser_version', 'platform', 'platform_version', \n",
    "               'bonusAmount', 'bonusDelay', 'prolificID', 'age',\n",
    "               'gender', 'ethnic', 'sight', 'glasses', 'degree', 'eyeshadow',\n",
    "               'masquara', 'eyeliner', 'browliner', 'vertPosition', 'triedChin',\n",
    "               'keptHead', 'optionalNote', 'window_width_max', 'window_height_max',\n",
    "               'window_diagonal_max'\n",
    "          ]\n",
    "     ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_group_means_by_subject(data, sourceData, varName):\n",
    "    if np.invert(varName in sourceData.columns): \n",
    "        print(varName + ' not in source Data!')\n",
    "    else:\n",
    "        if varName in data.columns:\n",
    "            print(varName + ' already added!')\n",
    "        else:\n",
    "            grouped = sourceData.groupby(['run_id']).mean() \\\n",
    "                .reset_index() \\\n",
    "                .loc[:, ['run_id', varName]]        \n",
    "            data = data.merge(grouped.loc[:, ['run_id', varName]], on=['run_id'], how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\n",
    "    'trial_duration_exact', \n",
    "    't_startTrial', \n",
    "    'window_width', \n",
    "    'window_height',\n",
    "    'fps'\n",
    "               ]:\n",
    "    data_subject = merge_group_means_by_subject(data_subject, data_trial, column)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\n",
    "    'choseLL'\n",
    "               ]:\n",
    "    data_subject = merge_group_means_by_subject(data_subject, data_trial_choice, column)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\n",
    "\n",
    "                   'offset',\n",
    "                   'precision', \n",
    "               ]:\n",
    "    data_subject = merge_group_means_by_subject(data_subject, data_et, column)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data_et_fixation.rename(columns={\n",
    "                                                'x_mean': 'x_mean_fixTask',\n",
    "                                                'y_mean': 'y_mean_fixTask'\n",
    "                                            })  \n",
    "for column in ['x_mean_fixTask', 'y_mean_fixTask']:\n",
    "    data_subject = merge_group_means_by_subject(data_subject, df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "            'chinFirst',\n",
    "            'eyeshadow', \n",
    "            'masquara',\n",
    "            'eyeliner',\n",
    "            'browliner',\n",
    "            'triedChin', \n",
    "            'keptHead',\n",
    "        ]\n",
    "\n",
    "data_subject[columns] = data_subject[columns].replace({'no': 0, 'yes': 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View(data_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data_subject variables to data_trial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_uniques_by_subject(data, sourceData, varName):\n",
    "    if np.invert(varName in sourceData.columns): \n",
    "        print(varName + ' not in source Data!')\n",
    "    else:\n",
    "        if varName in data.columns:\n",
    "            print(varName + ' already added!')\n",
    "        else:\n",
    "            grouped = sourceData.loc[:, \n",
    "                [\n",
    "                    'run_id', varName\n",
    "                ]\n",
    "            ] \\\n",
    "            .reset_index(drop=True) \\\n",
    "            .drop_duplicates()     \n",
    "            data = data.merge(grouped.loc[:, ['run_id', varName]], on=['run_id'], how='left')\n",
    "    return data\n",
    "\n",
    "for column in ['age', 'gender', 'ethnic', 'degree']:\n",
    "    data_trial_choice = merge_uniques_by_subject(data_trial_choice, data_subject, column)\n",
    "data_trial_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data_jupyter'):\n",
    "    os.mkdir('./data_jupyter')\n",
    "\n",
    "data_et.to_csv(\"data_jupyter/data_et.csv\", index=False, header=True)\n",
    "data_et_fixation.to_csv(\"data_jupyter/data_et_fixation.csv\", index=False, header=True)\n",
    "data_et_choice.to_csv(\"data_jupyter/data_et_choice.csv\", index=False, header=True)\n",
    "\n",
    "data_trial.to_csv(\"data_jupyter/data_trial.csv\", index=False, header=True)\n",
    "data_trial_fixation.to_csv(\"data_jupyter/data_trial_fixation.csv\", index=False, header=True)\n",
    "data_trial_choice.to_csv(\"data_jupyter/data_trial_choice.csv\", index=False, header=True)\n",
    "\n",
    "data_subject.to_csv(\"data_jupyter/data_subject.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatLab input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./amasino_dataPrep/data_source'):\n",
    "    os.mkdir('./amasino_dataPrep/data_source')\n",
    "\n",
    "data_et_choice['fixationCounter'] = 1\n",
    "data_et_choice.loc[:, \n",
    "                       [\n",
    "                           'run_id', \n",
    "                           'withinTaskIndex', \n",
    "                           'x', \n",
    "                           'y', \n",
    "                           't_task', \n",
    "                           'window_width', \n",
    "                           'window_height',\n",
    "                       ]\n",
    "                  ] \\\n",
    "   .to_csv(\"amasino_dataPrep/data_source/schneegansEtAl_ET.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial_choice.loc[:, \n",
    "                          [\n",
    "                              'run_id', \n",
    "                              'aSS', \n",
    "                              'aLL', \n",
    "                              'tSS', \n",
    "                              'tLL', \n",
    "                              'choseLL', \n",
    "                              'trial_duration_exact', \n",
    "                              'LL_top',\n",
    "                              'choseTop'\n",
    "                          ]\n",
    "                     ] \\\n",
    "    .to_csv(\"amasino_dataPrep/data_source/schneegansEtAl_behavior.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial_choice.loc[:, \n",
    "                       [\n",
    "                           'run_id', \n",
    "                           'withinTaskIndex', \n",
    "                           'optionIndex', \n",
    "                           'attributeIndex', \n",
    "                           'payneIndex'\n",
    "                       ]\n",
    "                  ] \\\n",
    "    .fillna(0) \\\n",
    "    .to_csv(\"amasino_dataPrep/intermediateCSVs/ET_indices.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subject.loc[:, ['run_id', 'choseLL']] \\\n",
    "    .to_csv(\"amasino_dataPrep/intermediateCSVs/percLeft.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
