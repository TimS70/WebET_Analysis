---
title: "Supplement: Amount and time exert independent influences on intertermporal choice"
output: html_notebook
---
Load packages and set participant exclusions
```{r}
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

getPackages(c('dplyr', 
              "effsize",
              "ggplot2",
              "ggsignif",
              'matlabr',
              'QuantPsyc',
              "RColorBrewer",
              'reshape2',
              'tidyr')
            )
```

# Matlab
Excludes outliers
```{r}
run_matlab_script('amasino_dataPrep/init.m')
```

Load data, make data frames
```{r}
# Data on subject level
data_subject <- read.table('data_jupyter/data_subject.csv', header=TRUE, sep=',')
alllogk<-read.table("amasino_dataPrep/intermediateCSVs/allLogk.csv", header=FALSE, sep=",")
names(alllogk) = c('run_id', 'logK')
data_subject = merge(data_subject, alllogk, by='run_id')

dfET = data_subject %>%
    dplyr::select(optionIndex, attributeIndex, payneIndex, logK)
names(dfET) = c('optInd', 'attInd', 'payneInd', 'logK')

# Data on Trial level
data_trial_choice <- read.table('data_jupyter/data_trial_choice.csv', header=TRUE, sep=',')
subjVals <- read.table("amasino_dataPrep/intermediateCSVs/subjVals.csv", header=FALSE, sep=",")
colnames(subjVals)<-c("run_id", 'svLL', 'svSS', 'svT', 'svB', 'dSV')
data_trial_choice = cbind(data_trial_choice, subjVals[, 2:6])

data_et_choice <- read.table('data_jupyter/data_et_choice.csv', header=TRUE, sep=',')
if ('choseTop' %in% names(data_et_choice))
    {data_et_choice = data_et_choice %>% select(!choseTop)}
data_et_choice = merge(
    data_et_choice, 
    data_trial_choice %>% 
        group_by(run_id, trial_index) %>% 
        summarise(choseTop = mean(choseTop)),
    by=c('run_id', 'trial_index')
)
data_et_choice$lookTopAOI = as.integer(data_et_choice$aoi == 'TL' | data_et_choice$aoi == 'TR')

# rt = data_subject$rt_choice

#Subjective value based on discount rate
percT<-read.table("amasino_dataPrep/intermediateCSVs/SVpropT.csv", header=FALSE, sep=",")
SV_RT<-read.table("amasino_dataPrep/intermediateCSVs/SVrt.csv", header=FALSE, sep=",")
#Melt percT by subject id
percTlong=melt(percT, id.vars=c("V1"))
percTlong$variable=as.integer(percTlong$variable) #get proper x vals
#Melt RT by subject id
SV_RTlong=melt(SV_RT, id.vars=c("V1"))
SV_RTlong$variable=as.integer(SV_RTlong$variable) #get proper x vals
```

# Screening
# Cleaning
see choice_analysis.Rmd

# Bins
Eye tracking bins with average proportion of looking top for each 
subject over trials when they chose the top option (binsT) or the bottom option
(binsB). 
```{r}
cutBin <- function(dataframe, nBins) {
  borders <- seq(0, nrow(dataframe), length=nBins+1)
  output=list()
  for (i in 1:nBins){
    output[[i]] = dataframe[ceiling(borders[i]+1):ceiling(borders[i+1]), ]
    output[[i]]$bin = i
  }
  return(output)
}

addBins <- function(data, nBins) {
    combinedSubjects = list()
    subjects = unique(data$run_id)
    for (i in 1:length(subjects)) {
        maxChoices = data %>% 
            filter(run_id == subjects[i]) %>%
            dplyr::select(withinTaskIndex) %>%
            max
      
        combinedTrials = list()
        for (j in 1:maxChoices) {
            bins = data %>%
                filter(run_id == subjects[i] & withinTaskIndex == j) %>%
                cutBin(nBins)
            combinedTrials[[j]] = bind_rows(bins)
        }
        combinedTrial = bind_rows(combinedTrials)
        combinedSubjects[[i]] = combinedTrials
    }
    combinedSubjects = bind_rows(combinedSubjects)
    combinedSubjects = combinedSubjects %>%
        filter(!is.na(run_id))
    return(combinedSubjects)
}


choseT <- data_et_choice %>%
    filter(choseTop == 1 & !is.na(aoi)) %>%
    addBins(5) %>%
    dplyr::select(run_id, withinTaskIndex, bin, lookTopAOI, choseTop) %>%
    group_by(run_id, choseTop, bin) %>%
    summarise(lookTopAOI=mean(lookTopAOI)) %>%
    spread(bin, lookTopAOI) 

choseB <- data_et_choice %>%
    filter(choseTop == 0 & !is.na(aoi)) %>%
    addBins(5) %>%
    dplyr::select(run_id, withinTaskIndex, bin, lookTopAOI, choseTop) %>%
    group_by(run_id, choseTop, bin) %>%
    summarise(lookTopAOI=mean(lookTopAOI)) %>%
    spread(bin, lookTopAOI) 

choseTBLong <- data_et_choice %>%
    filter(!is.na(aoi)) %>%
    addBins(5) %>%
    dplyr::select(run_id, withinTaskIndex, bin, lookTopAOI, choseTop) %>%
    group_by(run_id, choseTop, bin) %>%
    summarise(lookTopAOI=mean(lookTopAOI))

choseTB<-rbind(choseT,choseB)

```

Proportion of top choice based on the last fixation being to the top
(looksT) or right (looksB)
```{r}
addLastFix <- function(data) {
    if("lastFixTop" %in% colnames(data)){
        cat("LastFixTop already added!\n");
        output = data
    } else {
        combinedSubjects = list()
        subjects = unique(data$run_id)
        for (i in 1:length(subjects)) {
            maxChoices = data %>% 
                filter(run_id == subjects[i]) %>%
                dplyr::select(withinTaskIndex) %>%
                max
          
            combinedTrials = list()
            for (j in 1:maxChoices) {
                thisTrial = data %>%
                    filter(run_id == subjects[i] & withinTaskIndex == j)
                thisTrial$lastFixTop = thisTrial[nrow(thisTrial), 'lookTopAOI']
                combinedTrials[[j]] = thisTrial
            }
            combinedTrial = bind_rows(combinedTrials)
            combinedSubjects[[i]] = combinedTrials
        }
        output = bind_rows(combinedSubjects)
    }
    return(output)
}

data_et_choice = data_et_choice %>%
    addLastFix()

lookT <- data_et_choice %>%
    filter(lastFixTop == 1) %>%
    dplyr::select(run_id, withinTaskIndex, choseTop) %>%
    group_by(run_id, withinTaskIndex) %>%
    summarise(choseTop=mean(choseTop)) %>%
    group_by(run_id) %>%
    summarise(choseTop=mean(choseTop))
lookT

lookB <- data_et_choice %>%
    filter(lastFixTop == 0) %>%
    dplyr::select(run_id, withinTaskIndex, choseTop) %>%
    group_by(run_id, withinTaskIndex) %>%
    summarise(choseTop=mean(choseTop)) %>%
    group_by(run_id) %>%
    summarise(choseTop=mean(choseTop))
lookB

lookTBLong <- data_et_choice %>%
    dplyr::select(run_id, withinTaskIndex, lastFixTop, choseTop) %>%
    group_by(run_id, lastFixTop, withinTaskIndex) %>%
    summarise(choseTop=mean(choseTop)) %>%
    group_by(run_id, lastFixTop) %>%
    summarise(choseTop=mean(choseTop)) %>%
    filter(!(run_id %in% c(12, 93, 2009)))
lookTBLong
lookTBLong %>% group_by(run_id) %>% summarise(n = n()) %>%
  filter(n<2)

```

Error Analyis
```{r}
data_trial_choice$svLLGreatersvSS = as.integer(
    data_trial_choice$svLL > data_trial_choice$svLL)
data_trial_choice$predictTop = as.integer(
        (data_trial_choice$svT > data_trial_choice$svB)    
    )
data_trial_choice$predictLL = as.integer(
        data_trial_choice$predictTop & data_trial_choice$LL_top
    )
data_trial_choice$patientError = as.integer(
    (!data_trial_choice$predictLL & data_trial_choice$choseLL)
)
data_trial_choice$impatientError = as.integer(
    (data_trial_choice$predictLL & !data_trial_choice$choseLL)
)
data_trial_choice$errorTrial = as.integer(
        (data_trial_choice$predictTop != data_trial_choice$choseTop) 
    )
data_trial_choice %>%
    group_by(run_id) %>%
    summarise(errorTrial=sum(errorTrial))

matchCorrectTrials = function(errorTrials, data_subject) {
    errorTrials$closestCorrectTrial = 0 
    for (i in 1:nrow(errorTrials)) {
        if (errorTrials[i, ]$impatientError) {
            correctTrials = data_subject %>%
                filter(!errorTrial & choseLL)
        } else {
            correctTrials = data_subject %>%
                filter(!errorTrial & !choseLL)
        }
        if (nrow(correctTrials) > 0) {
            dSV_difference = abs(correctTrials$dSV-errorTrials[i, ]$dSV)
            dSV_difference
            closestCorrectTrial = correctTrials %>%
                filter(dSV_difference == min(dSV_difference))
            closestCorrectTrial
            errorTrials[i, ]$closestCorrectTrial = closestCorrectTrial$withinTaskIndex
        }
    }
    return(errorTrials)
}

data_subject$inconsistent = 0 
subjects = unique(data_subject$run_id)
## TODO
for (i in 1:length(subjects)) {
    thisSubject = data_trial_choice %>%
        filter(run_id == 16)
    
    errorTrials = thisSubject %>%
        filter(errorTrial == 1) %>%
        dplyr::select(run_id, option_topLeft, option_bottomLeft, svT, svB,
                 choseTop, errorTrial, 
                 dSV, impatientError)

    errorTrials = matchCorrectTrials(errorTrials, thisSubject)
    if (length(unique(errorTrials$closestCorrectTrial)) < 3) {
        data_subject[i, ]$inconsistent = 1 
    }
}
```

```{r}
#Error analysis from the Matlab code
#LL>SS mean SV LL > SV SS, so an error means SS was chosen, correct means LL was chosen. 
#SS>LL means SV SS > SV LL so an error means LL was chosen, correct means SS was chosen.
error<-data.frame(t(read.table("amasino_dataPrep/intermediateCSVs/errorMatrix.csv", header=FALSE, sep=",")))
rownames(error)<-c('SS>LLErrRT','SS>LLCorRT','SS>LLErrOI','SS>LLCorOI','SS>LLErrAI','SS>LLCorAI','SS>LLErrPI','SS>LLCorPI','LL>SSErrRT','LL>SSCorRT','LL>SSErrOI','LL>SSCorOI','LL>SSErrAI','LL>SSCorAI','LL>SSErrPI','LL>SSCorPI')

#Create variable that indexes errors vs. correct responses across types
error$errCorr='Error' 
error$errCorr[c(2,4,6,8,10,12,14,16)]='Correct' 
error$errCorr=as.factor(error$errCorr)

#Create variable that indicates correct answer (LL>SS or SS>LL) across types
error$labels=c('SS>LLRT','SS>LLRT','SS>LLOI','SS>LLOI','SS>LLAI','SS>LLAI','SS>LLPI','SS>LLPI','LL>SSRT','LL>SSRT','LL>SSOI','LL>SSOI','LL>SSAI','LL>SSAI','LL>SSPI','LL>SSPI')
error$labels=factor(error$labels, levels= c('SS>LLRT',  'SS>LLOI', 'SS>LLAI', 'SS>LLPI', 'LL>SSRT', 'LL>SSOI',  'LL>SSAI', 'LL>SSPI'))

errorRT=melt(error[c(1:2,9:10),],id=c("errCorr","labels")) #Response time
errorRT$value=as.numeric(errorRT$value)
errorOI=melt(error[c(3:4,11:12),],id=c("errCorr","labels")) #Option index
errorOI$value=as.numeric(errorOI$value)
errorAI=melt(error[c(5:6,13:14),],id=c("errCorr","labels")) #Attribute index
errorAI$value=as.numeric(errorAI$value)
errorPI=melt(error[c(7:8,15:16),],id=c("errCorr","labels")) #Payne index
errorPI$value=as.numeric(errorPI$value)

choiceSide<-data.frame(read.table("amasino_dataPrep/intermediateCSVs/percLeft.csv", header=FALSE, sep=","))
colnames(choiceSide)<-c("run_id", "sideProp")

numErrs<- read.table("amasino_dataPrep/intermediateCSVs/numErrs.csv", header = FALSE, sep=",")
colnames(numErrs)<-c("errors")
```

Histogram of log(k)
```{r}
ggplot(dfET, aes(x=logK))+
  geom_histogram(binwidth=.5, alpha=.5,position="identity")+
  scale_fill_manual(values=c("palegreen","cornflowerblue"), name="") +
  theme_bw()+theme(text=element_text(size=40))
  ggsave("plots/logk_hist.pdf", width=5.5, height=5)
```

Manipulation checks of prop left responses, RTs, fixations for SV L - SV R
```{r}
#Percent choices by difference in SV 
#Replication sample (T/B)
ggplot(data=percTlong, aes(x=variable, y=value))+ theme_bw()+
    geom_line(color='grey',alpha=.2, aes(group=as.numeric(V1)))+xlim(-10,10)+
    geom_line(stat="summary", fun.y="mean", size=.5)+
    stat_summary(fun.data=mean_se, geom="errorbar", width=.8)+
    xlab("SV top - SV bottom")+ylab("Proportion left choices")+
    theme(text=element_text(size=20))+ylim(0,1)
ggsave("plots/SV_TB.pdf", width=5.5, height=5)

#RT by difference in SV
 
#Replication sample (T/B)
ggplot(data=SV_RTlong, aes(x=variable, y=value)) +
    geom_line(color='grey',alpha=.2, aes(group=as.numeric(V1)))+xlim(-10,10)+
    geom_line(stat="summary", fun.y="mean", size=.5)+theme_bw()+
    stat_summary(fun.data=mean_se, geom="errorbar", width=.8)+
    xlab("SV top - SV bottom") + ylab("Response Time (s)")+
    theme(text=element_text(size=20))+ylim(0,6.5)
ggsave("plots/RT_TB.pdf",width=5.5, height=5)
```

Manipulation checks of eye tracking in time bins
```{r}

choseT$choseTop = as.factor(choseT$choseTop)
class(choseT$choseTop)

for (i in 3:7) {
    tTest = t.test(choseT[[i]], choseB[[i]], paired=TRUE)
    print(tTest)
}
cohen.d(as.numeric(choseT[[3]]),as.numeric(choseB[[3]]),pooled=TRUE,paired=TRUE)
```


```{r}
choseTBLong$choseTop = as.factor(choseTBLong$choseTop)
choseTBLong$bin = as.factor(choseTBLong$bin)

#Violin plot of time bins
ggplot(choseTBLong, aes(x=bin, y=lookTopAOI, fill=choseTop))+
  geom_violin(alpha=.7, size=0, position="dodge")+
  stat_summary(fun=mean,geom="point",shape=45,size=10, position=position_dodge(.9), aes(color=choseTop))+
  scale_colour_manual(values=c(1, 2), name="", labels=c("Chose top", "Chose bottom"))+
  geom_text(x=1, y=1.01, label="")+ annotate("segment",x=0.7, xend=1.3, y=1, yend=1)+
  geom_text(x=2, y=1.01, label="")+ annotate("segment",x=1.7, xend=2.3, y=1, yend=1)+
  geom_text(x=3, y=1.01, label="")+ annotate("segment",x=2.7, xend=3.3, y=1, yend=1)+
  geom_text(x=4, y=1.01, label="")+ annotate("segment",x=3.7, xend=4.3, y=1, yend=1)+
  geom_text(x=5, y=1.01, label="")+ annotate("segment",x=4.7, xend=5.3, y=1, yend=1)+
  scale_fill_grey(start=.3, end=.7, name="",labels=c("Chose top", "Chose bottom")) +
  xlab("Time bins") + ylab("Proportion looking top") +
  theme_bw()+theme(text=element_text(size=20), legend.position="bottom")
ggsave("plots/ET_TB.pdf",width=5.5, height=5)

#Violin plot last fixation location

lookTBLong$lastFixTop = as.factor(lookTBLong$lastFixTop)
t.test(choseTop ~ lastFixTop, data=lookTBLong, paired=TRUE) 
  #Already adjusted for ET exclusions 
cohen.d(choseTop ~ lastFixTop, data=lookTBLong, paired=TRUE, pooled=TRUE)
meanT<- lookTBLong %>%
    filter(lastFixTop == 1) %>%
    dplyr::select(choseTop) %>%
    mean()

ggplot(lookTBLong, aes(x=lastFixTop,y=choseTop))+
    geom_violin(fill="gray", size=0)+
    stat_summary(fun.y=mean,geom="point",shape=45,size=10, color="white")+
    geom_text(x=1.5, y=1.02, label="***")+ 
    annotate("segment",x=1, xend=2, y=1.01, yend=1.01)+
    theme_bw()+ylim(0,1.03)+xlab("") + 
    ylab("Proportion top choices") +
    xlab("last Fixation on Top AOIs") + 
    theme(text=element_text(size=20))
ggsave("plots/ET_look_TB.pdf",width=5.5, height=5)
```

Correlation between Option Index and discount rate k
```{r}
# correlationPlot <- function(data, xVar, yVar, xName, yName) {
#     data$xVar <- data[, xVar]
#     data$yVar <- data[, yVar]
#     
#     ggplot(data, aes(x=xVar, y=yVar)) +
#         theme_bw()+xlim(-1,1)+ylim(-10,0) +
#         scale_colour_grey(start=.1, end=.6) +
#         scale_shape_manual(values=c(16,17)) +
#         theme(text=element_text(size=20), legend.position = "none") +
#         xlab(xName) +
#         ylab(yName) 
# }

ggplot(dfET, aes(x=optInd, y=logK)) +
    theme_bw()+xlim(-1,1)+ylim(-10,0) +
    scale_colour_grey(start=.1, end=.6) +
    scale_shape_manual(values=c(16,17)) +
    theme(text=element_text(size=20), legend.position = "none") +
    xlab('Option Index') +
    ylab('Log(k)') 
ggsave('plots/opt_logk.pdf',width=5.7, height=5)

cor.test(dfET$optInd,dfET$logK) 
```

Correlation of Attribute index and Payne index
```{r}
#Replication sample
ggplot(dfET, aes(x=attInd, y=payneInd)) +
    geom_point(size=2.5, alpha=.5)+
    guides(alpha=FALSE)+ theme_bw()+xlim(-1,1)+
    scale_colour_grey()+ylim(-1,1)+
    theme(text=element_text(size=20))+
    xlab("Attribute index") + ylab("Payne index") 
ggsave("plots/att_payne.pdf",width=5.7, height=5)

cor.test(dfET$payneInd,dfET$attInd) 
```

Correlation of Eye tracking indices and discount rate
```{r}
#Plot correlation between attribute index and discount rate (k-val)
ggplot(dfET, aes(x=attInd, y=logK)) +
  geom_point(size=2.5, aes(alpha=.5))+
  guides(alpha=FALSE,color=FALSE, shape=FALSE)+
  theme_bw()+xlim(-1,1)+
  scale_colour_grey()+ylim(-10,0)+
  theme(text=element_text(size=20))+
  xlab("Attribute index") + ylab("log(k)") 
ggsave("plots/logk_att.pdf",width=5.7, height=5)
cor.test(dfET$attInd,dfET$logK) 

#Plot correlation between Payne index and discount rate
#Replication sample
ggplot(dfET, aes(x=payneInd, y=logK)) +
  geom_point(size=2.5, aes(alpha=.5))+
  guides(alpha=FALSE,color=FALSE, shape=FALSE)+
  theme_bw()+xlim(-1,1)+
  scale_colour_grey()+ylim(-10,0)+
  theme(text=element_text(size=20))+
  xlab("Payne index") +
  ylab("log(k)") 
ggsave("plots/logk_payne.pdf",width=5.7, height=5)
cor.test(dfET$payneInd,dfET$logK) 
```

Supplementary Figure 12 Error analysis
```{r}
#Response time error analysis

t.test(errorRT$value[errorRT$errCorr=="Error" & errorRT$labels=="SS>LLRT"], errorRT$value[errorRT$errCorr=="Correct" & errorRT$labels=="SS>LLRT"],paired=TRUE, na.action=na.pass) #SS>LL error vs. correct response time
t.test(errorRT$value[errorRT$errCorr=="Error" & errorRT$labels=="LL>SSRT"], errorRT$value[errorRT$errCorr=="Correct" & errorRT$labels=="LL>SSRT"],paired=TRUE, na.action=na.pass) #LL>SS error vs. correct response time
cohen.d(errorRT$value[errorRT$labels=="LL>SSRT"],errorRT$errCorr[errorRT$labels=="LL>SSRT"],pooled=TRUE,na.rm=TRUE, paired=TRUE) #Effect size for response time difference

ggplot(errorRT, aes(x=labels,y=value, fill=errCorr))+
  geom_violin(alpha=.6, size=0,position=position_dodge(0))+
  stat_summary(fun.data="mean_se",geom="linerange",aes(color=errCorr),alpha=1,size=1.5)+
  stat_summary(fun=mean, geom="line",aes(group=errCorr, color=errCorr),size=1.5)+
  geom_text(x=2, y=7.4, label="***",size=10)+ coord_cartesian(ylim=c(0,7.5))+
  theme_bw()+theme(text=element_text(size=20))+
  scale_x_discrete(labels=c("SS>LL", "LL>SS"))+
  xlab("Choices")+ylab("Response Time (s)")+labs(fill="",color="")+
  guides(size="none")+scale_colour_grey()+scale_fill_grey()
ggsave("plots/errRT.pdf",width=6.5, height=5)

#Option index analysis
#Replication sample
t.test(errorOI$value[errorOI$errCorr=="Error" & errorOI$labels=="SS>LLOI"], errorOI$value[errorOI$errCorr=="Correct" & errorOI$labels=="SS>LLOI"],paired=TRUE, na.action=na.pass) #SS>LL error vs. correct option index
cohen.d(errorOI$value[errorOI$labels=="SS>LLOI"],errorOI$errCorr[errorOI$labels=="SS>LLOI"],pooled=TRUE,na.rm=TRUE, paired=TRUE) #Effect size
t.test(errorOI$value[errorOI$errCorr=="Error" & errorOI$labels=="LL>SSOI"], errorOI$value[errorOI$errCorr=="Correct" & errorOI$labels=="LL>SSOI"],paired=TRUE, na.action=na.pass) #LL>SS error vs. correct option index
cohen.d(errorOI$value[errorOI$labels=="LL>SSOI"],errorOI$errCorr[errorOI$labels=="LL>SSOI"],pooled=TRUE,na.rm=TRUE, paired=TRUE)

ggplot(errorOI, aes(x=labels,y=value, fill=errCorr))+
  geom_violin(alpha=.6, size=0,position=position_dodge(0))+
  stat_summary(fun.data="mean_se",geom="linerange",aes(color=errCorr),alpha=1,size=1.5)+
  stat_summary(fun.y=mean, geom="line",aes(group=errCorr, color=errCorr),size=1.5)+
  geom_text(x=1, y=.9, label="***",size=10)+ geom_text(x=2, y=.9, label="***",size=10)+ 
  coord_cartesian(ylim=c(-1,1))+ scale_colour_grey()+scale_fill_grey()+
  theme_bw()+theme(text=element_text(size=20))+scale_x_discrete(labels=c("SS>LL", "LL>SS"))+ xlab("Choices")+ylab("Option Index")+
  labs(fill="",color="")+guides(size="none")
ggsave("plots/errOI.pdf",width=6.5, height=5)

#Attribute index analysis
#Replication sample
t.test(errorAI$value[errorAI$errCorr=="Error" & errorAI$labels=="SS>LLAI"], errorAI$value[errorAI$errCorr=="Correct" & errorAI$labels=="SS>LLAI"],paired=TRUE, na.action=na.pass) #SS>LL error vs. correct attribute index
t.test(errorAI$value[errorAI$errCorr=="Error" & errorAI$labels=="LL>SSAI"], errorAI$value[errorAI$errCorr=="Correct" & errorAI$labels=="LL>SSAI"],paired=TRUE, na.action=na.pass) #LL>SS error vs. correct attribute index

#Payne index analysis
#Replication sample
t.test(errorPI$value[errorPI$errCorr=="Error" & errorPI$labels=="SS>LLPI"], errorPI$value[errorPI$errCorr=="Correct" & errorPI$labels=="SS>LLPI"],paired=TRUE, na.action=na.pass) #SS>LL error vs. correct Payne index
t.test(errorPI$value[errorPI$errCorr=="Error" & errorPI$labels=="LL>SSPI"], errorPI$value[errorPI$errCorr=="Correct" & errorPI$labels=="LL>SSPI"],paired=TRUE, na.action=na.pass) #LL>SS error vs. correct Payne index
```

Supplementary Figure 13: Histogram of left/right and top/bottom choice distribution
```{r}
#Replication sample
ggplot(data=choiceSide,aes(x=sideProp))+
  geom_histogram(bins=15)+theme_bw()+xlab("Proportion Top Choices")+
  theme(text=element_text(size=20))+xlim(0,1)
ggsave("plots/choiceSide.pdf",width=5.5, height=5)
```
