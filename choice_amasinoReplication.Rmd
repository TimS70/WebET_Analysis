---
title: 'Supplement: Amount and time exert independent influences on intertermporal
  choice'
output:
  html_document:
    df_print: paged
---

```{r}
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

getPackages(c('plyr',
              'dplyr', 
              
              "effsize",
              'e1071',
              "ggplot2",
              "ggsignif",
              'matlabr',
              'QuantPsyc',
              "RColorBrewer",
              'reshape2',
              'tidyr')
            )
```
```{r echo=FALSE}
# https://stackoverflow.com/a/45614547
GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, draw_group = function(self, data, ..., draw_quantiles = NULL){
  data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
  grp <- data[1,'group']
  newdata <- plyr::arrange(transform(data, x = if(grp%%2==1) xminv else xmaxv), if(grp%%2==1) y else -y)
  newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
  newdata[c(1,nrow(newdata)-1,nrow(newdata)), 'x'] <- round(newdata[1, 'x']) 
  if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
    stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <= 
                                              1))
    quantiles <- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
    aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
    aesthetics$alpha <- rep(1, nrow(quantiles))
    both <- cbind(quantiles, aesthetics)
    quantile_grob <- GeomPath$draw_panel(both, ...)
    ggplot2:::ggname("geom_split_violin", grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
  }
  else {
    ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
  }
})

geom_split_violin <- function (mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}
```

# Read and create datasets

## data_subject
```{r}
data_subject <- read.table('data_jupyter/data_subject.csv', 
                           header=TRUE, sep=',')
data_subject

data_trial <- read.table('data_jupyter/data_trial_choice.csv',
                                header=TRUE, sep=',')
data_trial

data_et <- read.table('data_jupyter/data_et_choice.csv', 
                             header=TRUE, sep=',')
grouped = data_trial %>% 
      dplyr::group_by(run_id, trial_index) %>% 
      dplyr::summarise(choseTop = mean(choseTop))
if ('choseTop' %in% names(data_et))
    {data_et = data_et %>% select(!choseTop)}
data_et = merge(data_et, grouped, by=c('run_id', 'trial_index'))
data_et$lookTopAOI = as.integer(data_et$aoi == 'TL' | data_et$aoi == 'TR')
data_et
```

## k-values
K values and noise
```{r}
merge_mean_by_subject = function(data, data_source, varName) {
    grouped = data_source %>%
        dplyr::group_by(run_id) %>%
        dplyr::summarise(varName = mean(varName))
      
    if (varName %in% names(data)) {
        data = data %>% dplyr::select(!varName)
    }

    data = merge(
        data, 
        data_source %>% dplyr::select(run_id, varName), 
        by='run_id')
    return(data)
}

run_matlab_script('fitK/fit_discount_k.m')
logK <- read.table('fitK/logK.csv', header=TRUE, sep=',')
data_subject = merge_mean_by_subject(data_subject, logK, 'logK')
data_subject = merge_mean_by_subject(data_subject, logK, 'noise')

data_trial = merge_mean_by_subject(data_trial, logK, 'noise')
data_trial = merge_mean_by_subject(data_trial, logK, 'logK')

data_subject %>%
    dplyr::select(run_id, logK, noise)
```

# Screening

## Distribution of k-values
````{r}
ggplot(data_subject, aes(x=logK))+
    geom_histogram(binwidth=.5, alpha=.5, position="identity")+
    scale_fill_manual(values=c("palegreen","cornflowerblue"), name="") +
    theme_bw()+theme(text=element_text(size=40))
    ggsave("plots/logk_hist.pdf", width=5.5, height=5)
    
ggplot(data_subject, aes(x=noise))+
    geom_histogram(binwidth=5, alpha=.5, position="identity")+
    scale_fill_manual(values=c("palegreen","cornflowerblue"), name="") +
    theme_bw()+theme(text=element_text(size=40))
    ggsave("plots/logk_hist.pdf", width=5.5, height=5)
    
ggplot(data_subject, aes(x=logK, y=noise)) +
    geom_point(size=2.5, aes(alpha=.5))+
    guides(alpha=FALSE,color=FALSE, shape=FALSE)+
    theme_bw() + 
    scale_colour_grey() + 
    theme(text=element_text(size=20)) +
    xlab("logK") + ylab("neg_logLikelihood") +
    ggtitle('logK vs. noise') 
````

````{r}
subjects_biasedChoices = data_subject %>%
    filter(
        choseLL>0.99 | choseLL<0.01 |
        choseTop>0.99 | choseTop<0.01     
          ) %>%
    arrange(run_id) %>%
    dplyr::pull(run_id)
subjects_biasedChoices
```

```{r}
subjects_missingLogK = data_subject %>%
    filter(is.na(logK)) %>%
    arrange(run_id) %>%
    dplyr::pull(run_id)
subjects_missingLogK
```
# High noise
```{r}
subjects_noisyK = data_subject %>%
    filter(noise>10) %>%
    arrange(run_id) %>%
    dplyr::pull(run_id)
subjects_noisyK
```
Trials with too much missing data for Option Index
```{r}
grouped_NA_ET = data_trial %>%
    group_by(run_id) %>%
    summarise(fps = mean(fps),
              n_NA_OI = sum(is.na(optionIndex)),
              n_NA_AI = sum(is.na(attributeIndex)),
              n_NA_PI = sum(is.na(payneIndex))) %>%
    arrange(n_NA_OI, n_NA_AI, n_NA_PI)
grouped_NA_ET

subjects_NA_OI = grouped_NA_ET %>%
    filter(n_NA_OI>40) %>%
    dplyr::pull(run_id)

subjects_NA_AI = grouped_NA_ET %>%
    filter(n_NA_AI>40) %>%
    dplyr::pull(run_id)

subjects_NA_PI = grouped_NA_ET %>%
    filter(n_NA_PI>40) %>%
    dplyr::pull(run_id)
```

# Cleaning
```{r}
excludeSubjects <- read.table('data_jupyter/excludeSubjects_choice.csv', 
                           header=TRUE, sep=',')[, 1]
excludeSubjects = c(
    excludeSubjects,
    subjects_biasedChoices,
    subjects_missingLogK
)
excludeSubjects
```

```{r}
generalCleaninng = function(data) {
    data = data %>%
        filter(
            run_id < 1000 & 
            !(run_id %in% excludeSubjects)
                )
}

data_subject = generalCleaninng(data_subject)
data_trial = generalCleaninng(data_trial)
data_et = generalCleaninng(data_et)

print(paste('Number of subjects: ', length(unique(data_trial$run_id))))
```


# Histogram of left/right and top/bottom choice distribution
```{r}
#Replication sample
ggplot(data_subject, aes(x=choseTop))+
  geom_histogram(bins=15)+theme_bw()+xlab("Proportion Top Choices")+
  theme(text=element_text(size=20))+xlim(0,1)
ggsave("plots/choiceSide.pdf",width=5.5, height=5)
```

# Discount rate k (logK)

Histogram of log(k)
```{r}
ggplot(data_subject, aes(x=logK))+
  geom_histogram(binwidth=.5, alpha=.5, position="identity")+
  scale_fill_manual(values=c("palegreen","cornflowerblue"), name="") +
  theme_bw()+theme(text=element_text(size=40))
  ggsave("plots/logk_hist.pdf", width=5.5, height=5)
```
# Subjective value 
## Subjective value for top and bottom options
```{r}
subjectiveValues = function(data) {
    data$svLL = data$aLL / (1 + exp(data$logK) * data$tLL)
    data$svSS = data$aSS / (1 + exp(data$logK) * data$tSS)
    data$dSV_LLSS = data$svLL - data$svSS
    
    data$svT = data$aT / (1+ exp(data$logK) * data$tT)
    data$svB = data$aB / (1+ exp(data$logK) * data$tB)
    data$dSV_TB = data$svT - data$svB
    
    return(data)
}

data_trial = merge_mean_by_subject(data_trial, data_subject, 'logK')
data_trial = merge_mean_by_subject(data_trial, logK, 'noise')
data_trial = subjectiveValues(data_trial)


data_trial %>%
    dplyr::select(run_id, aT, tT, svT, aB, tB, svB, dSV_TB, choseTop) %>%
    mutate(across(c('svT', 'svB', 'dSV_TB'), round, 2)) %>%
    arrange(dSV_TB)
```

## choseTop by dSV bins
```{r}
data_trial$dSV_bin = 
    cut(data_trial$dSV_TB,
    breaks = seq(-5, 5, 1),
    labels = seq(-4.5, 4.5, 1),
    include.lowest=TRUE) %>%
    paste() %>%
    as.numeric()

SV_bins = data_trial %>%
    dplyr::group_by(run_id, dSV_bin) %>%
    dplyr::summarise(
        n=n(),
        logK = mean(logK),
        noise = mean(noise),
        choseTop=mean(choseTop), 
        rt=mean(trial_duration_exact)/1000, 
        count=mean(x_count)) %>%
    arrange(dSV_bin)
SV_bins

print(
    paste(
        'Remaining subjects: ', 
        SV_bins %>% 
            dplyr::pull(run_id) %>%
            unique() %>%
            length()
    )
)

ggplot(data=SV_bins, aes(x=dSV_bin, y=choseTop)) + 
    theme_bw() +
    geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
    xlim(-5,5) +
    geom_line(stat="summary", fun="mean", size=.5)+
    stat_summary(fun.data=mean_se, geom="errorbar", width=.8)+
    xlab("SV top - SV bottom")+ylab("Proportion top choices")+
    theme(text=element_text(size=20))+ylim(0,1)
ggsave("plots/SV_choseTop.pdf", width=5.5, height=5)

ggplot(data=SV_bins, aes(x=dSV_bin, y=rt)) +
    geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
    xlim(-5,5) + ylim(0, 6.5) +
    geom_line(stat="summary", fun.y="mean", size=.5) +
    stat_summary(fun.data=mean_se, geom="errorbar", width=.8) +
    xlab("SV top - SV bottom") + 
    ylab("Response Time (s)") +
    theme(text=element_text(size=20))
ggsave("plots/SV_RT.pdf",width=5.5, height=5)

ggplot(data=SV_bins, aes(x=dSV_bin, y=count)) +
    geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
    xlim(-5,5) + ylim(0,20) + 
    geom_line(stat="summary", fun.y="mean", size=.5) +
    stat_summary(fun.data=mean_se, geom="errorbar", width=.8) +
    xlab("SV top - SV bottom") + 
    ylab("Number of Fixations") +
    theme(text=element_text(size=20))
ggsave("plots/SV_Count.pdf",width=5.5, height=5)
```

## Correlation of Eye tracking indices and discount rate
```{r}
ggplot(data_subject %>% filter(!run_id %in% subjects_NA_OI), 
       aes(x=optionIndex, y=logK)) +
  geom_point(size=2.5, aes(alpha=.5)) +
  guides(alpha=FALSE,color=FALSE, shape=FALSE) +
  theme_bw() + 
  xlim(-1,1) +
  theme(text=element_text(size=20))+
  xlab("Option index") +
  ylab("log(k)") + 
  scale_colour_grey()
ggsave('plots/opt_logk.pdf',width=5.7, height=5)

data_test = data_subject %>% filter(!run_id %in% subjects_NA_OI)
cor.test(data_test$optionIndex, data_test$logK) 

ggplot(data_subject %>% filter(!run_id %in% subjects_NA_AI), 
       aes(x=attributeIndex, y=logK)) +
  geom_point(size=2.5, aes(alpha=.5))+
  guides(alpha=FALSE,color=FALSE, shape=FALSE)+
  theme_bw() + 
  xlim(-1,1) +
  scale_colour_grey()
  theme(text=element_text(size=20))+
  xlab("Attribute index") + ylab("log(k)") 
ggsave("plots/logk_attributeIndex.pdf",width=5.7, height=5)

data_test = data_subject %>% filter(!run_id %in% subjects_NA_AI)
cor.test(data_test$attributeIndex, data_test$logK) 

#Plot correlation between Payne index and discount rate
#Replication sample
ggplot(data_subject %>% filter(!run_id %in% subjects_NA_AI), 
       aes(x=payneIndex, y=logK)) +
  geom_point(size=2.5, aes(alpha=.5))+
  guides(alpha=FALSE,color=FALSE, shape=FALSE)+
  theme_bw() + 
  xlim(-1,1) + 
  scale_colour_grey() + 
  theme(text=element_text(size=20))+
  xlab("Payne index") +
  ylab("log(k)") 
ggsave("plots/logk_payneIndex.pdf",width=5.7, height=5)

data_test = data_subject %>% filter(!run_id %in% subjects_NA_PI)
cor.test(data_test$payneIndex, data_test$logK) 
```

### Trial bins
Little variance across the trials but this could also be due to the lower sample size
```{r}
plot_trial_bins = function(data, nBins, title) {
    data = data %>%
        mutate(trial_bin = cut(withinTaskIndex, nBins, include.lowest=TRUE, labels=c(1:nBins)))
    
    grouped_choseLL = data %>% 
        group_by(run_id, trial_bin) %>%
        summarise(choseLL = mean(choseLL))
    
    grouped_trialMeans = data %>%
        group_by(trial_bin) %>%
        summarise(trialMeans = mean(withinTaskIndex))
    
    trial_bins = merge(grouped_choseLL, grouped_trialMeans, by='trial_bin')
    trial_bins
    
    ggplot(
        data=trial_bins, 
        aes(x=trialMeans, y=choseLL)) + 
        theme_bw() +
        geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
        xlim(0, 80) +
        geom_line(stat="summary", fun="mean", size=.5)+
        stat_summary(fun.data=mean_se, geom="errorbar", width=.8)+
        xlab("Trial_index") + 
        ylab("Proportion LL choices") + 
        ggtitle(title) +
        theme(text=element_text(size=20))+ylim(0,1)
}

plot_trial_bins(data_trial, 8, "ChoseLL across trials")
```


## Correlation of Attribute index and Payne index
```{r}
#Replication sample
data_plot = data_subject %>% 
    filter(!run_id %in% c(subjects_NA_AI, subjects_NA_OI))
ggplot(data_plot, aes(x=attributeIndex, y=payneIndex)) +
    geom_point(size=2.5, alpha=.5)+
    guides(alpha=FALSE)+ theme_bw()+xlim(-1,1)+
    scale_colour_grey()+ylim(-1,1)+
    theme(text=element_text(size=20))+
    xlab("Attribute index") + ylab("Payne index") 
ggsave("plots/att_payne.pdf",width=5.7, height=5)

cor.test(data_plot$payneIndex, data_plot$attributeIndex) 
```


# Eye Tracking Bins
Eye tracking bins with average proportion of looking top for each 
subject over trials when they chose the top option or the bottom option.

## Exclude null AOI
```{r}
subjects_highFPS = data_subject %>%
    filter(fps>10) %>%
    arrange(run_id) %>%
    dplyr::pull(run_id)

timeBins_choseTB_long <- data_et %>%
    filter(!is.na(aoi) & aoi!=0 &
           run_id %in% subjects_highFPS) %>%
    ET_bins(5) %>%
    mutate(
        lookTop = as.numeric(aoi %in% c('TL', 'TR')), 
        lookBottom = as.numeric(aoi %in% c('BL', 'BR'))) %>%
    dplyr::group_by(run_id, choseTop, timeBin) %>%
    dplyr::summarise(
        n = n(),
        n_lookTop = sum(lookTop),
        n_lookBottom = sum(lookBottom),    
        p_lookTop = sum(lookTop)/n,
        p_lookBottom = sum(lookBottom)/n) %>%
    arrange(choseTop)
timeBins_choseTB_long 

timeBins_choseTB_long %>%
    group_by(run_id, choseTop) %>%
    summarise(n=length(unique(timeBin))) %>%
    filter(n<5)

subjects_not_enough_bins = timeBins_choseTB_long %>%
    group_by(run_id, choseTop) %>%
    summarise(n=length(unique(timeBin))) %>%
    filter(n<5) %>%
    dplyr::pull(run_id)

timeBins_choseTB_long %>%
    filter(timeBin %in% c(4, 5)) %>%
    dplyr::group_by(timeBin, choseTop) %>%
    dplyr::summarise(p_lookTop = mean(p_lookTop))
#Violin plot of time bins

timeBins_choseTB_long$choseTop = as.factor(timeBins_choseTB_long$choseTop)

for (bin in unique(timeBins_choseTB_long$timeBin)) {
    print(t.test(p_lookTop ~ choseTop, 
                 data=timeBins_choseTB_long %>% 
                     filter(timeBin==bin &
                            !(run_id %in% subjects_not_enough_bins)), 
                 paired=TRUE))
}

plot_aoi_across_time = function(
    data, yVar, title='AOI across timeBins') {
    
    plot = ggplot(
        data, 
        aes(x=factor(timeBin), y=yVar, fill=factor(choseTop, c('1', '0')))) +
        geom_split_violin(alpha=.7, size=1, position="dodge") +
        stat_summary(
            fun=mean, geom="point",
            shape=45,size=10,
            position=position_dodge(.9), 
            aes(color=factor(choseTop, c('1', '0')))) +
        theme_bw() + 
        theme(text=element_text(size=20), 
        legend.position="bottom") +
        ggtitle(title) +
        scale_colour_manual(
            values=c("1"="black", "0"="white"), 
            name="", 
            labels=c("Chose Top", "Chose Bottom")) +
        scale_fill_grey(
            start=.3, end=.7, name="",
            labels=c("Chose Top", "Chose Bottom"))
                  # If significant
    print(plot)
}
 
timeBins_choseTB_long %>%
    plot_aoi_across_time(timeBins_choseTB_long$p_lookTop, 'p_lookTop')
```

## Include null AOI: Proportion of looking top, looking bottom, and no aoi across time 
```{r}
df = data_et %>%
    filter(run_id %in% subjects_highFPS) %>%
    mutate(
    lookTop = as.numeric(aoi %in% c('TL', 'TR')), 
    lookBottom = as.numeric(aoi %in% c('BL', 'BR'))) %>%
    group_by(run_id, choseTop, timeBin) %>%
    summarise(
        n = n(),
        n_nullAOI = sum(aoi==0),
        n_lookTop = sum(lookTop),
        n_lookBottom = sum(lookBottom),
        p_nullAOI = n_nullAOI/n,
        p_lookTop = sum(lookTop)/n,
        p_lookBottom = sum(lookBottom)/n) %>%
    mutate(choseTop = factor(choseTop),
           timeBin = factor(timeBin))
df
df %>%
    group_by(timeBin, choseTop) %>%
    summarise(
        p_lookTop = mean(p_lookTop),
        p_lookBottom = mean(p_lookBottom),
        p_nullAOI = mean(p_nullAOI)) %>%
    arrange(choseTop, timeBin)


df %>%
    plot_aoi_across_time(df$p_lookTop, 'p_lookTop')

df %>%
    plot_aoi_across_time(df$p_lookBottom, 'p_lookBottom')

df %>%
    plot_aoi_across_time(df$p_nullAOI, 'p_nullAOI')

```

# Last fixation: Proportion of top choice 
```{r}
add_lastGazeTop = function(data_trial, data_et) {
    grouped_lastCoordinate = data_et %>%
        dplyr::group_by(run_id, trial_index) %>%
        dplyr::summarise(
            t_task = max(t_task)) %>%
        merge(data_et %>% 
                  dplyr::select(run_id, trial_index, t_task, aoi), 
              by=c('run_id', 'trial_index', 't_task')) %>%
        mutate(lastGazeTop = as.numeric(aoi %in% c('TL', 'TR')))
    grouped_lastCoordinate
    
    if ('lastGazeTop' %in% names(data_trial)) {
        data_trial = data_trial %>% dplyr::select(!lastGazeTop)}
    data_trial = data_trial %>% 
        merge(
            grouped_lastCoordinate %>% 
                dplyr::select(run_id, trial_index, lastGazeTop), 
            by=c('run_id', 'trial_index'))
    return(data_trial)
}

data_trial = add_lastGazeTop(data_trial, data_et)
data_trial %>%
    dplyr::select(run_id, trial_index, choseTop, lastGazeTop)
```

```{r}
lastGaze_long <- data_trial %>%
    dplyr::select(run_id, withinTaskIndex, lastGazeTop, choseTop) %>%
    dplyr::group_by(run_id, lastGazeTop, withinTaskIndex) %>%
    dplyr::summarise(choseTop=mean(choseTop)) %>%
    dplyr::group_by(run_id, lastGazeTop) %>%
    dplyr::summarise(
        n=n(),
        choseTop=mean(choseTop)) 
lastGaze_long

lastGaze_long$lastGazeTop = factor(lastGaze_long$lastGazeTop, c('1', '0'))
t.test(choseTop ~ lastGazeTop,
       data=lastGaze_long, 
       paired=TRUE)
```

```{r}
ggplot(lastGaze_long, aes(x=lastGazeTop, y=choseTop)) +
    geom_violin(fill="gray", size=0) +
    stat_summary(fun=mean,geom="point",shape=45,size=10, color="white") +
    geom_text(x=1.5, y=1.02, label="***") + 
    annotate("segment",x=1, xend=2, y=1.01, yend=1.01) +
    theme_bw()+ylim(0,1.03)+xlab("") + 
    ylab("Proportion top choices") +
    xlab("last Fixation on Top AOIs") + 
    theme(text=element_text(size=20))
ggsave("plots/LastGaze_vs_choice.pdf",width=5.5, height=5)
```

# Error Analyis
Error trials are those that are not predicted based on the subjective values, 
which themselves are based on individual's fitted k value

## Find Error trials
```{r}
identify_error_trials = function(data) {
    data$predictLL = as.integer(data$svLL > data$svSS)
    data$errorTrial = as.integer((data$choseLL != data$predictLL))
    data$patientError = as.integer((data$choseLL & !data$predictLL))
    data$impatientError = as.integer((!data$choseLL & data$predictLL))
    return(data)
}

data_trial = identify_error_trials(data_trial)

data_trial %>% 
    dplyr::select(svLL, svSS, predictLL, choseLL, 
                  errorTrial, patientError, impatientError)
   
data_trial %>%
    dplyr::group_by(run_id) %>%
    dplyr::summarise(choseLL = mean(choseLL), errorTrial=sum(errorTrial))
```


## Find Correct trial for each Error trial
````{r}
matchTrials = function(data) {
    data$matched_trial=0
    for (i in 1:nrow(data)) {
        if (data[i, ]$errorTrial) {
            if (data[i, ]$impatientError) {
                correctTrials = data %>% 
                    filter(
                        run_id==data[i, ]$run_id & 
                        !errorTrial & choseLL) %>%
                    dplyr::select(run_id, withinTaskIndex, dSV_LLSS)
                
            } 
            if (data[i, ]$patientError) {
                correctTrials = data %>% 
                    filter(
                        run_id==data[i, ]$run_id & 
                        !errorTrial & !choseLL) %>%
                    dplyr::select(run_id, withinTaskIndex, dSV_LLSS)
            }
        # If it is an error trial  
            
            if (nrow(correctTrials) > 0) {
                correctTrials$dSV_difference = 
                    abs(correctTrials$dSV_LLSS - data[i, ]$dSV_LLSS)
            
                matched_trials = correctTrials %>%
                    filter(dSV_difference == 
                                min(correctTrials$dSV_difference)) %>%
                    dplyr::pull(withinTaskIndex)
            
                data[i, ]$matched_trial = matched_trials[1]
                
                if (length(matched_trials)>1) {
                    already_matched = data %>% 
                        filter(run_id==data[i, ]$run_id) %>%
                        dplyr::pull(matched_trial)
                  
                    for (j in 1:length(matched_trials)) {
                        if (!(matched_trials[j] %in% already_matched)) {
                            data[i, ]$matched_trial = matched_trials[j]
                        }
                    }
                }
            }
        }
    }
    return(data)
}
data_trial = matchTrials(data_trial)

data_trial %>% 
#    filter(errorTrial==1) %>%
    dplyr::select(errorTrial, patientError, 
                  impatientError, matched_trial)

````

## ET indices and reaction time for error trials
Do subjects behave differently when they correctly choose LL (as expected) than when they unexpectedly chose SS instead?

### Group by LL or SS expected
```{r}
data_trial = data_trial %>%
    mutate(LLexpected = as.numeric(svLL > svSS))
data_trial %>%
    dplyr:: select(svLL, svSS, LLexpected)
```


### Filter those subjects with matched error and correct trials
````{r}
subjects_LLcorrect = data_trial %>%
    filter(LLexpected==1) %>%
    dplyr::group_by(run_id) %>%
    dplyr::summarise(n_unique_matched = length(unique(matched_trial))) %>%
    filter(n_unique_matched>2) %>%
    dplyr::pull(run_id)
subjects_LLcorrect
length(subjects_LLcorrect)

subjects_SScorrect = data_trial %>%
    filter(LLexpected==0) %>%
    dplyr::group_by(run_id) %>%
    dplyr::summarise(n_unique_matched = length(unique(matched_trial))) %>%
    filter(n_unique_matched>2) %>%
    dplyr::pull(run_id)
subjects_SScorrect
length(subjects_SScorrect)
```


Dianna found differences reaction time and option index

### group_by(LLexpected, run_id, errorTrial)
```{r}
grouped = data_trial %>%
    filter(
        (LLexpected==1 & run_id %in% subjects_LLcorrect) |
        (LLexpected==0 & run_id %in% subjects_SScorrect)) %>%
    dplyr::group_by(LLexpected, run_id, errorTrial) %>%
    dplyr::summarise(n = n(), 
              rt = mean(trial_duration_exact), 
              optionIndex = mean(optionIndex), 
              attributeIndex = mean(attributeIndex),
              payneIndex = mean(payneIndex)) %>%
    mutate(
        errorTrial = factor(errorTrial),
        rt = rt/1000)
grouped  
```

## t-test LL expected 
Do subjects behave differently when they correctly choose LL (as expected) than when they unexpectedly chose SS instead?
`````{r}
t.test(rt ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==1),
       paired=TRUE, na.action=na.pass)

t.test(optionIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==1 & !run_id %in% subjects_NA_OI),
       paired=TRUE, na.action=na.pass)

t.test(attributeIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==1 & !run_id %in% subjects_NA_AI),
       paired=TRUE, na.action=na.pass)

t.test(payneIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==1 & !run_id %in% subjects_NA_PI),
       paired=TRUE, na.action=na.pass)
````


## SS expected 
Do subjects behave differently when they correctly choose SS (as expected) than when they unexpectedly chose LL instead?
````{r}
t.test(rt ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==0),
       paired=TRUE, na.action=na.pass)

t.test(optionIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==0 & !run_id %in% subjects_NA_OI),
       paired=TRUE, na.action=na.pass)

t.test(attributeIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==0 & !run_id %in% subjects_NA_AI),
       paired=TRUE, na.action=na.pass)

t.test(payneIndex ~ errorTrial,
       data=grouped %>% filter(
           LLexpected==0 & !run_id %in% subjects_NA_PI),
       paired=TRUE, na.action=na.pass)
```


```{r}
data_plot = grouped %>%
    mutate(
        errorTrial = mapvalues(
            factor(errorTrial), 
            from = c(0, 1), 
            to = c("Correct", "Error")),
        LLexpected = factor(LLexpected)
        )


ggplot(data_plot, aes(x=LLexpected, y=rt, fill=errorTrial)) +
  geom_split_violin(alpha=.6, size=0, position=position_dodge(0)) +
  stat_summary(
      fun.data="mean_se",
      geom="linerange",
      aes(color=errorTrial),
      alpha=1,
      size=1.5) +
  stat_summary(
      fun=mean, 
      geom="line",
      aes(group=errorTrial, color=errorTrial), 
      size=1.5) +
  # geom_text(x=2, y=7.4, label="***",size=10) + 
  coord_cartesian(ylim=c(0,7.5)) +
  theme_bw() + 
  theme(text=element_text(size=20)) +
  scale_x_discrete(labels=c("SS>LL", "LL>SS")) +
  xlab("Choices") + ylab("Response Time (s)") + 
  labs(fill="",color="")+
  guides(size="none") + 
  scale_colour_grey() + scale_fill_grey()
ggsave("plots/error_responseTime.pdf",width=6.5, height=5)
```

```{r}
ggplot(
    data_plot %>% filter(
        !run_id %in% subjects_NA_OI), 
       aes(x=LLexpected, y=optionIndex, fill=errorTrial)) +
  geom_split_violin(alpha=.6, size=0, position=position_dodge(0)) +
  stat_summary(
      fun.data="mean_se",
      geom="linerange",
      aes(color=errorTrial),
      alpha=1,
      size=1.5) +
  stat_summary(
      fun=mean, 
      geom="line",
      aes(group=errorTrial, color=errorTrial), 
      size=1.5) +
  # geom_text(x=2, y=7.4, label="***",size=10) + 
  coord_cartesian(ylim=c(-2.5, 2.5)) +
  theme_bw() + 
  theme(text=element_text(size=20)) +
  scale_x_discrete(labels=c("SS>LL", "LL>SS")) +
  xlab("Choices") + ylab("Option Index") + 
  labs(fill="",color="")+
  guides(size="none") + 
  scale_colour_grey() + scale_fill_grey()
ggsave("plots/error_optionIndex.pdf",width=6.5, height=5)
```