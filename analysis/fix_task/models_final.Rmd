---
title: "Fixation task Regression Analysis -- Offset"
author: "Tim Schneegans"
date: "28th of January 2021"
output: html_document
---

# Setup
```{r, setup, message=FALSE, warning=FALSE}
root = "C:/Users/User/GitHub/WebET_Analysis"
path_results = file.path(root, 'results', 'plots', 'fix_task')

knitr::opts_knit$set(root.dir = normalizePath(file.path('..', '..')))

knitr::opts_knit$get("root.dir")

source(file.path(root, 'utils', 'r', 'geom_split_violin.R'))
source(file.path(root, 'utils', 'r', 'merge_by_subject.R'))
source(file.path(root, 'utils', 'r', 'merge_by_index.R'))
source(file.path(root, 'utils', 'r', 'summarize_datasets.R'))
source(file.path(root, 'utils', 'r', 'get_packages.R'))
source(file.path(root, 'utils', 'r', 'remove_runs.R'))
source(file.path(root, 'utils', 'r', 'add_log_k.R'))
source(file.path(root, 'utils', 'r', 'remove_na_et_indices.R'))
source(file.path(root, 'utils', 'r', 'add_x_count.R'))

get_packages(c( 'boot',
			    'broom',
			    'car',
			    'compiler',
			    'data.table',
			    'DHARMa',
			    'GGally',
			    'HLMdiag',
			    'Hmisc',
			    'influence.ME', 
			    "ICC",
			    "knitr",
			    'lme4',
			    'lattice',
			    'lme4',
			    "lmerTest", # Erhalte p-Werte
			    'nlme', 
			    'parallel',
				'pixiedust',
				'reshape',
			    'reshape2',
			    "rsq",
			    'tidyverse',
			    "tinytex"))
```


# Prep datasets
```{r}
path = file.path(root, 'data', 'fix_task', 'added_var')

data_subject = read.csv(file.path(path, 'data_subject.csv'))
data_trial = read.csv(file.path(path, 'data_trial.csv'))
data_et = read.csv(file.path(path, 'data_et.csv'))

summarize_datasets(data_et, data_trial, data_subject)
```


```{r}
data_trial = merge_by_subject(data_trial, data_subject, 'window')

data_trial = data_trial %>%
    mutate(y_pos_c = recode(y_pos, '0.2'=(-1L), '0.5'=0L, '0.8'=1L),
    	   x_pos_c = recode(x_pos, '0.2'=(-1L), '0.5'=0L, '0.8'=1L),
    	   fps_c = scale(fps),
    	   window_c = scale(window))
```

# MLA

## 3) Offset
Control variables, such as age and withinTaskIndex do not show a correlation. 
Predictors: attributeIndex + optionIndex + payneIndex
 - Effect of the Option Index: Odds for choseLL increase by the factor exp(-0.97)=0.38. The more gaze points on immediate options, the lower the odd for choseLL
 - Effect of the Payne Index: Odds for choseLL increase by the factor exp(-0.17)=0.84. The more transitions within options (positive payne), the lower the odd for chose LL
 - Did not try to get the procentual reduction of L1 and L2 variance because the logistic regression does not have error terms

```{r}
data_trial$offset_100 = data_trial$offset * 100

glmer_control = lmer(
    offset_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c +
    	(1 | run_id),
    data=data_trial,
    REML=FALSE)

glmer_experimental = lmer(
    offset_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 | run_id), 
    data=data_trial,
    REML=FALSE)

glmer_rs = lmer(
    offset_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 + chin | run_id), 
    data=data_trial,
    REML=FALSE)

anova(glmer_control, glmer_experimental, glmer_rs)

summary(glmer_experimental)
summary(glmer_rs)
confint(glmer_rs, method="boot", n=500)
```


## Hit mean
```{r}
data_trial = merge_by_subject(data_trial, data_subject, 'age')
data_trial$age = scale(data_trial$age)

data_trial$hit_mean_100 = data_trial$hit_mean * 100

glmer_control = lmer(
    hit_mean_100 ~ withinTaskIndex + age + x_pos_c + y_pos_c + window_c + fps_c +
    	(1 | run_id),
    data=data_trial,
    REML=FALSE)

glmer_experimental = lmer(
    hit_mean_100 ~ withinTaskIndex + age  + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 | run_id), 
    data=data_trial,
    REML=FALSE)

glmer_rs = lmer(
    hit_mean_100 ~ withinTaskIndex + age  + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 + chin | run_id), 
    data=data_trial,
    REML=FALSE)


anova(glmer_control, glmer_experimental, glmer_rs)

summary(glmer_rs)
# confint(glmer_rs, method="boot", n=500)
```

## Precision
```{r}
data_trial$precision_100 = data_trial$precision * 100

glmer_control = lmer(
    precision_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c +
    	(1 | run_id),
    data=data_trial,
    REML=FALSE)

glmer_experimental = lmer(
    precision_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 | run_id), 
    data=data_trial,
    REML=FALSE)

glmer_rs = lmer(
    precision_100 ~ withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c + 
    	chin + glasses_binary + 
    	(1 + chin | run_id), 
    data=data_trial,
    REML=FALSE)

anova(glmer_control, glmer_experimental, glmer_rs)

summary(glmer_experimental)
summary(glmer_rs)
confint(glmer_rs, method="boot", n=500)
```


## Search for cross-level interactions
```{r}
data_trial = merge_by_subject(data_trial, data_subject, 'age')
data_trial$age = scale(data_trial$age)

glmer_cross = lmer(
    hit_mean_100 ~ withinTaskIndex + x_pos_c + y_pos_c + fps_c + window_c +
    	fps_c * chin + glasses_binary + 
    	(1 + chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(glmer_cross)

glmer_cross = lmer(
    hit_mean_100 ~ withinTaskIndex + x_pos_c + fps_c + window_c +
    	y_pos_c * chin + glasses_binary + 
    	(1 + chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(glmer_cross)

```
## Effects
Use formulas without random slopes (Snijders & Bosker, 2012)
```{r}
m0 <- lmer(offset ~ (1 | run_id),
           data=data_trial,
           REML=FALSE)
m1 <- lmer(offset ~ withinTaskIndex + (1 | run_id),
           data=data_trial,
           REML=FALSE)

L1_m0 <- sigma(m0)^2 # L1-Residualvarianz RIO Modell
L1_m1 <- sigma(m1)^2 # L1-Residualvarianz RI Modell
print('Pseudo R^2')
print(paste(
    'Reduction of L1 variance due to chin: ',
    (L1_m0 - L1_m1)/L1_m0
))

L2_m0 <- unlist(summary(m0)$var) # Interceptvarianz RI Modell
L2_m1 <- unlist(summary(m1)$var) # Interceptvarianz IAO Modell
print(paste(
    'Reduction of L2 variance due to chin: ',
    (L2_m0 - L2_m1)/L2_m0
))

```


## Assumptions
Sources: 
 - https://www.youtube.com/watch?v=UvyxSqEXBwc
 - https://www.pythonfordatascience.org/mixed-effects-regression-python/
 - https://ademos.people.uic.edu/Chapter18.html
 
### Linearity: Plot residuals vs. observed
```{r}
plot(resid(glmer_final), data_trial$offset)
```

### Homosedasticity: Homogeneity of residuals across groups
ANOVA as a variation of Levene's test. Extract residuals from the model and square the absolute value. Should be not significant. Significant differences across residuals. We have Heteroscedasticity.
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(glmer_final),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(glmer_final)
```

### Normal distribution of residuals
Normal distribution not given. 
```{r}
qqmath(lmer4_rs, id=0.05)
```

Lets try with log transformed offset
Does not make it any better
```{r}
data_trial = data_trial %>%
    mutate(
        offset_log = log(offset+1),
        offset_log10 = log10(offset+1),
        offset_sqrt = sqrt(offset),
        )

lmer_log = lmer(
    offset_log ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_log)
# ranef(lmer_log)
qqmath(lmer_log, id=0.05, prep_global_data='log transformed offset')

lmer_log10 = lmer(
    offset_log10 ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_log10)
# ranef(lmer_log10)
qqmath(lmer_log10, id=0.05, prep_global_data='log10 transformed offset')

lmer_sqrt = lmer(
    offset_sqrt ~ y_pos_c + chin + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer_sqrt)
# ranef(lmer_sqrt)
qqmath(lmer_sqrt, id=0.05, prep_global_data='sqrt transformed offset')

```

### Residuals for sqrt transformation
Does not look better
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(lmer_sqrt),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(lmer_sqrt)
```

### Multicollinearity of the predictors
No multicollinearity
```{r}
predictors = c('withinTaskIndex', 'chin', 'glasses_binary')

correlation = cor(
    data_trial %>% 
        dplyr::select(predictors),
    use = 'pairwise.complete.obs'
)

symnum(correlation)
correlation

car::vif(lmer4_rs)
```

### HLMdiag
https://cran.rstudio.com/web/packages/HLMdiag/index.html
```{r}
#case_delete() #iteratively delete groups corresponding to the levels of a hierarchical linear model, using lmer to fit the models for each deleted case

#covratio() #calculate measures of the change in the covariance matrices for the fixed effects based on the deletion of an observation, or group of observations,

#diagnostics() #is used to compute deletion diagnostics for a hierarchical linear model based on the building blocks returned by case_delete.

#HLMresid() #extracts residuals from a hierarchical linear model fit using lmer. Can provide a variety of different types of residuals based upon the specifications when you call the function

#leverage() #calculates the leverage of a hierarchical linear model fit

#mdffits() #calculate measures of the change in the fixed effects estimates based on the deletetion of an observation, or group of observations
```


# Linear model (Fixed Effects, no MLA)
Average offset=0.17 = 17%
```{r}
lm_null = lm(offset ~ 1, data = data_trial %>% filter(!is.na(offset)))
summary(lm_null)

lm_sub_0_control = lm(offset ~ window + fps + age + ethnic, 
					  data = data_subject)

summary(lm_sub_0_control)

lm_sub_1 = lm(offset ~ window + fps + age + ethnic + glasses_binary,
			  data = data_subject)
summary(lm_sub_1)
anova(lm_sub_0_control, lm_sub_1)
```

