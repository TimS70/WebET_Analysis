---
title: "Fixation task Regression Analysis -- Precision"
author: "Tim Schneegans"
date: "28th of January 2021"
output: html_document
---

# Setup
```{r}
root = "C:/Users/User/GitHub/WebET_Analysis"
path_results = file.path(root, 'results', 'plots', 'fix_task')

knitr::opts_knit$set(root.dir = normalizePath(file.path('..', '..')))

knitr::opts_knit$get("root.dir")

source(file.path(root, 'utils', 'r', 'geom_split_violin.R'))
source(file.path(root, 'utils', 'r', 'merge_mean_by_subject.R'))
source(file.path(root, 'utils', 'r', 'merge_by_subject.R'))
source(file.path(root, 'utils', 'r', 'summarize_datasets.R'))
source(file.path(root, 'utils', 'r', 'get_packages.R'))
source(file.path(root, 'utils', 'r', 'remove_runs.R'))
source(file.path(root, 'utils', 'r', 'add_log_k.R'))
source(file.path(root, 'utils', 'r', 'remove_na_et_indices.R'))
source(file.path(root, 'utils', 'r', 'add_x_count.R'))

get_packages(c( 'boot',
			    'broom',
			    'car',
			    'compiler',
			    'data.table',
			    'DHARMa',
			    "dplyr",
			    'GGally',
			    'ggplot2',
			    'HLMdiag',
			    'Hmisc',
			    'influence.ME', 
			    "ICC",
			    "knitr",
			    'lme4',
			    'lattice',
			    'lme4',
			    "lmerTest", # Erhalte p-Werte
			    'nlme', 
			    'parallel',
			    'readr',
			    'reshape',
			    'reshape2',
			    "rsq",
			    'tidyverse',
			    "tinytex"))
```


# Read and create datasets
```{r}
data_subject = read.csv(
    file.path(root, 'data', 'fix_task', 'added_var', 
              'data_subject.csv'))

data_trial = read.csv(
    file.path(root, 'data', 'fix_task', 'added_var', 
              'data_trial_fix.csv'))

data_et = read.csv(
    file.path(root, 'data', 'fix_task', 'added_var', 'data_et_fix.csv'))

summarize_datasets(data_et, data_trial, data_subject)
```

## Add variables 
```{r}
# Relevel ethnic
data_subject$ethnic = factor(
	data_subject$ethnic,
	levels = c("caucasian", "hispanic", "asian", "black"), # Faktorstufen
	labels = c("caucasian", "hispanic", "asian", "black"))

# Window
grouped = data_trial %>%
	group_by(run_id) %>%
	dplyr::summarise(
		window_diagonal = mean(window_diagonal_max),
		.groups='keep')
if ('window_diagonal' %in% names(data_subject)) {
        data_subject = data_subject %>% dplyr::select(!'window_diagonal')
    }
data_subject = merge(data_subject, grouped, by='run_id')

data_trial = merge_by_subject(data_trial, data_subject, 'age')
```


# Screening & Cleaning 
Happens in Jupyter Notebook fix_variables_and_analysis.ipynb

## Visualize offset variance 
We need two more requirements to our data:
1) at least three trials with a valid option index
2) 40% of the trials have valid ET indices
```{r}
data_trial = add_x_count(data_trial, data_et)
	
grouped = data_trial %>% 
    group_by(run_id) %>%
    dplyr::summarise(
        n = n(),
        mean = mean(precision),
        sd = sd(precision),
        .groups='keep') %>%
	mutate(sem = sd / sqrt(n)) %>%
    arrange(run_id, mean)
grouped %>% head(5)

ggplot(grouped, aes(factor(run_id), mean)) + 
    geom_pointrange(aes(ymin=mean-1.96*sem, 
                        ymax=mean+1.96*sem)) +
    xlab('run_id') +
    ylab('Offset') + 
    theme(
        axis.text.x = element_blank(),
        ) +
    coord_cartesian(ylim=c(0, 1))

dir.create(file.path(path_results, 'MLA'))
ggsave(file.path(path_results, 'MLA', 'runs_vs_precision.pdf'), 
	   width=5.5, height=5)
```


## ANOVA
```{r, anova}
summary(aov(data_subject$precision ~ data_subject$gender))
summary(aov(data_subject$precision ~ data_subject$degree))
summary(aov(data_subject$precision ~ data_subject$ethnic))
```

# Linear model (Fixed Effects, no MLA)
Average precision=0.07 = 7%. No effect of glasses
```{r}
lm_null = lm(precision ~ 1, data = data_trial %>% filter(!is.na(precision)))
summary(lm_null)

lm_sub_0_control = lm(precision ~ window_diagonal + fps + age + ethnic, 
					  data = data_subject)
summary(lm_sub_0_control)

# Selecting significant control variables
lm_sub_1_control = lm(precision ~ ethnic, data = data_subject)

lm_sub_2_exp = lm(precision ~ glasses_binary, data = data_subject)
summary(lm_sub_2_exp)
anova(lm_sub_1_control, lm_sub_2_exp)
```


# MLA 
## 1) Emtpy Model (intercept only)
ICC = 0.47. 47% of the variance can be explained by the variance between the subjects. Interdependence assumption of the simple linear regression is violated. We should to an MLA
```{r}
lmer0_io = lmer(
    precision ~ 1 + (1 | run_id), 
    data=data_trial,
    REML=FALSE) # FML for comparing different fixed effects

summary(lmer0_io)

ICCest(factor(data_trial$run_id), data_trial$precision, alpha=.05, CI.type="THD")
```



## 2) Intermediate models

### Control variables
Control for the fact that the subjects start at different places regarding the accuracy of the eyetracking data. Standard error has increased. Subjects vary by about 0.12 (Jan 24) around the intercept. The RI model is way better than the IO model. Therefore, we should do an MLM.
```{r}
data_trial = data_trial %>%
    mutate(
        y_pos_c = scale(y_pos),
        x_pos_c = scale(x_pos),
        fps_c = scale(fps),
        window_c = scale(window_diagonal),
        age_c = scale(age))

lmer1_control = lmer(
    precision ~  withinTaskIndex + x_pos_c + y_pos_c + window_c + fps_c + 
    	age_c + (1 | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer1_control)

lmer2_control = lmer(
    precision ~  withinTaskIndex + y_pos_c + (1 | run_id), 
    data=data_trial,
    REML=FALSE)

anova(lmer0_io, lmer2_control)
```


### Random intercept (with experimental variables)
lmer2_control is to be preferred
```{r}
lmer3_experimental = lmer(
    precision ~ withinTaskIndex + y_pos_c + glasses_binary + chin + 
    	(1 | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer3_experimental)

lmer4_experimental = lmer(
    precision ~ withinTaskIndex + y_pos_c + chin + 
    	(1 | run_id), 
    data=data_trial,
    REML=FALSE)

summary(lmer4_experimental)

anova(lmer2_control, lmer3_experimental, lmer4_experimental)
```

## Random slopes
 - lmer4_rs is to be preferred
 - Random effects for chin rest and glasses are large. Participants vary a lot around the average score. Probably another variable. 
 - (Unfortunately), the RS-model is the better model, so the effect of chin-rest largely varies.
 - Do not forget to look at the correlations among the random effects
```{r}
lmer4_rs = lmer(
    precision ~ withinTaskIndex + y_pos_c + chin + glasses_binary + 
    	(chin + glasses_binary | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer4_rs)
confint(lmer4_rs, method="boot", n=50)
# ranef(lmer4_rs)
anova(lmer2_control, lmer4_rs)
```


### Intercepts as outcomes
 - Focus on chin
 - Can precision differences be predicted by fps? 
 - L2 predictor fps is centered by an unweighted mean. 
 - No evidence for an effect of subject's computation power on the outcome.
```{r}
# Get average 
grouped = data_trial %>%
    group_by(run_id) %>%
    dplyr::summarise(
    	fps_subject = mean(fps),
    	.groups = 'keep')
data_trial = data_trial %>%
    merge_by_subject(grouped, 'fps_subject') %>%
    mutate(fps_subject_c = fps - mean(grouped$fps_subject))
    
lmer5_iao = lmer(
    precision ~ withinTaskIndex + y_pos_c + chin + fps_subject_c + 
    	(chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer5_iao)

lmer6_iao = lmer(
    precision ~ withinTaskIndex + y_pos_c + chin * fps_subject_c + 
    	(chin | run_id), 
    data=data_trial,
    REML=FALSE)
summary(lmer6_iao)
# ranef(lmer5_iao)
anova(lmer4_rs, lmer5_iao, lmer6_iao)
```


## 3) Fial model: RIRS
Control variables, such as age and withinTaskIndex do not show a correlation. 
Predictors: attributeIndex + optionIndex + payneIndex
 - Effect of the Option Index: Odds for choseLL increase by the factor exp(-0.97)=0.38. The more gaze points on immediate options, the lower the odd for choseLL
 - Effect of the Payne Index: Odds for choseLL increase by the factor exp(-0.17)=0.84. The more transitions within options (positive payne), the lower the odd for chose LL
 - Did not try to get the procentual reduction of L1 and L2 variance because the logistic regression does not have error terms
```{r}
glmer_final = lmer(
    precision ~ withinTaskIndex + y_pos_c + chin + glasses_binary + 
    	(chin + glasses_binary | run_id), 
    data=data_trial,
    REML=FALSE)

summary(glmer_final)
confint(glmer_final, method="boot", n=50) # CI with Bootstrap
# The confidence intervals should not include 1 to be significant
```


## Effects
Use formulas without random slopes (Snijders & Bosker, 2012)
```{r}
m0 <- lmer(precision ~ withinTaskIndex + (1 | run_id),
           data=data_trial,
           REML=FALSE)
m1 <- lmer(precision ~ withinTaskIndex + y_pos_c + (1 | run_id),
           data=data_trial,
           REML=FALSE)

L1_m0 <- sigma(m0)^2 # L1-Residualvarianz RIO Modell
L1_m1 <- sigma(m1)^2 # L1-Residualvarianz RI Modell
print('Pseudo R^2')
print(paste(
    'Reduction of L1 variance due to y_pos: ',
    (L1_m0 - L1_m1)/L1_m0
))

L2_m0 <- unlist(summary(m0)$var) # Interceptvarianz RI Modell
L2_m1 <- unlist(summary(m1)$var) # Interceptvarianz IAO Modell
print(paste(
    'Reduction of L2 variance due to y_pos: ',
    (L2_m0 - L2_m1)/L2_m0
))

```


## Assumptions
Sources: 
 - https://www.youtube.com/watch?v=UvyxSqEXBwc
 - https://www.pythonfordatascience.org/mixed-effects-regression-python/
 - https://ademos.people.uic.edu/Chapter18.html
 
### Linearity: Plot residuals vs. observed
```{r}
plot(resid(glmer_final), data_trial$precision)
```

### Homosedasticity: Homogeneity of residuals across groups
ANOVA as a variation of Levene's test. Extract residuals from the model and square the absolute value. Should be not significant. Significant differences across residuals. We have Heteroscedasticity.
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(glmer_final),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(glmer_final)
```

### Normal distribution of residuals
Normal distribution not given. 
```{r}
qqmath(lmer4_rs, id=0.05)
```

Lets try with log transformed offset
Does not make it any better
```{r}
data_trial = data_trial %>%
    mutate(
    	
        outcome_log = log(precision+1),
        outcome_log10 = log10(precision+1),
        outcome_sqrt = sqrt(precision),
        )

lmer_log = lmer(
    outcome_log ~ withinTaskIndex + y_pos_c + chin + glasses_binary + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
# summary(lmer_log)
# ranef(lmer_log)
qqmath(lmer_log, id=0.05, prep_global_data='log transformed offset')

lmer_log10 = lmer(
    outcome_log10 ~ withinTaskIndex + y_pos_c + chin + glasses_binary + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
# summary(lmer_log10)
# ranef(lmer_log10)
qqmath(lmer_log10, id=0.05, prep_global_data='log10 transformed offset')

lmer_sqrt = lmer(
    outcome_sqrt ~ withinTaskIndex + y_pos_c + chin + glasses_binary + (chin | run_id), 
    data=data_trial,
    REML=FALSE)
# summary(lmer_sqrt)
# ranef(lmer_sqrt)
qqmath(lmer_sqrt, id=0.05, prep_global_data='sqrt transformed offset')

```

### Residuals for sqrt transformation
Does not look better
```{r}
data_trial = data_trial %>%
    mutate(
        res = residuals(lmer_sqrt),
        res_sq = (abs(res)^2))

levene_model <- lm(res_sq ~ run_id, data=data_trial)
anova(levene_model)

plot(lmer_sqrt)
```

### Multicollinearity of the predictors
No multicollinearity
```{r}
predictors = c('withinTaskIndex', 'y_pos_c', 'chin', 'glasses_binary')
correlation = cor(
    data_trial %>% 
        dplyr::select(predictors),
    use = 'pairwise.complete.obs'
)

symnum(correlation)
correlation

car::vif(lmer4_rs)
```

## HLMdiag
https://cran.rstudio.com/web/packages/HLMdiag/index.html
```{r}
#case_delete() #iteratively delete groups corresponding to the levels of a hierarchical linear model, using lmer to fit the models for each deleted case

#covratio() #calculate measures of the change in the covariance matrices for the fixed effects based on the deletion of an observation, or group of observations,

#diagnostics() #is used to compute deletion diagnostics for a hierarchical linear model based on the building blocks returned by case_delete.

#HLMresid() #extracts residuals from a hierarchical linear model fit using lmer. Can provide a variety of different types of residuals based upon the specifications when you call the function

#leverage() #calculates the leverage of a hierarchical linear model fit

#mdffits() #calculate measures of the change in the fixed effects estimates based on the deletetion of an observation, or group of observations
```
