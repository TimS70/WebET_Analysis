---
title: "Choice Task Regression Analysis (cluster corrected data)"
author: "Tim Schneegans"
date: "28th of January 2021"
output: html_document
---

# Setup
```{r}
root = "C:/Users/User/GitHub/WebET_Analysis"
path_results = file.path(root, 'results', 'plots', 'choice_task')

knitr::opts_knit$set(root.dir = normalizePath(file.path('..', '..')))

knitr::opts_knit$get("root.dir")

source(file.path(root, 'utils', 'r', 'geom_split_violin.R'))
source(file.path(root, 'utils', 'r', 'merge_mean_by_subject.R'))
source(file.path(root, 'utils', 'r', 'merge_mean_by_subject.R'))
source(file.path(root, 'utils', 'r', 'summarize_datasets.R'))
source(file.path(root, 'utils', 'r', 'get_packages.R'))
source(file.path(root, 'utils', 'r', 'remove_runs.R'))
source(file.path(root, 'utils', 'r', 'add_log_k.R'))
source(file.path(root, 'utils', 'r', 'remove_na_et_indices.R'))
source(file.path(root, 'utils', 'r', 'add_x_count.R'))
source(file.path(root, 'utils', 'r', 'identify_bad_choice_runs.R'))

get_packages(c('broom',
              'car', 
              'colorspace', 
              'dplyr', 
              "effsize",
              'e1071',
              'GGally',
              "ggplot2",
              "ggsignif",
              'lme4',
              'matlabr',
              'QuantPsyc',
              "RColorBrewer",
              'reshape2',
              'tidyr',
              'tidyverse'))
```


# Read and create datasets
```{r}
use_adjusted_et_data = TRUE
if (use_adjusted_et_data) {
    print('Using adjusted et_data. As a consequence there is no et data beyond the corrected aoi clusters')
}

if (use_adjusted_et_data) {
    
    data_subject = read.csv(
        file.path(root, 'data', 'choice_task', 'adjusted', 
                  'data_subject.csv'))
    
    data_trial = read.csv(
        file.path(root, 'data', 'choice_task', 'adjusted', 
                  'data_trial.csv'))
    
    data_et = read.csv(
        file.path(root, 'data', 'choice_task', 'adjusted', 
                  'data_et.csv'))

} else {

    data_subject = read.csv(
        file.path(root, 'data', 'choice_task', 'uncorrected', 
                  'data_subject.csv'))
    
    data_trial = read.csv(
        file.path(root, 'data', 'choice_task', 'uncorrected', 
                  'data_trial.csv'))
    
    data_et = read.csv(
        file.path(root, 'data', 'choice_task', 'uncorrected', 
                  'data_et.csv'))
}

summarize_datasets(data_et, data_trial, data_subject)
```


# Correlative Analysis

## Scatter matrix
```{r, scatter_plot, warning=FALSE}
sapply(
	data_subject %>%
		dplyr::select(
			'choseLL', 'attributeIndex', 'optionIndex', 'payneIndex', 
	    	'fps', 'birthyear', 'LL_top', 'choice_rt', 'logK'),
	function(x) sum(!is.na(x))
)

dir.create(file.path(path_results, 'correlations'))

ggpairs(
    data_subject,
    columns = c('choseLL', 'attributeIndex', 'optionIndex', 'payneIndex', 
    			'fps', 'birthyear', 'LL_top', 'choice_rt', 'logK'), 
    upper = list(continuous = wrap("cor", size = 3)),
    progress = F) 
ggsave(file.path(path_results, 'correlations', 'corr_plot_subject_clustered.pdf'), 
	   width=5.5, height=5)


ggpairs(
    data_trial,
    columns = c('choseLL', 'withinTaskIndex', 'trial_duration_exact',
    			'fps',
    			'attributeIndex', 'optionIndex', 'payneIndex'), 
    colour = "cyl", 
    upper = list(continuous = wrap("cor", size = 4)),
    progress = F) 
ggsave(file.path(path_results, 'correlations', 'corr_plot_trial_clustered.pdf'),
	   width=5.5, height=5)
```

# Logistic Regression on subject-level
 - No significant findings
```{r, logistic, results=FALSE, echo=FALSE, message=FALSE}
m_null = glm(choseLL ~ 1,
         data = data_subject %>%
		 	filter(!is.na(attributeIndex) & !is.na(payneIndex)), 
         family = binomial(link = "logit"))
summary(m_null)

data_subject$fps_c = scale(data_subject$fps)
data_subject$choice_rt_c = scale(data_subject$choice_rt)

m1 = glm(choseLL ~ 1 + choice_rt + fps_c,
         data = data_subject %>%
		 	filter(!is.na(attributeIndex) & !is.na(payneIndex)), 
         family = binomial(link = "logit"))
summary(m1)

m2 = glm(choseLL ~ 1 + choice_rt + fps_c + attributeIndex + payneIndex,
         data = data_subject %>%
		 	filter(!is.na(attributeIndex) & !is.na(payneIndex)), 
         family = binomial(link = "logit"))
summary(m2)

anova(m_null, m1, m2)
```

# MLA
When I do not look at the summarized scores but on every trial, I need to account for the lack of interdependence and use a MLA.

## Step 1) empty model (Intercept Only)
````{r, glmer0_io}
glmer0_io = glmer(
    choseLL ~ 1 + (1 | run_id), 
    data = data_trial %>%
    	filter(!is.na(attributeIndex) & !is.na(optionIndex)), 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)
summary(glmer0_io)

# take pi^2 / 3 instead of the level-1 residual
icc <- glmer0_io@theta[1]^2/ (glmer0_io@theta[1]^2 + (3.14159^2/3))
print(paste('icc:', icc))
```

## Random Intercept (Constrained intermediate model)
```{r, glmer1_ri}
data_trial$rt_c = scale(data_trial$trial_duration_exact)
data_trial$fps_c = scale(data_trial$fps)

glmer1_ri = glmer(
    choseLL ~ withinTaskIndex + rt_c + fps_c + 
    	attributeIndex + optionIndex + (1 | run_id), 
    data = data_trial %>%
    	filter(!is.na(attributeIndex) & !is.na(optionIndex)), 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)
summary(glmer1_ri)

### Random Intercept Random Slope (Augmented intermediate model)
glmer2_rirs = glmer(
    choseLL ~ withinTaskIndex + rt_c + fps_c +
    	attributeIndex + optionIndex + 
    	(attributeIndex + optionIndex | run_id), 
    data = data_trial %>%
    	filter(!is.na(attributeIndex) & !is.na(optionIndex)), 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)
summary(glmer2_rirs)

anova(glmer0_io, glmer1_ri, glmer2_rirs)
```

### Within-Subject centering
```{r, within_subject_centering}
grouped = data.frame(
    data_subject$run_id,
    data_subject$attributeIndex,
    data_subject$optionIndex,
    data_subject$payneIndex,
    data_subject$choice_rt)

names(grouped) = c('run_id', 
                   'cluster_mean_AI', 
                   'cluster_mean_OI', 
                   'cluster_mean_PI',
				   'cluster_mean_rt')

for (col in names(grouped)[2:5]){
    if (col %in% names(data_trial)) {
        data_trial = data_trial %>% dplyr::select(!col)
    }
}

data_trial = merge(data_trial, grouped, by='run_id')

data_trial$attributeIndex_cmc = data_trial$attributeIndex - 
	data_trial$cluster_mean_AI

data_trial$optionIndex_cmc = data_trial$optionIndex - 
    data_trial$cluster_mean_OI

data_trial$payneIndex_cmc = data_trial$payneIndex - 
    data_trial$cluster_mean_PI

glmer3_ri = glmer(
    choseLL ~ 
        withinTaskIndex + rt_c + fps_c + attributeIndex_cmc +
        optionIndex_cmc + (1 | run_id), 
    data = data_trial %>%
    	filter(!is.na(attributeIndex) & !is.na(optionIndex)), 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)
summary(glmer3_ri)

glmer4_rirs = glmer(
    choseLL ~  withinTaskIndex + rt_c + fps_c + attributeIndex_cmc +
        optionIndex_cmc + (attributeIndex_cmc + optionIndex_cmc | run_id), 
    data = data_trial %>%
    	filter(!is.na(attributeIndex) & !is.na(optionIndex)), 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)
summary(glmer4_rirs)
anova(glmer0_io, glmer3_ri, glmer4_rirs)
```

## Fial model: RIRS
Control variables, such as age and withinTaskIndex do not show a correlation. 
Predictors: attributeIndex + optionIndex + payneIndex
 - Effect of the Option Index: Odds for choseLL increase by the factor exp(-0.97)=0.38. The more gaze points on immediate options, the lower the odd for choseLL
 - Effect of the Payne Index: Odds for choseLL increase by the factor exp(-0.17)=0.84. The more transitions within options (positive payne), the lower the odd for chose LL
 - Did not try to get the procentual reduction of L1 and L2 variance because the logistic regression does not have error terms

```{r, glmer_final}
glmer_final = glmer(
    choseLL ~ withinTaskIndex + rt_c + fps_c +
    	attributeIndex + optionIndex + (1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 1)

summary(glmer_final)
confint(glmer_final, method="boot", n=50) # CI with Bootstrap
# The confidence intervals should not include 1 to be significant
```


## Simple Slopes
```{r, simple slopes}
# SD
sd_oi = sd(data_trial$optionIndex, na.rm = TRUE)

# Simple Slope 1
data_trial$oi_sd_1 = data_trial$optionIndex + sd_oi
# Simple Slope -1
data_trial$oi_sd_2 = data_trial$optionIndex - sd_oi

glmer_final_sd_1 = glmer(
    choseLL ~ withinTaskIndex + rt_c + fps_c + 
    	oi_sd_1 + attributeIndex + (1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"))
summary(glmer_final_sd_1)

glmer_final_sd_2 = glmer(
    choseLL ~ withinTaskIndex + rt_c + fps_c + 
    	oi_sd_2 + attributeIndex + (1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"))
summary(glmer_final_sd_2)
```

## Odds Ratios 
 - The effect of "payneIndex_cmc" is not significant, payneIndex_cmc OR = 0.83, 95% CI [0.67, 1] (has to be beyond 1 to be significant). Imagine it to be signficant: with an increase of the Payne Index of 1 (e.g. if they switch from neutral to only within option transitions), results in 0.67 times the chance (a lower chance) of choosing the delayed reward. 
 - Same for the ones with low (-1 SD) and high (+1 SD) Payne Index (If you have random slope, compare the different levels. 

```{r, effects}
OR <- exp(fixef(glmer_final))
CI <- exp(confint(glmer_final, parm="beta_")) # it can be slow (~ a few minutes). As alternative, the much faster but less precise Wald's method can be used: CI <- exp(confint(FM,parm="beta_",method="Wald")) 

or_sd_1 <- exp(fixef(glmer_final_sd_1))
ci_sd_1 <- exp(confint(glmer_final_sd_1, parm="beta_")) 

or_sd_2 <- exp(fixef(glmer_final_sd_2))
ci_sd_2 <- exp(confint(glmer_final_sd_2, parm="beta_")) 

OR_CI<-rbind(
    cbind(OR,CI), 
    cbind(or_sd_1, ci_sd_1)[3,], 
    cbind(or_sd_2, ci_sd_2)[3,])

rownames(OR_CI) = c(
    rownames(cbind(OR,CI)), 
    "payne_cmc_sd1", 
    "payne_cmc_sd0")
OR_CI
```

# Clusters
No clusters can improve the prediction of choices
```{r, clusters}
m_cluster_1 = glmer(
    choseLL ~ withinTaskIndex + rt_c + attributeIndex + (1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10) 

m_cluster_2 = glmer(
    choseLL ~ withinTaskIndex + rt_c + attributeIndex + cluster2 + 
    	(1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

m_cluster_3 = glmer(
    choseLL ~ withinTaskIndex + rt_c + attributeIndex + cluster3 + 
    	(1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

m_cluster_4 = glmer(
    choseLL ~ withinTaskIndex + rt_c + attributeIndex + cluster4 + 
    	(1 | run_id), 
    data = data_trial, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

fixef(m_cluster_2)[5]
fixef(m_cluster_3)[5]
fixef(m_cluster_4)[5]

# confint(m_cluster_2, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m_cluster_1, m_cluster_2, m_cluster_3, m_cluster_4)
```

# Assumptions

## Linear relationship between predicted log(choseLL) and the predictors
Looks quite linear. If not check out: http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/
```{r, linearity}
predictors <- c('attributeIndex', 'optionIndex', 'payneIndex')

data_plot = data_trial %>%
	filter(!is.na(attributeIndex)) %>%
    mutate(predict_choseLL_prob = 
        predict(glmer_final, type = "response"),
        logit = log(predict_choseLL_prob/(1-predict_choseLL_prob))) %>%
    dplyr::select(c(logit, predictors)) %>%
    gather(key = "predictors", value = "predictor_value", -logit)
data_plot %>% head(5)

ggplot(data_plot, aes(logit, predictor_value)) +
    geom_point(size = 0.5, alpha = 0.5) +
    geom_smooth(method = "loess") + 
    theme_bw() + 
    facet_wrap(~predictors, scales = "free_y")
dir.create(file.path('MLA', 'assumptions'))
ggsave(file.path(path_results, 'MLA', 'assumptions', 'linearity.pdf'), 
	   width=5.5, height=5)
```

## Multicollinearity
compute variance inflation factor. " As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity"
```{r, multicollinearity}
car::vif(glmer_final)
```

## DHARMa
"DHARMa was created by Florian Hartig in 2016 and creates readily interpretable residuals for generalized linear (mixed)"
https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html
```{r}
#simulateResiduals() #creates scaled (quantile) residuals through a default 250 simulations (which can be modified)

#plotSimulatedResiduals #provides qqplot and residuals vs predicted plots to determine deviations from normality

#Goodness of fit tests:
#testUniformity()
#testOverdispersion()
#testZeroinflation()
#testTemporalAutocorrelation()
#testSpatialAutocorrelation()
```