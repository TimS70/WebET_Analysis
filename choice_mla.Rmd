---
title: "MixedRegression"
author: "Tim Schneegans"
date: "4 Januar 2021"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
setwd("C:/Users/User/GitHub/WebET_Analysis")# https://gist.github.com/stevenworthington/3178163
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}
ipak(c("knitr",
       "dplyr",
       'readr',
       "rsq",
       'lme4',
       "ICC",
       'ggplot2',
       'GGally',
       'reshape2',
       'lme4',
       'compiler',
       'parallel',
       'boot',
       'lattice',
       "lmerTest", # Erhalte p-Werte
       "tinytex")
    )

knitr::opts_chunk$set(echo = TRUE)
options(scipen=999) # Show R markdown output as Integers
```


# Load data
# Screening
# Cleaning
Response time Outliers with malhalanobis distance
(https://www.youtube.com/watch?v=UvyxSqEXBwc) min 31:10


```{r data}
data_trial_choice <- read_csv('data_trial_choice.csv')

names <- c('chinFirst' ,'choseTop', 'choseLL', 'ethnic', 'gender', 'degree')
data_trial_choice[,names] <- lapply(data_trial_choice[,names] , factor)

# data_trial_choice$degree <- factor(data_trial_choice$degree, levels = c(1, 2, 0), 
#                    labels = c("College", "Grad","HighSchool"))

str(data_trial_choice)
```



## Visualize Predictors
```{r}
ggpairs(data_trial_choice[, c('choiceNr', 'trial_duration_exact', 'k', 'optionIndex', 'attributeIndex', 'payneIndex')]) # Correlations
```

# Violin Plots (categorical Variables)
```{r}
# ggplot(data_trial_choice, aes(x = choseTop, y = k)) +
#   stat_sum(aes(size = ..n.., group = 1)) +
#   scale_size_area(max_size=10)
```

```{r}
# TODO: FPS


violinPlot_1 = function(categoricalVariable) {
tmp <- melt(data_trial_choice[, c(categoricalVariable, "optionIndex", "attributeIndex", "payneIndex")], id.vars=categoricalVariable)
ggplot(tmp, aes(x = get(categoricalVariable), y = value)) +
  geom_jitter(alpha = .1) +
  geom_violin(alpha = .75) +
  facet_grid(variable ~ .) +
  scale_y_sqrt()
}

violinPlot_2 = function(categoricalVariable) {
tmp <- melt(data_trial_choice[, c(categoricalVariable, "trial_duration_exact")], id.vars=categoricalVariable)
ggplot(tmp, aes(x = get(categoricalVariable), y = value)) +
  geom_jitter(alpha = .1) +
  geom_violin(alpha = .75) +
  facet_grid(variable ~ .) +
  scale_y_sqrt()
}

violinPlot_1('gender')
violinPlot_1('ethnic')
violinPlot_1('degree')

violinPlot_2('gender')
violinPlot_2('ethnic')
violinPlot_2('degree')
```

# Boxplots (Binary)
```{r}
boxPlot = function(binaryVariable) {
tmp <- melt(data_trial_choice[, c(binaryVariable, "optionIndex", "attributeIndex", "payneIndex", 'trial_duration_exact')],
  id.vars=binaryVariable)
ggplot(tmp, aes(factor(get(binaryVariable)), y = value, fill=factor(get(binaryVariable)))) +
  geom_boxplot() +
  facet_wrap(~variable, scales="free_y")
}

boxPlot('choseTop')
```

## Rescale

## Random Slope
### Offset
```{r}
# https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/
data_trial_choice$choiceNr_c = scale(data_trial_choice$choiceNr)
model <- glmer(choseLL ~ choiceNr_c + optionIndex + attributeIndex + payneIndex + k + (1 | run_id), 
               data = data_trial_choice, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)

print(model, corr = FALSE)
summary(model)
confint(model, method="boot", n=50) # CI with Bootstrap does not need normality
```

## Visualize with Average Marginal Probability
```{r}
summary(data_trial_choice$optionIndex)
```

```{r}
tmpdat <- data_trial_choice[, c("choiceNr_c", 
                                "optionIndex",  
                                'attributeIndex', 
                                'payneIndex', 
                                'k',    
                                "run_id")]

# sequence of distinct values for predictor of interest
jvalues <- with(data_trial_choice, 
                seq(from = min(optionIndex), 
                    to = max(optionIndex), 
                    length.out = 100))

# calculate predicted probabilities and store in a list
predictions <- lapply(jvalues, function(j) {
    tmpdat$optionIndex <- j
    predict(model, newdata = tmpdat, type = "response")
})
```

```{r}
# average marginal predicted probability across a few different 
plotdat <- sapply(predictions[c(1, 20, 40, 60, 80, 100)], mean, na.rm=TRUE)

# get the means with lower and upper quartiles
# plotdat <- t(sapply(predictions, function(x) {
#               c(M = mean(x), quantile(x,
#                                       c(0.25, 0.75),
#                                       na.rm=na_rm))
#     }
#   )
# )

# add in LengthofStay values and convert to data frame
plotdat <- as.data.frame(cbind(plotdat, jvalues))

# better names and show the first few rows

colnames(plotdat) <- c("PredictedProbability", "optionIndex")
ggplot(plotdat, aes(x = optionIndex, y = PredictedProbability)) + geom_line() +
    ylim(c(0, 1))
```


# H5, H6
```{r prep data}
data_h56 <- read_csv('data_h56.csv')

data_h56$sight = factor(data_h56$sight, 
                    labels = c("glasses", "none", "contact", "perfect"))
data_h56$sight <- relevel(data_h56$sight, ref = "none")
```


## Null 
```{r nullModel}
null <- lmer(offset_perc ~ 1 + (1 | run_id), data_h56)
summary(null)
var.u0i <- unlist(VarCorr(null))
var.rti <- sigma(null)^2
var.u0i / (var.u0i + var.rti)
fixef(null)
ranef(null)
coef(null)
```

ICC = x%. x% of the variance relate to the variance between the subjects 
```{r ICC}
library(ICC)
data_h56$run_id_factor <- as.factor(data_h56$run_id)
ICCest(data_h56$run_id_factor, data_h56$offset_perc, alpha=.05, CI.type="THD")
fixef(null)
ranef(null)
coef(null)
```

## Random Intercept

### Offset
```{r}
model_ri_1 <- lmer(offset_perc ~ 1 + ethnic + positionIndex + fixation_nr + (1 | run_id), data_h56)
model_ri_2 <- lmer(offset_perc ~ 1 + ethnic + positionIndex + fixation_nr + chin + sight + glasses + (1 | run_id), data_h56)
summary(model_ri_2)
confint(model_ri_2, method="boot", n=1000) # CI with Bootstrap does not need normality 
```

### Precision
```{r}
model_ri_1 <- lmer(precision_perc ~ 1 + ethnic + positionIndex + fixation_nr + (1 | run_id), data_h56)
model_ri_2 <- lmer(precision_perc ~ 1 + ethnic + positionIndex + fixation_nr + chin + sight + glasses + (1 | run_id), data_h56)
summary(model_ri_2)
confint(model_ri_2, method="boot", n=1000) # CI with Bootstrap does not need normality 
```

## Random Slope
### Offset
```{r}
model_ri_1 <- lmer(offset_perc ~ 1 + ethnic + positionIndex + fixation_nr + (1 | run_id), data_h56)
model_ri_2 <- lmer(offset_perc ~ 1 + ethnic + positionIndex + fixation_nr + chin + sight + glasses + (1 + chin | run_id), data_h56)
summary(model_ri_2)
confint(model_ri_2, method="boot", n=1000) # CI with Bootstrap does not need normality 
```

### Precision
```{r}
model_ri_1 <- lmer(precision_perc ~ 1 + ethnic + positionIndex + fixation_nr + (1 | run_id), data_h56)
model_ri_2 <- lmer(precision_perc ~ 1 + ethnic + positionIndex + fixation_nr + chin + sight + glasses + (1 + chin | run_id), data_h56)
summary(model_ri_2)
confint(model_ri_2, method="boot", n=1000) # CI with Bootstrap does not need normality 
anova(model_ri_1, model_ri_2, refit=FALSE)
```