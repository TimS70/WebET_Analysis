---
title: "MixedRegression"
author: "Tim Schneegans"
date: "4 Januar 2021"
output: html_document
---


```{r}
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

getPackages(c('dplyr', 
              "effsize",
              'e1071',
              "ggplot2",
              "ggsignif",
              'lme4',
              'matlabr',
              'QuantPsyc',
              "RColorBrewer",
              'reshape2',
              'tidyr')
            )
```

# Matlab
```{r}
# run_matlab_script('amasino_dataPrep/fit_discount_k.m')
```

# Screening
# Cleaning
see choice_analysis.Rmd

# Read and create datasets
## Exclude subjects
```{r}
# Data on subject level
excludeSubjects <- read.table('data_jupyter/excludeSubjects_choice.csv', 
                           header=TRUE, sep=',')[, 1]
excludeSubjects
```


## data_subject
```{r}
# Data on subject level
data_subject <- read.table('data_jupyter/data_subject.csv', 
                           header=TRUE, sep=',') %>%
    filter(!(run_id %in% excludeSubjects))
alllogk<-read.table(
    "amasino_dataPrep/intermediateCSVs/allLogk.csv", header=FALSE, sep=",")
names(alllogk) = c('run_id', 'logK')
data_subject = merge(data_subject, alllogk, by='run_id')
data_subject = data_subject %>% 
    filter(!is.na(logK))
print(nrow(data_subject))
data_subject
```


## data_trial_choice
```{r}
# Data on Trial level
data_trial_choice <- read.table('data_jupyter/data_trial_choice.csv',
                                header=TRUE, sep=',')  %>%
    filter(run_id %in% data_subject$run_id)

if ('logK' %in% names(data_trial_choice))
    {data_trial_choice = data_trial_choice %>% select(!logK)}
data_trial_choice = merge(
    data_trial_choice,
    data_subject %>% dplyr::select(run_id, logK),
    by='run_id'
)

data_trial_choice = data_trial_choice %>% filter(!is.na(logK))

print(paste('Number of subjects: ', length(unique(data_trial_choice$run_id))))
data_trial_choice %>% dplyr::select(run_id, trial_index, logK)
```

## data_et_choice
```{r}
data_et_choice <- read.table('data_jupyter/data_et_choice.csv', 
                             header=TRUE, sep=',') %>%
    filter(run_id %in% data_subject$run_id)

if ('choseTop' %in% names(data_et_choice))
    {data_et_choice = data_et_choice %>% select(!choseTop)}
data_et_choice = merge(
    data_et_choice, 
    data_trial_choice %>% 
        dplyr::group_by(run_id, trial_index) %>% 
        dplyr::summarise(choseTop = mean(choseTop)),
    by=c('run_id', 'trial_index')
)

data_et_choice$lookTopAOI = as.integer(data_et_choice$aoi == 'TL' | data_et_choice$aoi == 'TR')

print(paste('Number of subjects: ', length(unique(data_et_choice$run_id))))

```

# Models
## Intercept Only 
https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/
Average choice tendency is -0.62 (Jan 28), which is a strong tendency against the larger later choice 
````{r}
m0_io = glmer(
    choseLL ~ 1 + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)
summary(m0_io)
```

## Random Intercept Fixed Slope
Control variables: withinTaskIndex
```{r}
m1_ri = glmer(
    choseLL ~ withinTaskIndex + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)
summary(m1_ri)
anova(m0_io, m1_ri)
```

Predictors: attributeIndex + optionIndex + payneIndex
```{r}
m2_ri = glmer(
    choseLL ~ attributeIndex + optionIndex + payneIndex + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)
summary(m2_ri)
confint(m2_ri, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m0_io, m2_ri)
```

## Random Intercept Fixed Slope
The effect of ET variables largely varies by subjects
```{r}
m3_rs = glmer(
    choseLL ~ attributeIndex + optionIndex + payneIndex + 
        (1 + attributeIndex + optionIndex + payneIndex | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"))
summary(m3_rs)
# confint(m3_rs, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m2_ri, m3_rs)
```


# Clusters
No clusters can improve the prediction of choices
```{r}

m_cluster_1 = glmer(
    choseLL ~ attributeIndex + optionIndex + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10) 

m_cluster_2 = glmer(
    choseLL ~ attributeIndex + optionIndex + 
        cluster2 + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

m_cluster_3 = glmer(
    choseLL ~ attributeIndex + optionIndex + 
        cluster3 + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

m_cluster_4 = glmer(
    choseLL ~ attributeIndex + optionIndex + 
        cluster4 + (1 | run_id), 
    data = data_trial_choice, 
    family = binomial, 
    control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

fixef(m_cluster_2)[5]
fixef(m_cluster_3)[5]
fixef(m_cluster_4)[5]

# confint(m_cluster_2, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m_cluster_1, m_cluster_2, m_cluster_3, m_cluster_4)
```

## Visualize with Average Marginal Probability
#```{r}
summary(data_trial_choice$optionIndex)
```

#```{r}
tmpdat <- data_trial_choice[, c("choiceNr_c", 
                                "optionIndex",  
                                'attributeIndex', 
                                'payneIndex', 
                                'k',    
                                "run_id")]

# sequence of distinct values for predictor of interest
jvalues <- with(data_trial_choice, 
                seq(from = min(optionIndex), 
                    to = max(optionIndex), 
                    length.out = 100))

# calculate predicted probabilities and store in a list
predictions <- lapply(jvalues, function(j) {
    tmpdat$optionIndex <- j
    predict(model, newdata = tmpdat, type = "response")
})
```

#```{r}
# average marginal predicted probability across a few different 
plotdat <- sapply(predictions[c(1, 20, 40, 60, 80, 100)], mean, na.rm=TRUE)

# get the means with lower and upper quartiles
# plotdat <- t(sapply(predictions, function(x) {
#               c(M = mean(x), quantile(x,
#                                       c(0.25, 0.75),
#                                       na.rm=na_rm))
#     }
#   )
# )

# add in LengthofStay values and convert to data frame
plotdat <- as.data.frame(cbind(plotdat, jvalues))

# better names and show the first few rows

colnames(plotdat) <- c("PredictedProbability", "optionIndex")
ggplot(plotdat, aes(x = optionIndex, y = PredictedProbability)) + geom_line() +
    ylim(c(0, 1))
```

