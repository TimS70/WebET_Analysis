data_et_choice = merge(
data_et_choice,
data_trial_choice %>%
dplyr::group_by(run_id, trial_index) %>%
dplyr::summarise(choseTop = mean(choseTop)),
by=c('run_id', 'trial_index')
)
data_et_choice$lookTopAOI = as.integer(data_et_choice$aoi == 'TL' | data_et_choice$aoi == 'TR')
print(paste('Number of subjects: ', length(unique(data_et_choice$run_id))))
ggpairs(
data_subject %>%
dplyr::select(
choseLL,
attributeIndex, optionIndex, payneIndex,
fps),
progress = F
)
install.packages("colorspace") # Install it again
install.packages("colorspace")
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
getPackages(c('colorspace',
'dplyr',
"effsize",
'e1071',
"ggplot2",
"ggsignif",
'lme4',
'matlabr',
'QuantPsyc',
"RColorBrewer",
'reshape2',
'tidyr')
)
# run_matlab_script('amasino_dataPrep/fit_discount_k.m')
# Data on subject level
excludeSubjects <- read.table('data_jupyter/excludeSubjects_choice.csv',
header=TRUE, sep=',')[, 1]
excludeSubjects
# Data on subject level
data_subject <- read.table('data_jupyter/data_subject.csv',
header=TRUE, sep=',') %>%
filter(!(run_id %in% excludeSubjects))
alllogk<-read.table(
"amasino_dataPrep/intermediateCSVs/allLogk.csv", header=FALSE, sep=",")
names(alllogk) = c('run_id', 'logK')
data_subject = merge(data_subject, alllogk, by='run_id')
data_subject = data_subject %>%
filter(!is.na(logK))
print(nrow(data_subject))
data_subject
# Data on Trial level
data_trial_choice <- read.table('data_jupyter/data_trial_choice.csv',
header=TRUE, sep=',')  %>%
filter(run_id %in% data_subject$run_id)
if ('logK' %in% names(data_trial_choice))
{data_trial_choice = data_trial_choice %>% select(!logK)}
data_trial_choice = merge(
data_trial_choice,
data_subject %>% dplyr::select(run_id, logK),
by='run_id'
)
data_trial_choice = data_trial_choice %>% filter(!is.na(logK))
print(paste('Number of subjects: ', length(unique(data_trial_choice$run_id))))
data_trial_choice %>% dplyr::select(run_id, trial_index, logK)
data_et_choice <- read.table('data_jupyter/data_et_choice.csv',
header=TRUE, sep=',') %>%
filter(run_id %in% data_subject$run_id)
if ('choseTop' %in% names(data_et_choice))
{data_et_choice = data_et_choice %>% select(!choseTop)}
data_et_choice = merge(
data_et_choice,
data_trial_choice %>%
dplyr::group_by(run_id, trial_index) %>%
dplyr::summarise(choseTop = mean(choseTop)),
by=c('run_id', 'trial_index')
)
data_et_choice$lookTopAOI = as.integer(data_et_choice$aoi == 'TL' | data_et_choice$aoi == 'TR')
print(paste('Number of subjects: ', length(unique(data_et_choice$run_id))))
ggpairs(
data_subject %>%
dplyr::select(
choseLL,
attributeIndex, optionIndex, payneIndex,
fps),
progress = F
)
m0 = glm(choseLL ~ 1,
data = data_subject,
family = binomial(link = "logit"))
summary(m0)
m1 = glm(choseLL ~ 1 + attributeIndex + optionIndex + payneIndex,
data = data_subject,
family = binomial(link = "logit"))
summary(m1)
anova(m0, m1)
m0_io = glmer(
choseLL ~ 1 + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"),
nAGQ = 10)
summary(m0_io)
exp(-0.62)
m1_ri = glmer(
choseLL ~ withinTaskIndex + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"),
nAGQ = 10)
summary(m1_ri)
anova(m0_io, m1_ri)
m1_ri = glmer(
choseLL ~ attributeIndex + optionIndex + payneIndex + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"),
nAGQ = 10)
summary(m2_ri)
exp(-0.62) / (1+exp(-0.62))
exp(0.4418)
m1_ri = glmer(
choseLL ~ attributeIndex + optionIndex + payneIndex + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"),
nAGQ = 10)
summary(m1_ri)
confint(m1_ri, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m0_io, m1_ri)
exp(-0.17)
exp(-0.97)
# Reduction of L1-variance
L1_var = (sigma(m0_io)^2-sigma(m1_ri)^2) / m0_io
sigma(m0_io)^2
sigma(m1_ri)^2)
sigma(m1_ri)^2
m2_rs = glmer(
choseLL ~ attributeIndex + optionIndex + payneIndex +
(1 + attributeIndex + optionIndex + payneIndex | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m2_rs)
# confint(m3_rs, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m1_ri, m2_rs)
m2_rs = glmer(
choseLL ~ attributeIndex + optionIndex + payneIndex +
(1 + attributeIndex + optionIndex + payneIndex | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m2_rs)
confint(m3_rs, method="boot", n=50) # CI with Bootstrap does not need normality
m0_io@theta[1]^2
d1 = c(1:5)
d2 = c(1:5)
cbind(d1, d2)
data.frame(
data_subject$attributeIndex,
data_subject$optionIndex,
data_subject$payneIndex
)
grouped = data.frame(
data_subject$run_id
data_subject$attributeIndex,
grouped = data.frame(
data_subject$run_id,
data_subject$attributeIndex,
data_subject$optionIndex,
data_subject$payneIndex
)
names(grouped) = c('run_id',
'cluster_mean_AI',
'cluster_mean_OI',
'cluster_mean_PI')
data_trial_choice %>%
select(attributeIndex, attributeIndex_cm,
optionIndex, optionIndex_cm,
payneIndex, payneIndex_cm)
grouped = data.frame(
data_subject$run_id,
data_subject$attributeIndex,
data_subject$optionIndex,
data_subject$payneIndex
)
names(grouped) = c('run_id',
'cluster_mean_AI',
'cluster_mean_OI',
'cluster_mean_PI')
data_trial_choice = merge(
data_trial_choice,
grouped,
by='run_id'
)
data_trial_choice$attributeIndex_cm =
data_trial_choice$attributeIndex -
data_trial_choice$cluster_mean_AI
data_trial_choice$optionIndex_cm =
data_trial_choice$optionIndex -
data_trial_choice$cluster_mean_OI
data_trial_choice$payneIndex_cm =
data_trial_choice$payneIndex -
data_trial_choice$cluster_mean_PI
data_trial_choice %>%
select(attributeIndex, attributeIndex_cm,
optionIndex, optionIndex_cm,
payneIndex, payneIndex_cm)
data_trial_choice %>%
dpylr::select(attributeIndex, attributeIndex_cm,
optionIndex, optionIndex_cm,
payneIndex, payneIndex_cm)
data_trial_choice %>%
dplyr::select(attributeIndex, attributeIndex_cm,
optionIndex, optionIndex_cm,
payneIndex, payneIndex_cm)
m1_ri = glmer(
choseLL ~ attributeIndex_cm + optionIndex_cm + payneIndex_cm
+ (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"),
nAGQ = 10)
summary(m1_ri)
confint(m1_ri, method="boot", n=50) # CI with Bootstrap does not need normality
anova(m0_io, m1_ri)
# take pi^2 / 3 instead of the level-1 residual
icc <- m0_io@theta[1]^2/ (m0_io@theta[1]^2 + (3.14159^2/3))
icc
3.14159^2/3)
3.14159^2/3
m1_rirs = glmer(
choseLL ~ withinTaskIndex +
data_trial_choice + optionIndex_cm +
payneIndex_cm
+ (1 + attributeIndex_cm + optionIndex_cm +
payneIndex_cm | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
m1_rirs = glmer(
choseLL ~ withinTaskIndex +
attributeIndex_cm + optionIndex_cm +
payneIndex_cm +
(1 + attributeIndex_cm + optionIndex_cm +
payneIndex_cm | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m1_rirs)
# confint(m1_rirs, method="boot", n=50) # CI with Bootstrap does not need normality
# anova(m1_ri, m2_rs)
m1_ri = glmer(
choseLL ~ withinTaskIndex +
attributeIndex_cm + optionIndex_cm +
payneIndex_cm + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m1_ri)
paste("FYI: The deviance of the CIM is:", m1_ri@devcomp$cmp[[8]])
# confint(m1_rirs, method="boot", n=50) # CI with Bootstrap does not need normality
# anova(m1_ri, m2_rs)
m1_ri = glmer(
choseLL ~ withinTaskIndex +
attributeIndex_cm + optionIndex_cm +
payneIndex_cm + (1 | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m1_ri)
paste("FYI: The deviance of the AIM is:", m1_ri@devcomp$cmp[[8]])
# confint(m1_rirs, method="boot", n=50) # CI with Bootstrap does not need normality
# anova(m1_ri, m2_rs)
m2_rirs = glmer(
choseLL ~ withinTaskIndex +
attributeIndex_cm + optionIndex_cm +
payneIndex_cm +
(1 + attributeIndex_cm + optionIndex_cm +
payneIndex_cm | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m2_rirs)
paste("FYI: The deviance of the CIM is:", m2_rirs@devcomp$cmp[[8]])
# confint(m2_rirs, method="boot", n=50) # CI with Bootstrap
anova(m1_ri, m2_rirs)
m3_rirs = glmer(
choseLL ~ withinTaskIndex +
attributeIndex_cm + optionIndex_cm +
payneIndex_cm +
(1 + attributeIndex_cm + optionIndex_cm +
payneIndex_cm | run_id),
data = data_trial_choice,
family = binomial,
control = glmerControl(optimizer = "bobyqa"))
summary(m3_rirs)
paste("FYI: The deviance of the CIM is:", m3_rirs@devcomp$cmp[[8]])
confint(m3_rirs, method="boot", n=50) # CI with Bootstrap
setwd("C:/Users/User/GitHub/WebET_Analysis")
getPackages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
getPackages(c('plyr',
'dplyr',
"effsize",
'e1071',
"ggplot2",
"ggsignif",
'matlabr',
'QuantPsyc',
"RColorBrewer",
'reshape2',
'tidyr')
)
run_matlab_script('amasino_dataPrep/fit_discount_k.m')
# Data on subject level
excludeSubjects <- read.table('data_jupyter/excludeSubjects_choice.csv',
header=TRUE, sep=',')[, 1]
excludeSubjects
# Data on subject level
data_subject <- read.table('data_jupyter/data_subject.csv',
header=TRUE, sep=',') %>%
filter(!(run_id %in% excludeSubjects))
alllogk<-read.table(
"amasino_dataPrep/intermediateCSVs/allLogk.csv", header=FALSE, sep=",")
names(alllogk) = c('run_id', 'logK')
data_subject = merge(data_subject, alllogk, by='run_id')
data_subject = data_subject %>%
filter(!is.na(logK))
print(nrow(data_subject))
data_subject
# Data on Trial level
data_trial_choice <- read.table('data_jupyter/data_trial_choice.csv',
header=TRUE, sep=',')  %>%
filter(run_id %in% data_subject$run_id)
if ('logK' %in% names(data_trial_choice)) {
data_trial_choice = data_trial_choice %>% select(!logK)}
data_trial_choice = merge(
data_trial_choice,
data_subject %>% dplyr::select(run_id, logK),
by='run_id')
data_trial_choice = data_trial_choice %>% filter(!is.na(logK))
print(paste('Number of subjects: ', length(unique(data_trial_choice$run_id))))
data_trial_choice %>% dplyr::select(run_id, trial_index, logK)
data_et_choice <- read.table('data_jupyter/data_et_choice.csv',
header=TRUE, sep=',') %>%
filter(run_id %in% data_subject$run_id)
grouped = data_trial_choice %>%
dplyr::group_by(run_id, trial_index) %>%
dplyr::summarise(choseTop = mean(choseTop))
if ('choseTop' %in% names(data_et_choice))
{data_et_choice = data_et_choice %>% select(!choseTop)}
data_et_choice = merge(data_et_choice, grouped, by=c('run_id', 'trial_index'))
data_et_choice$lookTopAOI = as.integer(data_et_choice$aoi == 'TL' | data_et_choice$aoi == 'TR')
print(paste('Number of subjects: ', length(unique(data_et_choice$run_id))))
#Replication sample
ggplot(data_subject, aes(x=choseTop))+
geom_histogram(bins=15)+theme_bw()+xlab("Proportion Top Choices")+
theme(text=element_text(size=20))+xlim(0,1)
ggsave("plots/choiceSide.pdf",width=5.5, height=5)
#Replication sample
ggplot(data_subject, aes(x=attributeIndex, y=payneIndex)) +
geom_point(size=2.5, alpha=.5)+
guides(alpha=FALSE)+ theme_bw()+xlim(-1,1)+
scale_colour_grey()+ylim(-1,1)+
theme(text=element_text(size=20))+
xlab("Attribute index") + ylab("Payne index")
ggsave("plots/att_payne.pdf",width=5.7, height=5)
cor.test(data_subject$payneIndex, data_subject$attributeIndex)
ggplot(data_subject, aes(x=logK))+
geom_histogram(binwidth=.5, alpha=.5,position="identity")+
scale_fill_manual(values=c("palegreen","cornflowerblue"), name="") +
theme_bw()+theme(text=element_text(size=40))
ggsave("plots/logk_hist.pdf", width=5.5, height=5)
#Plot correlation between attribute index and discount rate (k-val)
ggplot(data_subject, aes(x=attributeIndex, y=logK)) +
geom_point(size=2.5, aes(alpha=.5))+
guides(alpha=FALSE,color=FALSE, shape=FALSE)+
theme_bw()+xlim(-1,1)+
scale_colour_grey()+ylim(-10,0)+
theme(text=element_text(size=20))+
xlab("Attribute index") + ylab("log(k)")
ggsave("plots/logk_attributeIndex.pdf",width=5.7, height=5)
cor.test(data_subject$attributeIndex, data_subject$logK)
#Plot correlation between Payne index and discount rate
#Replication sample
ggplot(data_subject, aes(x=payneIndex, y=logK)) +
geom_point(size=2.5, aes(alpha=.5))+
guides(alpha=FALSE,color=FALSE, shape=FALSE)+
theme_bw()+xlim(-1,1)+
scale_colour_grey()+ylim(-10,0)+
theme(text=element_text(size=20))+
xlab("Payne index") +
ylab("log(k)")
ggsave("plots/logk_payneIndex.pdf",width=5.7, height=5)
cor.test(data_subject$payneIndex,data_subject$logK)
# correlationPlot <- function(data, xVar, yVar, xName, yName) {
#     data$xVar <- data[, xVar]
#     data$yVar <- data[, yVar]
#
#     ggplot(data, aes(x=xVar, y=yVar)) +
#         theme_bw()+xlim(-1,1)+ylim(-10,0) +
#         scale_colour_grey(start=.1, end=.6) +
#         scale_shape_manual(values=c(16,17)) +
#         theme(text=element_text(size=20), legend.position = "none") +
#         xlab(xName) +
#         ylab(yName)
# }
ggplot(data_subject, aes(x=optionIndex, y=logK)) +
geom_point(size=2.5, aes(alpha=.5))+
guides(alpha=FALSE,color=FALSE, shape=FALSE)+
theme_bw()+xlim(-1,1)+
scale_colour_grey()+ylim(-10,0)+
theme(text=element_text(size=20))+
xlab("Option index") +
ylab("log(k)")
ggsave('plots/opt_logk.pdf',width=5.7, height=5)
cor.test(data_subject$optionIndex, data_subject$logK)
subjectiveValue = function(data) {
data$svLL = data$aLL / (1+ exp(data$logK) * data$tLL)
data$svSS = data$aSS / (1+ exp(data$logK) * data$tSS)
data$svT = data$LL_top * data$svLL +
(1-data$LL_top) * data$svSS
data$svB = data$LL_top * data$svSS +
(1-data$LL_top) * data$svLL
data$dSV_TB = data$svT - data$svB
data$dSV_LLSS = data$svLL - data$svSS
return(data)
}
data_trial_choice = subjectiveValue(data_trial_choice)
data_trial_choice %>%
dplyr::select(run_id, logK, choseLL, aLL, tLL, svLL, aSS, dSV_LLSS)
data_trial_choice %>%
dplyr::select(run_id, logK, choseTop, LL_top, aLL, tLL, svT, svB, dSV_TB)
data_trial_choice$run_id = factor(data_trial_choice$run_id)
ggplot(data_trial_choice, aes(x=tLL, y=svLL, color=run_id)) +
geom_line() +
ggtitle('svLL across tLL')
grouped = data_trial_choice %>%
dplyr::group_by(run_id, tLL) %>%
dplyr::summarise(svLL = mean(svLL))
ggplot(grouped, aes(x=tLL, y=svLL, color=run_id)) +
geom_line() +
ggtitle('Grouped svLL across tLL')
nBins = 8
data_trial_choice$general_dSV_TB_bin = cut(
data_trial_choice$dSV_TB,
nBins,
include.lowest=TRUE,
labels=c(1:nBins))
data_trial_choice$general_dSV_LLSS_bin = cut(
data_trial_choice$dSV_LLSS,
nBins,
include.lowest=TRUE,
labels=c(1:nBins))
unique(data_trial_choice$general_dSV_TB_bin)
unique(data_trial_choice$general_dSV_LLSS_bin)
grouped = data_trial_choice %>%
dplyr::group_by(general_dSV_TB_bin) %>%
dplyr::summarise(dSV_TB = mean(dSV_TB))
SV_bins = data_trial_choice %>%
dplyr::group_by(run_id, general_dSV_TB_bin) %>%
dplyr::summarise(
choseTop=mean(choseTop),
rt=mean(trial_duration_exact)/1000,
count=mean(x_count)
)
SV_bins = merge(
SV_bins,
grouped,
by='general_dSV_TB_bin'
)
SV_bins
#Percent choices by difference in SV
ggplot(data=SV_bins, aes(x=dSV_TB, y=choseTop)) +
theme_bw() +
geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
xlim(-5,5) +
geom_line(stat="summary", fun.y="mean", size=.5)+
stat_summary(fun.data=mean_se, geom="errorbar", width=.8)+
xlab("SV top - SV bottom")+ylab("Proportion top choices")+
theme(text=element_text(size=20))+ylim(0,1)
ggsave("plots/SV_TB.pdf", width=5.5, height=5)
#RT by difference in SV
#Replication sample (T/B)
ggplot(data=SV_bins, aes(x=dSV_TB, y=rt)) +
geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
xlim(-5,5) +
geom_line(stat="summary", fun.y="mean", size=.5) +
stat_summary(fun.data=mean_se, geom="errorbar", width=.8) +
xlab("SV top - SV bottom") +
ylab("Response Time (s)") +
theme(text=element_text(size=20))+ylim(0,6.5)
ggsave("plots/SV_RT.pdf",width=5.5, height=5)
ggplot(data=SV_bins, aes(x=dSV_TB, y=count)) +
geom_line(color='grey',alpha=.2, aes(group=as.numeric(run_id))) +
xlim(-5,5) +
geom_line(stat="summary", fun.y="mean", size=.5) +
stat_summary(fun.data=mean_se, geom="errorbar", width=.8) +
xlab("SV top - SV bottom") +
ylab("Number of Fixations") +
theme(text=element_text(size=20))+ylim(0,20)
ggsave("plots/SV_Count.pdf",width=5.5, height=5)
